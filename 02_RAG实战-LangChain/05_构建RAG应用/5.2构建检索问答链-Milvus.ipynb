{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c794bc7",
   "metadata": {},
   "source": [
    "# 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0f2c3-3bd9-4de1-bbd2-e0e2b09161c8",
   "metadata": {},
   "source": [
    "我们已经介绍了如何根据自己的本地知识文档，搭建一个向量知识库。 在接下来的内容里，我们将使用搭建好的向量数据库，对 query 查询问题进行召回，并将召回结果和 query 结合起来构建 prompt，输入到大模型中进行问答。   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8d968-8d98-47b9-8885-dc17d24dce76",
   "metadata": {},
   "source": [
    "## 1. 加载向量数据库\n",
    "\n",
    "首先，我们加载在前一章已经构建的向量数据库。注意，此处你需要使用和构建时相同的 Emedding。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc86262-da78-4fda-a597-600d54057062",
   "metadata": {},
   "source": [
    "### Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8349782-7ca4-4ebb-acc1-6097ff5cee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "my_emb = OllamaEmbeddings(base_url='http://129.201.70.35:11434', model=\"dengcao/Qwen3-Embedding-0.6B:F16\")\n",
    "\n",
    "# Milvus 连接参数\n",
    "vectordb = Milvus(\n",
    "        embedding_function=my_emb,\n",
    "        collection_name=\"ZXVMAXS\",  # Milvus 集合名称\n",
    "        connection_args={\n",
    "            \"host\": \"129.201.70.35\",  # Milvus 服务器地址\n",
    "            \"port\": \"19530\",  # Milvus 默认端口\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14c39416-a9b2-4de1-9fb6-5c521a7fd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'pk': 460219909630597135, 'producer': 'Apache FOP Version 2.6', 'creator': 'DITA Open Toolkit', 'creationdate': '2023-05-23T21:45:33+08:00', 'source': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf', 'file_path': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf', 'total_pages': 29, 'format': 'PDF 1.4', 'title': '目录', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20230523214533+08'00'\", 'page': 13}, page_content='4\\xa0功能本章包含如下主题：\\uf06c上网日志保存\\n10\\n\\uf06c上网日志查询\\n10\\n\\uf06c上网日志批量导入查询\\n11\\n\\uf06c日志管理\\n11\\n\\uf06c账号管理\\n11\\n\\uf06c角色管理\\n12\\n\\uf06c资源监控\\n12\\n\\uf06c告警管理\\n12\\n\\uf06c省级网关对接\\n12\\n\\uf06c拨测结果自动比对功能\\n12\\n\\uf06cNAT日志入库功能\\n13\\n\\uf06c北向接口\\n13\\n\\uf06c上网日志历史查询\\n13\\n\\uf06c云化上网日志XDR查询\\n13\\n以下介绍ZXVMAX-S的主要的功能。\\n4.1\\xa0上网日志保存\\uf06c支持使用Gbase数据库或HDFS保存上网日志。\\uf06c上网日志保存时间可配置，最短保存7天时间，最长可保存一年时间。\\uf06c支持自动清理超过保存时间的上网日志。\\n4.2\\xa0上网日志查询可通过web界面指定查询条件，查询用户上网日志。支持的查询条件：\\uf06c时间范围+公网IP\\n\\uf06c时间范围+目的IP\\n\\uf06c时间范围+MSISDN\\n\\uf06c时间范围+IMSI\\n\\uf06c时间范围+URL\\n\\uf06c支持组合以上五种基础条件，或在基础条件上增加指定公网端口、目的端口，做更精确的查询。\\n10\\nSJ-20220623151803-017|2023-03-30（R1.0）'),\n",
       " Document(metadata={'pk': 460219909630596834, 'producer': 'Apache FOP Version 2.3', 'creator': 'DITA Open Toolkit', 'creationdate': '2022-06-23T16:34:22+08:00', 'source': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）告警处理.pdf', 'file_path': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）告警处理.pdf', 'total_pages': 330, 'format': 'PDF 1.4', 'title': '目录', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20220623163422+08'00'\", 'page': 297}, page_content='ZXVMAX-S多维价值分析系统告警处理可能原因确保实际填充率达到预期填充率处理步骤确保实际填充率达到预期填充率\\n7.2194000200303HTTP接口下行TCP重传报文数完整率(小时)告警描述确保实际填充率达到预期填充率告警级别警告可能原因确保实际填充率达到预期填充率处理步骤确保实际填充率达到预期填充率\\n7.2204000200304HTTP接口TCP建链响应时延（ms）完整率(小时)告警描述确保实际填充率达到预期填充率告警级别警告可能原因确保实际填充率达到预期填充率处理步骤确保实际填充率达到预期填充率\\n7.2214000200305HTTP接口TCP建链确认时延（ms）完整率(小时)告警描述确保实际填充率达到预期填充率\\n276\\nSJ-20220623151803-011|2022-06-20（R1.0）')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vectordb.similarity_search(query=\"什么是vmax的上网日志系统？\", k=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f8dbd-ecd5-449d-9753-aedc2b74289c",
   "metadata": {},
   "source": [
    "## 2. 创建一个 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bd74f-3dd0-496e-905b-950a444bb7a7",
   "metadata": {},
   "source": [
    "在这里，我们调用 OpenAI 的 API 创建一个 LLM，当然你也可以使用其他 LLM 的 API 进行创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774193e5-62a0-4a08-a0b8-047202c8e166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a89fb297-888a-4d35-b519-90eba639893c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n嗯，用户发来“你好”，我需要回应。首先，要友好，用中文。然后，可能用户想开始对话，所以应该主动询问他们有什么需要帮助的。保持自然，不要太机械。比如可以说“你好！有什么我可以帮你的吗？”或者更亲切一点，比如“你好呀！今天过得怎么样？”不过用户可能只是测试，所以保持简洁和开放。另外，注意不要用太复杂的句子，保持口语化。可能用户之后会问问题，所以准备好回答各种问题。总之，回应要友好、开放，鼓励用户继续对话。\\n</think>\\n\\n你好！有什么我可以帮你的吗？😊'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "my_llm = Ollama(base_url='http://129.201.70.35:11434', model='qwen3:8B', temperature=0.1)\n",
    "\n",
    "my_llm.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e85917-7a21-4de3-b45a-19d00152382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import VLLMOpenAI  # 注意类名为 VLLMOpenAI[3](@ref)\n",
    "# my_llm = VLLMOpenAI(\n",
    "#     openai_api_key=\"token-abc123\",          # vLLM 无需鉴权，设为空字符串[3](@ref)\n",
    "#     openai_api_base=\"http://129.201.70.35:9991/v1\",  # 服务端地址\n",
    "#     model_name=\"my_qwen3_8b\",  # 需与部署的模型路径一致\n",
    "#     max_tokens=1024,                # 控制生成文本最大长度\n",
    "#     temperature=0,               # 生成多样性参数（0~1）\n",
    "#     top_p=0.9,                      # 采样阈值\n",
    "#     streaming=True                  # 支持流式输出（可选）\n",
    "# )\n",
    "# response = my_llm.invoke(\"你是谁？/no_think\")\n",
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f361e27-cafb-48bf-bb41-50c9cb3a4f7e",
   "metadata": {},
   "source": [
    "## 3. 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b5e3c-1bc9-40e9-83c7-0594c2e7727d",
   "metadata": {},
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91be03f4-264d-45cb-bebd-223c1c5747fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"你是VMAX运维助手，使用以下上下文来回答问题。如果你不知道答案，就说你不知道，不要试图编造答案。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\", \"sources\"],\n",
    "                                 template=template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d06d7f-1dca-4d10-b5cd-3a23e9d91200",
   "metadata": {},
   "source": [
    "#### 创建一个基于模板的检索链： 基础检索版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b05eb57-edf5-4b35-9538-42c2b8f5cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 基础检索\n",
    "base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 15},  # 扩大召回池\n",
    "    search_type=\"mmr\",  # 最大边际相关性算法（网页5）\n",
    "    # metadata_filter={\"source\": \"../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（5GC业务）.pdf\"}  # 元数据过滤\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(my_llm,\n",
    "                                       retriever=base_retriever,\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a7972-a673-41ca-a028-647169d19fcb",
   "metadata": {},
   "source": [
    "## 4.检索问答链效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2223f-6fb5-4504-bfcd-ac74ca9ff2fa",
   "metadata": {},
   "source": [
    "### 4.1 基于召回结果和 query 结合起来构建的 prompt 效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa1a61eb-feea-4fff-8063-a20c3b392aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_1 的结果：\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "ZXVMAX-S的5GC业务是指ZXVMAX-S多维价值分析系统在5G核心网（5G Core Network, 5GC）场景中的应用。该系统面向用户的网络运维和运营分析，能够从网元、用户、终端、业务等多个维度，对业务使用过程中的质量和特征进行全方位的挖掘。它支持实时分析（如网络质量、数据业务质量等）和事后分析（如用户投诉、问题分析等），为移动通信网络的运维和运营提供全面支撑。在5GC业务中，ZXVMAX-S系统能够帮助运营商优化网络性能、提升服务质量，并为市场发展提供数据支撑。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "question_1 = \"什么是ZXVMAX-S的5GC业务？/no_think\"\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])\n",
    "# print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2707095e-21d0-4e2b-8a5b-0c02258d2ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_2 的结果：\n"
     ]
    }
   ],
   "source": [
    "question_2 = \"严威是谁？/no_think\"\n",
    "result = qa_chain({\"query\": question_2})\n",
    "print(\"大模型+知识库后回答 question_2 的结果：\")\n",
    "# print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4195cfa-1fc8-41a9-8984-91f2e5fbe013",
   "metadata": {},
   "source": [
    "### 4.2 无知识库大模型自己回答的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569fbe28-2e2d-4042-b3a1-65326842bdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1270322/46941173.py:5: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  my_llm.predict(prompt_template)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\n好的，我现在要回答用户的问题：“什么是vmax的5GC业务？”首先，我需要明确用户提到的“vmax”指的是什么。因为“vmax”可能是一个公司、产品或技术的名称，但我不太确定。首先，我应该检查是否有常见的公司或技术使用“vmax”作为缩写。\\n\\n首先，我想到的是，可能用户指的是“vMAX”这个产品，比如由Dell EMC公司推出的vMAX存储系统。不过，vMAX通常与存储解决方案相关，而不是5GC业务。5GC（5G Core）是5G网络的核心网部分，涉及网络功能虚拟化（NFV）和云原生架构。因此，如果用户提到的是vMAX的5GC业务，可能是指某个公司利用vMAX技术或平台来支持5GC服务。\\n\\n接下来，我需要确认是否存在名为“vMAX”的5GC相关产品或服务。可能用户将“vMAX”与5GC结合，指的是某个特定的解决方案。例如，某些公司可能将他们的存储或虚拟化平台用于5GC的部署，但这种情况比较少见。\\n\\n另外，也有可能用户存在拼写错误，比如“vMAX”是否应为其他名称，如“vMAG”或其他缩写。但根据现有信息，我需要假设用户确实指的是“vMAX”。\\n\\n接下来，我需要考虑5GC业务的基本概念。5GC是5G核心网的一部分，负责处理用户数据、移动性管理、会话管理等。它基于NFV和云原生技术，支持灵活的网络切片和边缘计算。因此，如果vMAX与5GC相关，可能涉及虚拟化、云原生架构、网络切片管理等方面。\\n\\n假设vMAX是一个虚拟化平台或云原生解决方案，那么vMAX的5GC业务可能指的是利用该平台来部署和管理5G核心网功能。例如，vMAX可能提供虚拟化网络功能（VNF）的部署、资源管理、自动化运维等服务，支持运营商构建灵活、可扩展的5GC网络。\\n\\n不过，如果用户提到的vMAX并非指存储产品，而是另一个公司或技术，可能需要更多的上下文。例如，某些公司可能有自己的5GC解决方案，命名为vMAX。但目前没有广泛认知的vMAX与5GC直接关联的案例。\\n\\n因此，可能的结论是，用户可能混淆了术语，或者vMAX指的是某个特定公司的产品，该产品支持5GC业务。在这种情况下，我需要解释5GC业务的一般概念，并指出vMAX可能涉及的方面，同时建议用户确认具体上下文。\\n\\n总结来说，我需要先澄清vMAX的含义，然后结合5GC业务的定义，解释可能的关联。如果无法确定vMAX的具体指代，应建议用户提供更多信息，或者说明5GC业务的基本内容，并指出vMAX可能在其中扮演的角色，如虚拟化平台或云原生解决方案。\\n</think>\\n\\nvMAX的5GC业务通常指的是基于虚拟化和云原生技术的5G核心网（5GC）解决方案。以下是对这一概念的详细解释：\\n\\n---\\n\\n### **1. 5GC业务的核心概念**\\n**5G核心网（5GC）** 是5G网络的核心部分，负责处理用户数据、移动性管理、会话管理、网络切片等关键功能。其核心特点包括：\\n- **网络功能虚拟化（NFV）**：将传统硬件设备替换为虚拟化网络功能（VNF），如AMF、SMF、UPF等。\\n- **云原生架构**：基于微服务、容器化和自动化运维，实现灵活扩展和快速部署。\\n- **网络切片**：支持不同行业（如工业、医疗、车联网）的定制化网络服务。\\n- **边缘计算**：将计算能力下沉至靠近用户的边缘节点，降低延迟。\\n\\n---\\n\\n### **2. vMAX的5GC业务可能涉及的领域**\\n如果 **vMAX** 是某个公司或平台的名称（如存储、虚拟化或云服务），其5GC业务可能包括以下方面：\\n- **虚拟化平台支持**：利用vMAX的虚拟化技术部署5GC功能（如VNF），实现资源池化和动态分配。\\n- **云原生解决方案**：通过vMAX的云原生架构（如容器编排、微服务管理）构建5GC网络，支持快速迭代和弹性扩展。\\n- **网络切片管理**：基于vMAX的资源调度能力，为不同行业提供定制化的5G切片服务。\\n- **边缘计算集成**：结合vMAX的边缘计算能力，优化5GC的UPF部署和数据处理效率。\\n\\n---\\n\\n### **3. 可能的混淆点**\\n- **vMAX的常见含义**：在IT领域，vMAX通常指 **Dell EMC的存储解决方案**（如vMAX存储阵列），与5GC无直接关联。如果用户提到的是vMAX的5GC业务，可能是以下情况：\\n  1. **术语混淆**：用户可能将“vMAX”与“vMAG”（虚拟化管理平台）或其他技术混淆。\\n  2. **特定厂商的定制方案**：某些公司可能将自家的虚拟化或云平台命名为vMAX，并用于5GC部署（需具体厂商信息）。\\n  3. **拼写错误**：可能是其他缩写（如vMAG、vMAG）的误写。\\n\\n---\\n\\n### **4. 建议**\\n- **确认上下文**：若用户指的是某个特定厂商的vMAX产品，请提供更多信息（如公司名称、技术背景）。\\n- **通用解释**：若vMAX是虚拟化/云平台，其5GC业务通常涉及虚拟化部署、云原生架构和网络切片管理。\\n- **行业案例**：例如，某些运营商可能使用虚拟化平台（如vMAX）作为底层基础设施，部署5GC功能以支持物联网、工业自动化等场景。\\n\\n---\\n\\n### **总结**\\nvMAX的5GC业务可能指基于虚拟化或云原生技术的5G核心网解决方案，具体功能取决于vMAX的定义。若需更准确的解释，建议进一步明确vMAX的背景或厂商信息。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_1)\n",
    "\n",
    "### 基于大模型的问答\n",
    "my_llm.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d3a813-db19-4be5-8926-ad8298e3e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n好的，用户问“严威是谁？”，我需要先确定这个“严威”指的是谁。首先，可能是一个公众人物，比如演员、歌手、作家，或者某个领域的专家。但“严威”这个名字比较常见，可能有多个同名的人。\\n\\n首先，我应该考虑是否有名人叫严威。比如，演员方面，有没有叫严威的？我记得可能有演员严宽，但不确定有没有严威。或者可能是指其他领域的，比如作家、科学家、企业家等。\\n\\n另外，用户可能是在问某个特定领域的人物，比如科技、文化、体育等。如果用户没有提供更多背景，可能需要给出多个可能的解释。\\n\\n也有可能用户指的是某个虚构角色，比如小说或影视作品中的角色，但这种情况可能性较低，除非有特别的上下文。\\n\\n接下来，我需要检查是否有知名人物叫严威。比如，搜索一下，发现严威可能是一个演员，但不确定。或者可能是指某个历史人物？比如古代的某个官员或学者？\\n\\n另外，也有可能用户打错了名字，比如“严威”是否是“严宽”或其他名字的误写？这时候可能需要提示用户确认名字的正确性。\\n\\n如果无法确定具体是谁，应该说明可能有多个同名人物，并列举一些可能的选项，同时建议用户提供更多信息以便更准确的回答。\\n\\n总结一下，可能的步骤是：1. 确认名字的正确性；2. 检查是否有知名人物；3. 提供可能的解释；4. 建议用户提供更多背景信息。\\n</think>\\n\\n“严威”是一个较为常见的中文名字，可能指代不同领域的人物，具体身份需结合上下文判断。以下是几种可能的解释：\\n\\n1. **演员/艺人**  \\n   中国内地演员**严宽**（本名严威）曾因出演《仙剑奇侠传三》中的李逍遥而广为人知。他于2005年因该剧走红，后逐渐淡出娱乐圈。\\n\\n2. **历史人物**  \\n   古代可能有同名人物，但需更多背景信息确认。\\n\\n3. **其他领域**  \\n   可能是作家、学者、企业家等，但需具体信息进一步核实。\\n\\n**建议**：若需更准确的回答，请补充更多背景（如领域、相关事件等）。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_2)\n",
    "\n",
    "### 基于大模型的问答\n",
    "my_llm.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9ba4a-053d-409a-a632-63336c2bdf84",
   "metadata": {},
   "source": [
    "> ⭐ 通过以上两个问题，我们发现 LLM 对于一些近几年的知识以及非常识性的专业问题，回答的并不是很好。而加上我们的本地知识，就可以帮助 LLM 做出更好的回答。另外，也有助于缓解大模型的“幻觉”问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fee88-5d13-43dd-9415-180d9e6bf2e7",
   "metadata": {},
   "source": [
    "## 5. 添加历史对话的记忆功能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e633b4-879d-4e67-8f3e-d5c82f1712c3",
   "metadata": {},
   "source": [
    "现在我们已经实现了通过上传本地知识文档，然后将他们保存到向量知识库，通过将查询问题与向量知识库的召回结果进行结合输入到 LLM 中，我们就得到了一个相比于直接让 LLM 回答要好得多的结果。在与语言模型交互时，你可能已经注意到一个关键问题 - **它们并不记得你之前的交流内容**。这在我们构建一些应用程序（如聊天机器人）的时候，带来了很大的挑战，使得对话似乎缺乏真正的连续性。这个问题该如何解决呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cc4ec-5b42-4c8c-aafc-65745c9e59b2",
   "metadata": {},
   "source": [
    "### 5.1 记忆（Memory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc053f6c-aeed-42b9-938a-2c52020f1327",
   "metadata": {},
   "source": [
    "在本节中我们将介绍 LangChain 中的储存模块，即如何将先前的对话嵌入到语言模型中的，使其具有连续对话的能力。我们将使用 `ConversationBufferMemory` ，它保存聊天消息历史记录的列表，这些历史记录将在回答问题时与问题一起传递给聊天机器人，从而将它们添加到上下文中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ed5b18-1bd6-4160-b68e-4300ccc5d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1270322/2228008247.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d2c797-5706-438c-ae11-bf4aa81795ba",
   "metadata": {},
   "source": [
    "关于更多的 Memory 的使用，包括保留指定对话轮数、保存指定 token 数量、保存历史对话的总结摘要等内容，请参考 langchain 的 Memory 部分的相关文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56fe278-2109-4b7b-9604-2ea030b18caa",
   "metadata": {},
   "source": [
    "### 5.2 对话检索链（ConversationalRetrievalChain）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abe746-8e01-4067-9675-354deecdfde7",
   "metadata": {},
   "source": [
    "对话检索链（ConversationalRetrievalChain）在检索 QA 链的基础上，增加了处理对话历史的能力。\n",
    "\n",
    "它的工作流程是:\n",
    "1. 将之前的对话与新问题合并生成一个完整的查询语句。\n",
    "2. 在向量数据库中搜索该查询的相关文档。\n",
    "3. 获取结果后,存储所有答案到对话记忆区。\n",
    "4. 用户可在 UI 中查看完整的对话流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98d830-0f2f-4794-acc2-4c23428bdd8c",
   "metadata": {},
   "source": [
    "这种链式方式将新问题放在之前对话的语境中进行检索，可以处理依赖历史信息的查询。并保留所有信\n",
    "息在对话记忆中，方便追踪。\n",
    "\n",
    "接下来让我们可以测试这个对话检索链的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ba5ed5-24c4-4725-be2f-5d24bfbdee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "# 修改后的Prompt模板（添加chat_history变量）\n",
    "template = \"\"\"你是VMAX运维助手，请参考以下对话历史和上下文来回答问题：\n",
    "    {chat_history}\n",
    "    \n",
    "    相关上下文：\n",
    "    {context}\n",
    "    \n",
    "    问题：{question}\n",
    "    回答结束时说“谢谢你的提问！”\n",
    "    \"\"\"\n",
    "    \n",
    "QA_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"chat_history\", \"context\", \"question\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "# 创建对话链\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=my_llm,\n",
    "        retriever=vectordb.as_retriever(),\n",
    "        memory=memory,\n",
    "        combine_docs_chain_kwargs={\"prompt\": QA_PROMPT},\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    \n",
    "    # result = qa_chain({\"question\": question})\n",
    "    # return result[\"answer\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f98ff-9b0b-40f7-a3b4-7481fb6597d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c837e3-afae-4e0c-8b59-9e9fbc3e2a98",
   "metadata": {},
   "source": [
    "然后基于答案进行下一个问题“为什么这门课需要教这方面的知识？”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e96fbc6-935e-40ac-81b5-3a220fe05741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答：<think>\n",
      "好的，用户问的是“什么是ZXVMAX-S的5GC业务？”，我需要根据提供的上下文来回答。首先，我得仔细看看相关上下文里有没有提到ZXVMAX-S的5GC业务相关内容。\n",
      "\n",
      "在上下文中，有提到“ZXVMAX-S多维价值分析系统产品描述（5GC业务）图5-8会话跟踪组网逻辑图”，这说明ZXVMAX-S的5GC业务可能与产品描述和组网逻辑有关。另外，其他部分主要涉及告警处理、接口完整率和合规率的问题，可能和5GC业务的具体功能或应用场景相关。\n",
      "\n",
      "不过，上下文中的信息比较零散，没有直接定义5GC业务是什么。可能需要结合已知的5GC知识来补充。5GC（5G Core）是5G网络的核心部分，负责控制面和用户面功能，支持网络切片、边缘计算等特性。ZXVMAX-S作为多维价值分析系统，可能在5GC业务中用于数据收集、分析，帮助运营商优化网络性能和业务策略。\n",
      "\n",
      "但根据用户提供的上下文，重点可能在于ZXVMAX-S系统如何支持5GC业务，比如通过会话跟踪、接口监控等。因此，回答应结合产品描述和组网逻辑，说明ZXVMAX-S在5GC中的角色，如数据分析、性能监控等，同时提到相关告警处理机制确保服务质量和合规性。\n",
      "\n",
      "需要注意的是，用户提供的上下文可能没有详细说明5GC业务的具体定义，所以回答需要基于现有信息，并适当扩展，但避免超出上下文范围。最后，确保回答结束时有“谢谢你的提问！”。\n",
      "</think>\n",
      "\n",
      "ZXVMAX-S的5GC业务是指基于5G核心网（5G Core）的多维价值分析系统，主要用于支持5G网络中的业务数据分析、性能监控及优化。该系统通过采集和分析5GC（5G Core Cloud）相关接口（如S11、SGS等）的数据，帮助运营商实现对网络切片、会话管理、服务指标等关键业务的精细化运营，从而提升网络效率和用户体验。其核心功能包括告警处理、填充率监控（如接口完整率、合规率）以及组网逻辑分析（如会话跟踪），确保5GC业务的稳定运行和资源优化。  \n",
      "\n",
      "谢谢你的提问！\n",
      "\n",
      "==================================================\n",
      "\n",
      "回答：<think>\n",
      "好的，用户现在问的是ZXVMAX-S的5GC业务包含哪些具体功能。我需要根据之前的对话历史和上下文来回答。首先，回顾之前的对话，用户已经询问过ZXVMAX-S的5GC业务是什么，而我的回答提到了多维价值分析系统，涉及5GC的组网逻辑、告警处理、接口完整率和合规率监控等。\n",
      "\n",
      "现在用户进一步询问具体功能，我需要详细列出这些功能。根据上下文中的信息，ZXVMAX-S的5GC业务功能包括：\n",
      "\n",
      "1. **会话分析**：针对PDU会话创建、修改、释放的失败流程进行分析，通过多接口关联分析定位首次失败点，并进行失败码聚类分析，辅助问题定位。同时支持在小区、网元、终端等维度进行TOP分析。\n",
      "\n",
      "2. **切换分析**：针对5GC内切换流程的失败码进行分析，关联多接口信息，分析切换成功率及各阶段时延，提升用户5G驻留比。\n",
      "\n",
      "3. **4/5G互操作分析**：分析4/5G互操作的三种场景（切换、重选、重接入），关联控制面信息，评估互操作成功率及时延，优化用户切换体验。\n",
      "\n",
      "4. **告警处理**：监控S11、SGS等接口的完整率和合规率（如MMEPort、MSCServerPort、APN等），当实际填充率未达预期时触发告警，帮助定位问题根源。\n",
      "\n",
      "5. **组网逻辑分析**：通过会话跟踪组网逻辑图（如图5-8）分析网络结构，支持对5GC业务的精细化运营和资源优化。\n",
      "\n",
      "这些功能共同支持运营商对5GC网络的高效管理，确保服务质量和资源利用率。最后，确保回答结束时有“谢谢你的提问！”。\n",
      "</think>\n",
      "\n",
      "ZXVMAX-S的5GC业务主要包含以下具体功能：  \n",
      "1. **会话流程分析**：针对PDU会话创建、修改、释放的失败流程，通过多接口关联分析定位首次失败点，并对失败码组合进行聚类分析，辅助问题定界；支持按小区、网元、终端等维度进行TOP分析。  \n",
      "2. **切换流程分析**：分析5GC内切换流程的失败码，关联多接口信息，评估切换成功率及各阶段时延，提升用户5G驻留比。  \n",
      "3. **4/5G互操作分析**：针对切换、重选、重接入等场景，关联控制面信息，分析互操作成功率及时延，优化用户切换体验。  \n",
      "4. **告警监控与处理**：实时监控S11、SGS等接口的完整率和合规率（如MMEPort、MSCServerPort、APN等），当实际填充率未达预期时触发告警，辅助问题定位。  \n",
      "5. **组网逻辑分析**：基于会话跟踪组网逻辑图（如图5-8），分析5GC业务的网络结构，支持精细化运营和资源优化。  \n",
      "\n",
      "这些功能共同保障5GC业务的稳定性、性能及服务质量。  \n",
      "谢谢你的提问！\n",
      "\n",
      "==================================================\n",
      "\n",
      "回答：<think>\n",
      "好的，用户现在希望将之前提到的ZXVMAX-S的5GC业务功能整理成表格。我需要先回顾之前的对话，确保准确理解用户的需求。用户之前询问了ZXVMAX-S的5GC业务包含哪些功能，我详细列出了五个功能点，包括会话流程分析、切换流程分析、4/5G互操作分析、告警监控与处理以及组网逻辑分析。\n",
      "\n",
      "现在用户要求将这些信息整理成表格，我需要将每个功能点转化为表格中的行，可能包括功能名称、描述和应用场景等列。首先，我需要确认用户是否希望表格包含所有提到的功能，或者是否有其他需要补充的信息。根据之前的回答，每个功能点都有具体的描述，因此表格应包含这些细节。\n",
      "\n",
      "另外，用户可能希望表格结构清晰，便于阅读和理解。因此，我需要确定表格的列标题，例如“功能名称”、“功能描述”和“应用场景”等。同时，要确保每个功能点的信息准确无误，与之前的回答一致。例如，会话流程分析需要说明其针对的流程和分析方法，切换流程分析要提到失败码和时延评估，互操作分析要涵盖三种场景等。\n",
      "\n",
      "还需要注意用户可能的深层需求，比如是否需要进一步的技术细节或实际应用案例，但根据当前问题，用户只是要求整理成表格，因此应保持简洁。最后，确保表格格式正确，使用清晰的分隔符，如竖线或连字符，并在结尾加上“谢谢你的提问！”以符合之前的回答风格。\n",
      "</think>\n",
      "\n",
      "| **功能名称**         | **功能描述**                                                                 | **应用场景**                                                                 |\n",
      "|----------------------|------------------------------------------------------------------------------|------------------------------------------------------------------------------|\n",
      "| **会话流程分析**     | 分析PDU会话创建、修改、释放的失败流程，定位首次失败点，失败码聚类分析，支持按小区/网元/终端维度TOP分析 | 优化5G会话管理成功率，提升用户体验                                         |\n",
      "| **切换流程分析**     | 分析5GC内切换流程的失败码，关联多接口信息，评估切换成功率及各阶段时延         | 提升用户5G驻留比，优化网络切换性能                                         |\n",
      "| **4/5G互操作分析**   | 分析切换、重选、重接入等场景，关联控制面信息，评估互操作成功率及时延         | 优化4/5G互操作体验，减少用户切换中断                                       |\n",
      "| **告警监控与处理**   | 监控S11、SGS等接口的完整率和合规率（如MMEPort、MSCServerPort、APN等），触发告警 | 快速定位接口填充率异常，保障5GC业务稳定性                                   |\n",
      "| **组网逻辑分析**     | 基于会话跟踪组网逻辑图（如图5-8），分析5GC业务网络结构                       | 支持网络资源优化和精细化运营，提升5GC组网效率                               |\n",
      "\n",
      "谢谢你的提问！\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"什么是ZXVMAX-S的5GC业务？\",\n",
    "    \"包含哪些功能\", \n",
    "    \"整理成表格\"  \n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"question\": question})  # Pass string directly, not dict\n",
    "    # print(f\"问题：{question}\")\n",
    "    print(f\"回答：{result['answer']}\")\n",
    "    # print(\"对话历史：\", memory.load_memory_variables({}))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62782f0-a996-4461-af2e-3fa4ce304c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (env_rag)",
   "language": "python",
   "name": "env_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

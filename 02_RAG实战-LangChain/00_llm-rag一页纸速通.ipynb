{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db071c0-efa7-48ed-aff7-4ffdc6df6f04",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7097c-0224-4293-8fd6-48e138774c6f",
   "metadata": {},
   "source": [
    "## 单个数据预处理\n",
    "\n",
    "为构建我们的本地知识库，我们需要对以多种类型存储的本地文档进行处理，读取本地文档并通过前文描述的 Embedding 方法将本地文档的内容转化为词向量来构建向量数据库。接下来以一些实际示例入手，来讲解如何对本地文档进行处理。\n",
    "### 数据读取\n",
    "将知识库源数据放置在 data_base/knowledge_db 目录下\n",
    "\n",
    "**PDF文档为例**  \n",
    "可以使用 LangChain 的 PyMuPDFLoader 来读取知识库的 PDF 文件。PyMuPDFLoader 是 PDF 解析器中速度最快的一种，结果会包含 PDF 及其页面的详细元数据，并且每页返回一个文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e736760-dd3c-412c-93e6-fd7d7ccec8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "\n",
    "# 创建一个 PyMuPDFLoader Class 实例，输入为待加载的 pdf 文档路径\n",
    "loader = PyMuPDFLoader(\"data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf\")\n",
    "\n",
    "# 调用 PyMuPDFLoader Class 的函数 load 对 pdf 文件进行加载\n",
    "pdf_pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7cb72-bb72-42fd-91a8-6a1d9665d256",
   "metadata": {},
   "source": [
    "文档加载后储存在 `pdf_pages` 变量中:\n",
    "- `pdf_pages` 的变量类型为 `List`\n",
    "- 打印 `pdf_pages` 的长度可以看到 pdf 一共包含多少页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74838b7c-028d-423d-b5ab-e83b16a8fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入后的变量类型为：<class 'list'>， 该 PDF 一共包含 29 页\n"
     ]
    }
   ],
   "source": [
    "print(f\"载入后的变量类型为：{type(pdf_pages)}，\",  f\"该 PDF 一共包含 {len(pdf_pages)} 页\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5968d8-f894-49e7-be97-29dc053db898",
   "metadata": {},
   "source": [
    "`pdf_pages` 中的每一元素为一个文档，变量类型为 `langchain_core.documents.base.Document`, 文档变量类型包含两个属性\n",
    "- `page_content` 包含该文档的内容。\n",
    "- `meta_data` 为文档相关的描述性数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848c9e07-0074-45e8-9239-53996e22d4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'producer': 'Apache FOP Version 2.6', 'creator': 'DITA Open Toolkit', 'creationdate': '2023-05-23T21:45:33+08:00', 'source': 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf', 'file_path': 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf', 'total_pages': 29, 'format': 'PDF 1.4', 'title': '目录', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20230523214533+08'00'\", 'page': 20}\n",
      "------\n",
      "查看该文档的内容:\n",
      "7 可靠性设计\n",
      "容错能力\n",
      "ZXVMAX-S通过对关键软件资源的定时检测、实时任务监控、存储保护、数据校验、操作日志\n",
      "信息保存等手段，可有效地防止小软件故障对系统所造成的冲击，提高了软件系统的容错能力\n",
      "（即软件错误情况下的自愈能力）。\n",
      "故障监视及处理\n",
      "ZXVMAX-S具备自动检测与诊断系统软硬件故障的功能，可对故障硬件实施自动隔离、倒换、\n",
      "重新启动、重新加载等处理。\n",
      "满足漏洞扫描\n",
      "为了避免存在安全漏洞使在网设备受外部攻击，需要使系统满足主流安全漏洞扫描工具的要求。\n",
      "ZXVMAX-S满足Nessus和CD工具安全漏洞扫描的要求。\n",
      "7.3 数据可靠性\n",
      "ZXVMAX-S产品在不同分层架构下的数据都可以确保数据可靠和可恢复。\n",
      "\n",
      "采集层\n",
      "采集层运行环境部署采用冗余磁盘阵列设计，在服务器损坏、单一硬盘故障等场景下，通过\n",
      "替换故障硬件后即可工作，数据不会丢失。同时，系统支持数据补充采集，确保系统数据连\n",
      "续性。\n",
      "\n",
      "存储共享层\n",
      "存储共享层的MPP数据库，根据需要都设置了多个冗余备份，单一节点的损坏不会影响整系\n",
      "统的运行，也不会导致数据丢失。在替换损坏硬件后，系统能自动进行数据冗余备份的补全\n",
      "和负载均衡。\n",
      "存储共享层的MPP数据库，设计运行在冗余磁盘阵列上，并且是具备双控制器的外置磁阵，\n",
      "在确保性能的同时避免了磁阵数据丢失。\n",
      "\n",
      "应用分析层\n",
      "应用分析层操作系统和软件模块都部署在冗余磁盘阵列上，系统软件、配置数据等信息在单\n",
      "一磁盘损坏，主机故障等情形下都不会丢失。\n",
      "7.4 组网可靠性\n",
      "ZXVMAX-S产品根据需要，可以通过交换机冗余备份，各主机网络的以太网隧道冗余备份，实\n",
      "现对业务和设备的保护。\n",
      "在单一交换机故障时，备用交换机会及时启用，避免业务中断。\n",
      "在单一的网络传输故障时，备用的传输链路仍然生效，也能避免业务中断。\n",
      "SJ-20220623151803-017 | 2023-03-30（R1.0）\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "pdf_page = pdf_pages[20]\n",
    "print(f\"每一个元素的类型：{type(pdf_page)}.\", \n",
    "    f\"该文档的描述性数据：{pdf_page.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{pdf_page.page_content}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fc2d18-6402-4dd5-b904-d2d464dafe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设环境中缺少 NLTK 数据包中的 punkt 资源，这是 NLTK 库中用于分词的一个重要组件。解决这个问题的方法是按照报错信息中提到的步骤下载并安装 punkt 资源。\n",
    "# import nltk\n",
    "# nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b5cb66-5547-449f-84b2-354ea917ff02",
   "metadata": {},
   "source": [
    "### 数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86e288-f363-4bc8-8427-179a30f6ad18",
   "metadata": {},
   "source": [
    "我们期望知识库的数据尽量是有序的、优质的、精简的，因此我们要删除低质量的、甚至影响理解的文本数据。  \n",
    "可以看到上文中读取的pdf文件不仅将一句话按照原文的分行添加了换行符`\\n`，也在原本两个符号中间插入了`\\n`，我们可以使用正则表达式匹配并删除掉`\\n`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3569b6c-1c5c-4f29-b1a4-fc2202a34091",
   "metadata": {},
   "source": [
    "**处理单个page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38cbc84-1f6c-4b2a-ae2c-0972a20ee81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 预编译正则表达式（提升效率）\n",
    "linebreak_pattern = re.compile(\n",
    "    r'(?<![\\\\u4e00-\\\\u9fff])\\n(?![\\\\u4e00-\\\\u9fff])',  # 负向断言匹配非中文环境换行\n",
    "    flags=re.DOTALL\n",
    ")\n",
    "space_pattern = re.compile(r'[ 　]+')  # 匹配半角/全角空格\n",
    "special_chars = ['•', '▪', '▫', '▶', '®', '©']  # 可扩展的干扰符号列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8db982d-0b5e-4eb6-b169-cb0a0a6ad19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7可靠性设计容错能力\\nZXVMAX-S通过对关键软件资源的定时检测、实时任务监控、存储保护、数据校验、操作日志信息保存等手段，可有效地防止小软件故障对系统所造成的冲击，提高了软件系统的容错能力（即软件错误情况下的自愈能力）。故障监视及处理\\nZXVMAX-S具备自动检测与诊断系统软硬件故障的功能，可对故障硬件实施自动隔离、倒换、重新启动、重新加载等处理。满足漏洞扫描为了避免存在安全漏洞使在网设备受外部攻击，需要使系统满足主流安全漏洞扫描工具的要求。\\nZXVMAX-S满足Nessus和CD工具安全漏洞扫描的要求。\\n7.3\\xa0数据可靠性\\nZXVMAX-S产品在不同分层架构下的数据都可以确保数据可靠和可恢复。\\uf06c采集层采集层运行环境部署采用冗余磁盘阵列设计，在服务器损坏、单一硬盘故障等场景下，通过替换故障硬件后即可工作，数据不会丢失。同时，系统支持数据补充采集，确保系统数据连续性。\\uf06c存储共享层存储共享层的MPP数据库，根据需要都设置了多个冗余备份，单一节点的损坏不会影响整系统的运行，也不会导致数据丢失。在替换损坏硬件后，系统能自动进行数据冗余备份的补全和负载均衡。存储共享层的MPP数据库，设计运行在冗余磁盘阵列上，并且是具备双控制器的外置磁阵，在确保性能的同时避免了磁阵数据丢失。\\uf06c应用分析层应用分析层操作系统和软件模块都部署在冗余磁盘阵列上，系统软件、配置数据等信息在单一磁盘损坏，主机故障等情形下都不会丢失。\\n7.4\\xa0组网可靠性\\nZXVMAX-S产品根据需要，可以通过交换机冗余备份，各主机网络的以太网隧道冗余备份，实现对业务和设备的保护。在单一交换机故障时，备用交换机会及时启用，避免业务中断。在单一的网络传输故障时，备用的传输链路仍然生效，也能避免业务中断。\\nSJ-20220623151803-017|2023-03-30（R1.0）\\n17'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_page.page_content = re.sub(\n",
    "        linebreak_pattern,\n",
    "        lambda m: m.group().replace('\\n', ''),\n",
    "        pdf_page.page_content\n",
    "    )\n",
    "    \n",
    "# 2. 批量清理特殊符号\n",
    "for char in special_chars:\n",
    "        pdf_page.page_content = pdf_page.page_content.replace(char, '')\n",
    "    \n",
    "# 3. 安全删除空格（保留URL等特殊场景）\n",
    "pdf_page.page_content = space_pattern.sub('', pdf_page.page_content)\n",
    "\n",
    "pdf_page.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190bf16-9902-4ca7-9bb0-cff57b5e5d85",
   "metadata": {},
   "source": [
    "### 文档分割\n",
    "\n",
    "由于单个文档的长度往往会超过模型支持的上下文，导致检索得到的知识太长超出模型的处理能力，因此，在构建向量知识库的过程中，我们往往需要对文档进行分割，将单个文档按长度或者按固定的规则分割成若干个 chunk，然后将每个 chunk 转化为词向量，存储到向量数据库中。\n",
    "\n",
    "在检索时，我们会以 chunk 作为检索的元单位，也就是每一次检索到 k 个 chunk 作为模型可以参考来回答用户问题的知识，这个 k 是我们可以自由设定的。\n",
    "\n",
    "Langchain 中文本分割器都根据 `chunk_size` (块大小)和 `chunk_overlap` (块与块之间的重叠大小)进行分割。\n",
    "\n",
    "![image.png](../assets/rag8.png)\n",
    "\n",
    "* chunk_size 指每个块包含的字符或 Token （如单词、句子等）的数量\n",
    "\n",
    "* chunk_overlap 指两个块之间共享的字符数量，用于保持上下文的连贯性，避免分割丢失上下文信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215c71d-b0a4-4757-b61a-717f1f0a2485",
   "metadata": {},
   "source": [
    "**Langchain 提供多种文档分割方式，区别在怎么确定块与块之间的边界、块由哪些字符/token组成、以及如何测量块大小**\n",
    "\n",
    "- RecursiveCharacterTextSplitter(): 按字符串分割文本，递归地尝试按不同的分隔符进行分割文本。\n",
    "- CharacterTextSplitter(): 按字符来分割文本。\n",
    "- MarkdownHeaderTextSplitter(): 基于指定的标题来分割markdown 文件。\n",
    "- TokenTextSplitter(): 按token来分割文本。\n",
    "- SentenceTransformersTokenTextSplitter(): 按token来分割文本\n",
    "- Language(): 用于 CPP、Python、Ruby、Markdown 等。\n",
    "- NLTKTextSplitter(): 使用 NLTK（自然语言工具包）按句子分割文本。\n",
    "- SpacyTextSplitter(): 使用 Spacy按句子的切割文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c6d51b-967b-4ecc-b45a-463ff4ef6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* RecursiveCharacterTextSplitter 递归字符文本分割\n",
    "RecursiveCharacterTextSplitter 将按不同的字符递归地分割(按照这个优先级[\"\\n\\n\", \"\\n\", \" \", \"\"])，\n",
    "    这样就能尽量把所有和语义相关的内容尽可能长时间地保留在同一位置\n",
    "RecursiveCharacterTextSplitter需要关注的是4个参数：\n",
    "\n",
    "* separators - 分隔符字符串数组\n",
    "* chunk_size - 每个文档的字符数量限制\n",
    "* chunk_overlap - 两份文档重叠区域的长度\n",
    "* length_function - 长度计算函数\n",
    "'''\n",
    "#导入文本分割器\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b38f2d9-2992-4369-8380-1e76c53bcd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 知识库中单段文本长度\n",
    "CHUNK_SIZE = 512\n",
    "\n",
    "# 知识库中相邻文本重合长度\n",
    "OVERLAP_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e20d373d-23f3-433f-ac9b-7f1199214718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用递归字符文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "# text_splitter.split_text(pdf_page.page_content[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f5dd4e-6ec4-4eaa-85dd-4dc1159c4036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的文件数量：55\n"
     ]
    }
   ],
   "source": [
    "split_docs = text_splitter.split_documents(pdf_pages)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ce8bfa-6e29-4514-8b44-1c8be44150d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10\\xa0遵循标准与要求\\n本章包含如下主题：\\n\\uf06c 运维标准\\n23\\n\\uf06c 安全标准\\n23\\n10.1\\xa0运维标准\\nZXVMAX-S产品符合TMF以下标准：GB923，GB921，GB917，GB922，TR148，TR149\\n10.2\\xa0安全标准\\nZXVMAX-S产品符合以下安全标准：\\n\\uf06c\\nCIS 安全加固标准\\n\\uf06c\\nISO/IEC 15408：信息技术安全评估通用准则（CC，Common Criteria，对应的国标是GB/\\nT 18336）\\n\\uf06c\\nGB/T 18336：信息技术 安全技术 信息技术安全性评估准则\\n\\uf06c\\nUL 60950-1：ed.2/CSA-C22.2 No.60950-1-07:ed.2\\nSJ-20220623151803-017 | 2023-03-30（R1.0）\\n23'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[50].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7aa8f6-f527-44a2-93c3-dea9902ca069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的字符数（可以用来大致评估 token 数）：18934\n"
     ]
    }
   ],
   "source": [
    "print(f\"切分后的字符数（可以用来大致评估 token 数）：{sum([len(doc.page_content) for doc in split_docs])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b25c9-01bc-41c5-8758-e58f1f7fa4b4",
   "metadata": {},
   "source": [
    "注：如何对文档进行分割，其实是数据处理中最核心的一步，其往往决定了检索系统的下限。但是，如何选择分割方式，往往具有很强的业务相关性——针对不同的业务、不同的源数据，往往需要设定个性化的文档分割方式。因此，在本章，我们仅简单根据 chunk_size 对文档进行分割。对于有兴趣进一步探索的读者，欢迎阅读我们第三部分的项目示例来参考已有的项目是如何进行文档分割的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90d129-b037-418b-b2a9-68d52ed1ff71",
   "metadata": {},
   "source": [
    "## 批量数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10bdac-448c-46a7-b0a7-dae2b1f8be63",
   "metadata": {},
   "source": [
    "批量处理文件夹中所有文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c8ff5dd-cf08-44ea-b702-eedc1d731f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（5GC业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）告警处理.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（语音业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（数据业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）故障管理概述.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（端到端业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取folder_path下所有文件路径，储存在file_paths里\n",
    "file_paths = []\n",
    "folder_path = 'data_base/knowledge_path/VMAX-S'\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "print(file_paths)\n",
    "\n",
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "# from langchain.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "# 遍历文件路径并把实例化的loader存放在loaders里\n",
    "loaders = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {file_type} for file {file_path}\")\n",
    "\n",
    "\n",
    "# 下载文件并存储到text\n",
    "# 加载所有文档内容到 texts\n",
    "texts = []\n",
    "for loader in loaders:\n",
    "    texts.extend(loader.load())  # 关键步骤：初始化 texts\n",
    "\n",
    "\n",
    "# 作数据清洗\n",
    "# 修改后的数据清洗部分（替换原始代码中对应段落）\n",
    "import re\n",
    "\n",
    "# 预编译正则表达式（提升效率）\n",
    "linebreak_pattern = re.compile(\n",
    "    r'(?<![\\\\u4e00-\\\\u9fff])\\n(?![\\\\u4e00-\\\\u9fff])',  # 负向断言匹配非中文环境换行\n",
    "    flags=re.DOTALL\n",
    ")\n",
    "space_pattern = re.compile(r'[ 　]+')  # 匹配半角/全角空格\n",
    "special_chars = ['•', '▪', '▫', '▶', '®', '©']  # 可扩展的干扰符号列表\n",
    "\n",
    "# 替换原始代码中的清洗循环\n",
    "for text in texts:\n",
    "    # 1. 清理非中文环境换行\n",
    "    text.page_content = re.sub(\n",
    "        linebreak_pattern,\n",
    "        lambda m: m.group().replace('\\n', ''),\n",
    "        text.page_content\n",
    "    )\n",
    "    \n",
    "    # 2. 批量清理特殊符号\n",
    "    for char in special_chars:\n",
    "        text.page_content = text.page_content.replace(char, '')\n",
    "    \n",
    "    # 3. 安全删除空格（保留URL等特殊场景）\n",
    "    text.page_content = space_pattern.sub('', text.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "911d421d-4371-481d-bee4-235cf27240be",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* RecursiveCharacterTextSplitter 递归字符文本分割\n",
    "RecursiveCharacterTextSplitter 将按不同的字符递归地分割(按照这个优先级[\"\\n\\n\", \"\\n\", \" \", \"\"])，\n",
    "    这样就能尽量把所有和语义相关的内容尽可能长时间地保留在同一位置\n",
    "RecursiveCharacterTextSplitter需要关注的是4个参数：\n",
    "\n",
    "* separators - 分隔符字符串数组\n",
    "* chunk_size - 每个文档的字符数量限制\n",
    "* chunk_overlap - 两份文档重叠区域的长度\n",
    "* length_function - 长度计算函数\n",
    "'''\n",
    "#导入文本分割器\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30df5e18-6ef0-462a-b3b6-c27347863fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 知识库中单段文本长度\n",
    "CHUNK_SIZE = 512\n",
    "\n",
    "# 知识库中相邻文本重合长度\n",
    "OVERLAP_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "904689c2-2ec7-4d03-a93d-ac1b5eaeded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用递归字符文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "# text_splitter.split_text(text.page_content[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10d6c95c-0333-4ce4-9e3a-7a5fa09c3963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的文件数量：891\n"
     ]
    }
   ],
   "source": [
    "split_docs = text_splitter.split_documents(texts)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aadc420-7103-48d1-8489-c887c71ee146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的字符数（可以用来大致评估 token 数）：319269\n"
     ]
    }
   ],
   "source": [
    "print(f\"切分后的字符数（可以用来大致评估 token 数）：{sum([len(doc.page_content) for doc in split_docs])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d36a2de-02c0-46ed-a19d-d55dec3b13c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZXVMAX-S多维价值分析系统告警处理可能原因通过DAPManager查看具体原因并参照其建议处理处理步骤通过DAPManager查看具体原因并参照其建议处理\\n1.120114010081ResourceManager进程MEM使用率告警描述\\nResourceManager进程MEM使用率告警级别可变（对于不同值，会产生相应级别的告警）可能原因内存配置无法满足业务需求。内存使用率达到上限。处理步骤\\n1.修改告警阈值，当内存使用率小于或等于阈值时，告警恢复；\\n2.对节点进行内存扩容；\\n3.收集故障信息，通过菜单日志搜索yarn服务日志，联系技术支持分析日志；\\n1.121114020039NodeManager进程本地空间使用率告警描述\\nNodeManager进程本地空间使用率告警级别可变（对于不同值，会产生相应级别的告警）可能原因\\nYarn空间使用率超过空间告警阈值处理步骤\\n1.修改告警阈值，当空间使用率小于或等于阈值时，告警恢复；\\n2.对节点进行磁盘扩容\\n66\\nSJ-20220623151803-011|2022-06-20（R1.0）'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[300].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0967728-3925-490a-bcb9-749959db9aaf",
   "metadata": {},
   "source": [
    "# 向量数据库搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254db68-acf9-4c5f-aca8-a54868ad915e",
   "metadata": {},
   "source": [
    "### 安装Milvus数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a457ef-648b-4b77-8490-71cd90d96590",
   "metadata": {},
   "source": [
    "Milvus Standalone 是单机服务器部署。Milvus Standalone 的所有组件都打包到一个[Docker 镜像](https://milvus.io/docs/install_standalone-docker.md)中，部署起来非常方便。如果你有生产工作负载，但又不想使用 Kubernetes，那么在内存充足的单机上运行 Milvus Standalone 是一个不错的选择。此外，Milvus Standalone 通过主从复制支持高可用性。\n",
    "\n",
    "**使用 Docker Compose 运行 Milvus (Linux)**\n",
    "\n",
    "Milvus 在 Milvus 资源库中提供了 Docker Compose 配置文件。要使用 Docker Compose 安装 Milvus，只需运行\n",
    "\n",
    "```shell\n",
    "# Download the configuration file\n",
    "$ wget https://bgithub.xyz/milvus-io/milvus/releases/download/v2.5.6/milvus-standalone-docker-compose.yml -O docker-compose.yml\n",
    "\n",
    "# Start Milvus\n",
    "$ sudo docker compose up -d\n",
    "\n",
    "Creating milvus-etcd  ... done\n",
    "Creating milvus-minio ... done\n",
    "Creating milvus-standalone ... done\n",
    "```\n",
    "\n",
    "- 如果运行上述命令失败，请检查系统是否安装了 Docker Compose V1。如果是这种情况，建议你根据[本页](https://docs.docker.com/compose/)的说明迁移到 Docker Compose V2。\n",
    "- 如果您在拉取镜像时遇到任何问题，请通过[community@zilliz.com](mailto:community@zilliz.com)联系我们，并提供有关问题的详细信息，我们将为您提供必要的支持。\n",
    "\n",
    "启动 Milvus 后、\n",
    "\n",
    "- 名为milvus-standalone、milvus-minio和milvus-etcd的容器启动。\n",
    "  - **milvus-etcd**容器不向主机暴露任何端口，并将其数据映射到当前文件夹中的**volumes/etcd**。\n",
    "  - **milvus-minio**容器使用默认身份验证凭据在本地为端口**9090**和**9091**提供服务，并将其数据映射到当前文件夹中的**volumes/minio**。\n",
    "  - **Milvus-standalone**容器使用默认设置为本地**19530**端口提供服务，并将其数据映射到当前文件夹中的**volumes/milvus**。\n",
    "\n",
    "你可以使用以下命令检查容器是否启动并运行：\n",
    "\n",
    "```shell\n",
    "$ sudo docker-compose ps\n",
    "\n",
    "      Name                     Command                  State                            Ports\n",
    "--------------------------------------------------------------------------------------------------------------------\n",
    "milvus-etcd         etcd -advertise-client-url ...   Up             2379/tcp, 2380/tcp\n",
    "milvus-minio        /usr/bin/docker-entrypoint ...   Up (healthy)   9000/tcp\n",
    "milvus-standalone   /tini -- milvus run standalone   Up             0.0.0.0:19530->19530/tcp, 0.0.0.0:9091->9091/tcp\n",
    "```\n",
    "\n",
    "你还可以访问 Milvus WebUI，网址是`http://127.0.0.1:9091/webui/` ，了解有关 Milvus 实例的更多信息。详情请参阅[Milvus WebUI](https://milvus.io/docs/zh/milvus-webui.md)。\n",
    "\n",
    "**停止和删除 Milvus**\n",
    "\n",
    "您可以按以下步骤停止和删除此容器\n",
    "\n",
    "```shell\n",
    "# Stop Milvus\n",
    "$ sudo docker compose down\n",
    "\n",
    "# Delete service data\n",
    "$ sudo rm -rf volumes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911fe1d3-4f0f-452b-b5d5-3fad71a19c19",
   "metadata": {},
   "source": [
    "**Attu（Milvus 图形用户界面）**\n",
    "\n",
    "https://github.com/zilliztech/attu\n",
    "\n",
    "```\n",
    "docker run -p 9092:3000 -e MILVUS_URL=129.201.70.35:19530 zilliz/attu:v2.6\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**milvus使用指南**\n",
    "\n",
    "- [数据库](https://milvus.io/docs/zh/manage_databases.md)\n",
    "- Collections\n",
    "- Schema 和数据字段\n",
    "- 插入和删除\n",
    "- 索引\n",
    "- 搜索和 Rerankers\n",
    "\n",
    "> 参考https://milvus.io/docs/zh/manage_databases.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917dfaf-9ac9-4b5e-918c-60d3819e5ce3",
   "metadata": {},
   "source": [
    "## 前序数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed958b3-6eca-4c42-9396-5b3c2c956af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# 批量处理文件夹中所有文件\n",
    "import os\n",
    "\n",
    "# 获取folder_path下所有文件路径，储存在file_paths里\n",
    "file_paths = []\n",
    "folder_path = 'data_base/knowledge_path/VMAX-S'\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "print(file_paths)\n",
    "\n",
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "# from langchain.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "# 遍历文件路径并把实例化的loader存放在loaders里\n",
    "loaders = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {file_type} for file {file_path}\")\n",
    "\n",
    "# 下载文件并存储到text\n",
    "# 加载所有文档内容到 texts\n",
    "texts = []\n",
    "for loader in loaders:\n",
    "    texts.extend(loader.load())  # 关键步骤：初始化 texts\n",
    "\n",
    "    \n",
    "# 作数据清洗\n",
    "# 修改后的数据清洗部分（替换原始代码中对应段落）\n",
    "import re\n",
    "\n",
    "# 预编译正则表达式（提升效率）\n",
    "linebreak_pattern = re.compile(\n",
    "    r'(?<![\\\\u4e00-\\\\u9fff])\\n(?![\\\\u4e00-\\\\u9fff])',  # 负向断言匹配非中文环境换行\n",
    "    flags=re.DOTALL\n",
    ")\n",
    "space_pattern = re.compile(r'[ 　]+')  # 匹配半角/全角空格\n",
    "special_chars = ['•', '▪', '▫', '▶', '®', '©']  # 可扩展的干扰符号列表\n",
    "\n",
    "# 替换原始代码中的清洗循环\n",
    "for text in texts:\n",
    "    # 1. 清理非中文环境换行\n",
    "    text.page_content = re.sub(\n",
    "        linebreak_pattern,\n",
    "        lambda m: m.group().replace('\\n', ''),\n",
    "        text.page_content\n",
    "    )\n",
    "\n",
    "    # 2. 批量清理特殊符号\n",
    "    for char in special_chars:\n",
    "        text.page_content = text.page_content.replace(char, '')\n",
    "\n",
    "    # 3. 安全删除空格（保留URL等特殊场景）\n",
    "    text.page_content = space_pattern.sub('', text.page_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#导入文本分割器\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "''' \n",
    "* RecursiveCharacterTextSplitter 递归字符文本分割\n",
    "RecursiveCharacterTextSplitter 将按不同的字符递归地分割(按照这个优先级[\"\\n\\n\", \"\\n\", \" \", \"\"])，\n",
    "    这样就能尽量把所有和语义相关的内容尽可能长时间地保留在同一位置\n",
    "RecursiveCharacterTextSplitter需要关注的是4个参数：\n",
    "\n",
    "* separators - 分隔符字符串数组\n",
    "* chunk_size - 每个文档的字符数量限制\n",
    "* chunk_overlap - 两份文档重叠区域的长度\n",
    "* length_function - 长度计算函数\n",
    "'''\n",
    "\n",
    "\n",
    "# 知识库中单段文本长度\n",
    "CHUNK_SIZE = 512\n",
    "\n",
    "# 知识库中相邻文本重合长度\n",
    "OVERLAP_SIZE = 50\n",
    "\n",
    "\n",
    "# 使用递归字符文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "split_docs = text_splitter.split_documents(texts)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"切分后的字符数（可以用来大致评估 token 数）：{sum([len(doc.page_content) for doc in split_docs])}\")\n",
    "\n",
    "\n",
    "\n",
    "split_docs[300].page_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1480401-f378-40ab-9fb5-8ce56dc247e1",
   "metadata": {},
   "source": [
    "预期输出：\n",
    "```bash\n",
    "['data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（5GC业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）告警处理.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（语音业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（数据业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）故障管理概述.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（端到端业务）.pdf', 'data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf']\n",
    "切分后的文件数量：891\n",
    "切分后的字符数（可以用来大致评估 token 数）：319269\n",
    "'ZXVMAX-S多维价值分析系统告警处理可能原因通过DAPManager查看具体原因并参照其建议处理处理步骤通过DAPManager查看具体原因并参照其建议处理\\n1.120114010081ResourceManager进程MEM使用率告警描述\\nResourceManager进程MEM使用率告警级别可变（对于不同值，会产生相应级别的告警）可能原因内存配置无法满足业务需求。内存使用率达到上限。处理步骤\\n1.修改告警阈值，当内存使用率小于或等于阈值时，告警恢复；\\n2.对节点进行内存扩容；\\n3.收集故障信息，通过菜单日志搜索yarn服务日志，联系技术支持分析日志；\\n1.121114020039NodeManager进程本地空间使用率告警描述\\nNodeManager进程本地空间使用率告警级别可变（对于不同值，会产生相应级别的告警）可能原因\\nYarn空间使用率超过空间告警阈值处理步骤\\n1.修改告警阈值，当空间使用率小于或等于阈值时，告警恢复；\\n2.对节点进行磁盘扩容\\n66\\nSJ-20220623151803-011|2022-06-20（R1.0）'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a99092-972a-48fd-b49f-17165784e9b8",
   "metadata": {},
   "source": [
    "## embedding模型准备z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d042dd-fa00-4d27-86eb-a02e194fd913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZhipuAIEmbeddings模型\n",
    "# import os\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# _ = load_dotenv(find_dotenv())\n",
    "\n",
    "# from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "\n",
    "# my_emb = ZhipuAIEmbeddings(\n",
    "#     model=\"embedding-2\",\n",
    "#     api_key = os.environ['ZHIPUAI_API_KEY'],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55728b6-fcef-43c1-b268-274c3a8fdcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "# # 初始化嵌入模型\n",
    "# my_emb = OllamaEmbeddings(\n",
    "#     base_url='http://localhost:11434',\n",
    "#     model=\"bge-m3:latest\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87cad4-1f89-4682-817e-e6ae2dc680f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import XinferenceEmbeddings\n",
    "\n",
    "# 使用API代理服务提高访问稳定性\n",
    "my_emb = XinferenceEmbeddings(\n",
    "    server_url=\"http://129.201.70.35:9997\", \n",
    "    model_uid=\"my_qwen3_embed_0.6b\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dedd5f3-55f0-46e0-9fde-cf1dd40aa5b2",
   "metadata": {},
   "source": [
    "## 构建Milvus向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9eed60-c6a5-49b1-b113-2e7a196f4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# 创建嵌入模型\n",
    "my_emb = XinferenceEmbeddings(\n",
    "    server_url=\"http://129.201.70.35:9997\", \n",
    "    model_uid=\"my_qwen3_embed_0.6b\"\n",
    ")\n",
    "\n",
    "# 向量库创建\n",
    "# connection_args = {\n",
    "#     \"uri\": \"tcp://129.201.70.35:19530\"\n",
    "# }\n",
    "\n",
    "connection_args = {\n",
    "    \"host\": \"129.201.70.35\",\n",
    "    \"port\": 19530,\n",
    "}\n",
    "\n",
    "# 定义每批处理的文档数量\n",
    "batch_size = 30\n",
    "\n",
    "# 如果只想导入部分数据\n",
    "# split_docs = split_docs[:3]\n",
    "try:\n",
    "    # 计算总批次数\n",
    "    total_batches = (len(split_docs) + batch_size - 1) // batch_size\n",
    "    \n",
    "    # 初始化向量数据库（如果是第一次创建）\n",
    "    vectordb = None\n",
    "    \n",
    "    for batch_num in range(total_batches):\n",
    "        # 计算当前批次的起始和结束索引\n",
    "        start_idx = batch_num * batch_size\n",
    "        end_idx = min((batch_num + 1) * batch_size, len(split_docs))\n",
    "        \n",
    "        # 获取当前批次的文档\n",
    "        batch_docs = split_docs[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"正在处理第 {batch_num + 1}/{total_batches} 批文档 (文档 {start_idx}-{end_idx-1})\")\n",
    "\n",
    "        if batch_num == 0:\n",
    "            # 第一次创建向量数据库\n",
    "            vectordb = Milvus.from_documents(\n",
    "            documents=batch_docs,\n",
    "            embedding=my_emb,\n",
    "            collection_name=\"ZXVMAXS1204\",\n",
    "            drop_old=False,\n",
    "            connection_args=connection_args,\n",
    "            )\n",
    "            \n",
    "            # 如果使用Milvus的混合检索\n",
    "            # 创建 Milvus VectorStore，实现 dense + sparse 混合检索 \n",
    "            # vectordb = Milvus.from_documents( \n",
    "            # documents=batch_docs, \n",
    "            # embedding=my_emb, # 用于语义检索的 dense 向量 \n",
    "            # builtin_function=BM25BuiltInFunction(), # BM25 的 sparse 全文检索 \n",
    "            # vector_field=[\"dense\", \"sparse\"], # 指定两个向量字段名称 \n",
    "            # connection_args=connection_args, \n",
    "            # collection_name=\"ZXVMAXS6\",\n",
    "            # consistency_level=\"Strong\", \n",
    "            # drop_old=True, # 若已有旧 collection，可删除重建 \n",
    "            # )\n",
    "\n",
    "        else:\n",
    "            # 后续批次添加到现有集合\n",
    "            vectordb.add_documents(batch_docs)\n",
    "        \n",
    "        # 每批处理后持久化\n",
    "        # vectordb.persist()\n",
    "        print(f\"第 {batch_num + 1} 批文档已成功导入并持久化\")\n",
    "    \n",
    "    print(\"所有文档已成功导入并持久化到向量数据库。\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"处理过程中发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89b38d-99fb-4ea1-a644-0aaf5d94ad72",
   "metadata": {},
   "source": [
    "## 连接数据库进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0868ae-8db3-43d3-82e1-4843c23f5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "\n",
    "my_emb = XinferenceEmbeddings(\n",
    "    server_url=\"http://129.201.70.35:9997\", \n",
    "    model_uid=\"my_qwen3_embed_0.6b\"\n",
    ")\n",
    "\n",
    "# connection_args = {\n",
    "#     \"uri\": \"tcp://129.201.70.35:19530\"\n",
    "# }\n",
    "\n",
    "connection_args = {\n",
    "    \"host\": \"129.201.70.35\",\n",
    "    \"port\": 19530,\n",
    "}\n",
    "# Milvus 连接参数\n",
    "vectordb = Milvus(\n",
    "        embedding_function=my_emb,\n",
    "        collection_name=\"ZXVMAXS1204\",  # Milvus 集合名称\n",
    "        connection_args=connection_args,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d12328-c28a-4b1c-96ac-1412693c567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility\n",
    "\n",
    "def list_all_collections():\n",
    "    \"\"\"获取所有collection列表\"\"\"\n",
    "    try:\n",
    "        # 连接到Milvus（使用与vectordb相同的参数）\n",
    "        connections.connect(\n",
    "            alias=\"default\",\n",
    "            host=\"129.201.70.35\",\n",
    "            port=\"19530\"\n",
    "        )\n",
    "        \n",
    "        # 获取所有collection\n",
    "        collections = utility.list_collections()\n",
    "        print(\"所有Collection列表:\")\n",
    "        for i, coll_name in enumerate(collections, 1):\n",
    "            print(f\"{i}. {coll_name}\")\n",
    "            \n",
    "        return collections\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"获取collection列表失败:\", e)\n",
    "        return []\n",
    "    finally:\n",
    "        # 断开连接\n",
    "        connections.disconnect(\"default\")\n",
    "\n",
    "# 执行\n",
    "collections = list_all_collections()\n",
    "print(f\"总共找到 {len(collections)} 个collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e08174-c4ac-4fc1-a7dc-688a9d51f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试相似性搜索\n",
    "query = \"ZXVMAXS的5G上网日志有那些功能？\"\n",
    "results = vectordb.similarity_search(query, k=2)\n",
    "print(\"相似性搜索结果:\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"结果 {i+1}: {doc.page_content} - 元数据: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a3686-b6fe-4605-aba6-d96bbe44dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取带相似度分数的结果\n",
    "results_with_score = vectordb.similarity_search_with_score(query, k=3)\n",
    "print(\"带分数的搜索结果:\")\n",
    "for doc, score in results_with_score:\n",
    "    print(f\"内容: {doc.page_content}, 分数: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27680c19-1e72-436e-8ddb-023cc0647aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0742bc17-8067-43db-b999-54296bbe8fa7",
   "metadata": {},
   "source": [
    "# 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1f095-cb2d-47b9-ab51-e80c5778ebeb",
   "metadata": {},
   "source": [
    "我们已经介绍了如何根据自己的本地知识文档，搭建一个向量知识库。 在接下来的内容里，我们将使用搭建好的向量数据库，对 query 查询问题进行召回，并将召回结果和 query 结合起来构建 prompt，输入到大模型中进行问答。   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0ad70-1f92-4962-82bd-1b33ecd684c1",
   "metadata": {},
   "source": [
    "## 加载向量数据库\n",
    "\n",
    "首先，我们加载在前一章已经构建的向量数据库。注意，此处你需要使用和构建时相同的 Emedding。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723334a8-14e2-4a5e-a7cf-1feb270d96ed",
   "metadata": {},
   "source": [
    "### Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70825c6c-5353-4fad-985d-f220d389f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "\n",
    "# ollama版本\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# my_emb = OllamaEmbeddings(base_url='http://129.201.70.35:11434', model=\"dengcao/Qwen3-Embedding-0.6B:F16\")\n",
    "\n",
    "# xinference版本\n",
    "from langchain_community.embeddings import XinferenceEmbeddings\n",
    "my_emb = XinferenceEmbeddings(\n",
    "    server_url=\"http://129.201.70.35:9997\", \n",
    "    model_uid=\"my_qwen3_embed_0.6b\"\n",
    ")\n",
    "\n",
    "# Milvus 连接参数\n",
    "vectordb = Milvus(\n",
    "        embedding_function=my_emb,\n",
    "        collection_name=\"ZXVMAXS1204\",  # Milvus 集合名称\n",
    "        connection_args={\n",
    "            \"host\": \"129.201.70.35\",  # Milvus 服务器地址\n",
    "            \"port\": \"19530\",  # Milvus 默认端口\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e3f8a-fb0c-4d1c-a700-de548d18ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectordb.similarity_search(query=\"什么是vmax的上网日志系统？\", k=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88db012-be98-4bf1-acfb-937d7d4571bc",
   "metadata": {},
   "source": [
    "预期输出： \n",
    "```\n",
    "[Document(metadata={'pk': 461017040453077208, 'producer': 'Apache FOP Version 2.6', 'creator': 'DITA Open Toolkit', 'creationdate': '2023-05-23T21:45:33+08:00', 'source': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf', 'file_path': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.23）产品描述（上网日志业务）.pdf', 'total_pages': 29, 'format': 'PDF 1.4', 'title': '目录', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20230523214533+08'00'\", 'page': 13}, page_content='4\\xa0功能本章包含如下主题：\\uf06c上网日志保存\\n10\\n\\uf06c上网日志查询\\n10\\n\\uf06c上网日志批量导入查询\\n11\\n\\uf06c日志管理\\n11\\n\\uf06c账号管理\\n11\\n\\uf06c角色管理\\n12\\n\\uf06c资源监控\\n12\\n\\uf06c告警管理\\n12\\n\\uf06c省级网关对接\\n12\\n\\uf06c拨测结果自动比对功能\\n12\\n\\uf06cNAT日志入库功能\\n13\\n\\uf06c北向接口\\n13\\n\\uf06c上网日志历史查询\\n13\\n\\uf06c云化上网日志XDR查询\\n13\\n以下介绍ZXVMAX-S的主要的功能。\\n4.1\\xa0上网日志保存\\uf06c支持使用Gbase数据库或HDFS保存上网日志。\\uf06c上网日志保存时间可配置，最短保存7天时间，最长可保存一年时间。\\uf06c支持自动清理超过保存时间的上网日志。\\n4.2\\xa0上网日志查询可通过web界面指定查询条件，查询用户上网日志。支持的查询条件：\\uf06c时间范围+公网IP\\n\\uf06c时间范围+目的IP\\n\\uf06c时间范围+MSISDN\\n\\uf06c时间范围+IMSI\\n\\uf06c时间范围+URL\\n\\uf06c支持组合以上五种基础条件，或在基础条件上增加指定公网端口、目的端口，做更精确的查询。\\n10\\nSJ-20220623151803-017|2023-03-30（R1.0）'),\n",
    " Document(metadata={'pk': 461017040453076907, 'producer': 'Apache FOP Version 2.3', 'creator': 'DITA Open Toolkit', 'creationdate': '2022-06-23T16:34:22+08:00', 'source': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）告警处理.pdf', 'file_path': '../data_base/knowledge_path/VMAX-S/ZXVMAX-S（V6.20.80.02）告警处理.pdf', 'total_pages': 330, 'format': 'PDF 1.4', 'title': '目录', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20220623163422+08'00'\", 'page': 297}, page_content='ZXVMAX-S多维价值分析系统告警处理可能原因确保实际填充率达到预期填充率处理步骤确保实际填充率达到预期填充率\\n7.2194000200303HTTP接口下行TCP重传报文数完整率(小时)告警描述确保实际填充率达到预期填充率告警级别警告可能原因确保实际填充率达到预期填充率处理步骤确保实际填充率达到预期填充率\\n7.2204000200304HTTP接口TCP建链响应时延（ms）完整率(小时)告警描述确保实际填充率达到预期填充率告警级别警告可能原因确保实际填充率达到预期填充率处理步骤确保实际填充率达到预期填充率\\n7.2214000200305HTTP接口TCP建链确认时延（ms）完整率(小时)告警描述确保实际填充率达到预期填充率\\n276\\nSJ-20220623151803-011|2022-06-20（R1.0）')]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb55d6-8d30-46bd-91ca-57dd1ac04a66",
   "metadata": {},
   "source": [
    "## 创建一个 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf714ca-9a4a-4535-be6a-75ab6adc9742",
   "metadata": {},
   "source": [
    "在这里，我们调用 OpenAI 的 API 创建一个 LLM，当然你也可以使用其他 LLM 的 API 进行创建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2216cd9-39c1-45de-9992-e9d5a9068df3",
   "metadata": {},
   "source": [
    "### ollama版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2b42b-f4d9-48bd-869a-59332dd92ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama版本\n",
    "from langchain_community.llms import Ollama\n",
    "my_llm = Ollama(base_url='http://localhost:11434', model='qwen3:8B', temperature=0)\n",
    "my_llm.invoke(\"你是谁？/no_think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a518b-0a3e-498c-b629-db49e4fad134",
   "metadata": {},
   "source": [
    "### vllm版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256dacb-db75-4bd0-bcf1-d86ebd04acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 连接信息 - 注意这里的 base_url 需要与你的vLLM服务器地址一致\n",
    "my_llm = ChatOpenAI(\n",
    "    openai_api_key=\"token-abc123\",  # 若服务端无验证，可设为\"EMPTY\"等任意非空字符串\n",
    "    base_url=\"http://129.201.70.35:9991/v1\",  # 你的vLLM服务器地址\n",
    "    model_name=\"my_qwen3_8b\",\n",
    "    temperature=0,\n",
    "    # streaming=True  # 同样支持流式输出\n",
    ")\n",
    "\n",
    "# 调用模型，返回的是AIMessage对象，通过.content获取文本内容\n",
    "result = my_llm.invoke(\"你是谁？/no_think\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42158d-9318-4323-ad83-b5c7d78bf411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 避雷！VLLMOpenAI这个方法问题很多！幻觉严重\n",
    "# from langchain_community.llms import VLLMOpenAI  \n",
    "# my_llm = VLLMOpenAI(\n",
    "#     openai_api_key=\"token-abc123\",          \n",
    "#     openai_api_base=\"http://129.201.70.35:9991/v1\",  \n",
    "#     model_name=\"my_qwen3_8b\",  \n",
    "#     # max_tokens=10240,                \n",
    "#     temperature=0.5,  \n",
    "#     streaming=True                \n",
    "# )\n",
    "# my_llm.invoke(\"你是谁？/no_think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d3a05-786f-42bd-8a0b-c2a3122cff98",
   "metadata": {},
   "source": [
    "### Xinference版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d5ac9-98f7-42db-a8cf-b378011908fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xinference版本\n",
    "from langchain_community.llms import Xinference\n",
    "my_llm = Xinference(\n",
    "    server_url=\"http://129.201.70.35:9997\",\n",
    "    model_uid = \"my_qwen3_14b\", \n",
    "    temperature=0\n",
    ")\n",
    "my_llm.invoke(\"你是谁？/no_think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce05fbd-1a40-4904-981e-beab3c42b083",
   "metadata": {},
   "source": [
    "预期输出： \n",
    "\n",
    "```\n",
    "'<think>\\n嗯，用户发来“你好”，我需要回应。首先，要友好，用中文。然后，可能用户想开始对话，所以应该主动询问他们有什么需要帮助的。保持自然，不要太机械。比如可以说“你好！有什么我可以帮你的吗？”或者更亲切一点，比如“你好呀！今天过得怎么样？有什么我可以协助你的吗？”这样既友好又开放，鼓励用户进一步交流。同时要注意语气，避免过于正式，让对话更轻松。另外，可能用户只是测试，所以需要保持灵活，根据后续回复调整。总之，回应要简洁、友好，引导用户说出具体需求。\\n</think>\\n\\n你好呀！今天过得怎么样？有什么我可以协助你的吗？😊'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa410df-ca2c-4308-87a6-bdfd0d39e1a5",
   "metadata": {},
   "source": [
    "## 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd16bb-6434-41e4-abf1-6f71ea3f703a",
   "metadata": {},
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03ec5c-d7b9-4a28-8c9e-d6895dfd8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 优化后的提示模板\n",
    "template = \"\"\"你是VMAX运维助手，请严格根据以下上下文信息回答问题。\n",
    "\n",
    "上下文：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "请根据上下文直接回答，如果上下文没有提供答案，请说\"我不知道\"。\n",
    "请确保回答的连贯性和唯一性，不要重复相同的信息。\n",
    "最后说\"谢谢你的提问！\"\n",
    "\n",
    "回答：\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde97580-89cc-452b-8580-16edfa14225c",
   "metadata": {},
   "source": [
    "#### 创建一个基于模板的检索链： 基础检索版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c7d6b-38a4-41cf-afc6-751ebf10c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# 优化检索器\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 8,  # 减少返回文档数，提高相关性\n",
    "        \"score_threshold\": 0.75  # 相似度阈值\n",
    "    },\n",
    "    search_type=\"mmr\"\n",
    ")\n",
    "\n",
    "# 创建问答链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    my_llm,\n",
    "    retriever=base_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022966c-4426-4f29-9772-48f2126110cb",
   "metadata": {},
   "source": [
    "## 检索问答链效果测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f6108-19d5-49d8-a020-f7ce5dab7ff1",
   "metadata": {},
   "source": [
    "### 基于召回结果和 query 结合起来构建的 prompt 效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b73129-9121-4c24-b366-a24bb3e4b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "question_1 = \"什么是ZXVMAX-S的5GC业务？\"\n",
    "result = qa_chain.invoke({\"query\": question_1})  # 使用invoke而非call\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])\n",
    "# print(\"\\n来源文档数量：\", len(result[\"source_documents\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87705e66-6ea9-4dba-a56a-672d23e341b0",
   "metadata": {},
   "source": [
    "预期输出： \n",
    "```\n",
    "大模型+知识库后回答 question_1 的结果：\n",
    "\n",
    "\n",
    "ZXVMAX-S的5GC业务是指其针对第五代核心网（5GC）场景设计的运维分析能力，涵盖信令回溯、记录查询、呼叫分析、网络质量分析、业务质量定界、时延分析等功能，支持对用户投诉问题的快速定位（如4G/5G无线、核心网、SP及用户因素分析），以及通过区域感知和用户感知功能对全网或重点区域的性能评估与根因定位。系统采用分层架构（采集层、存储共享层、应用分析层），依赖探针设备采集原始数据并生成XDR格式，为网络优化和故障处理提供支撑。\n",
    "\n",
    "谢谢你的提问！\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48044b-c8d8-4f68-a8fc-c03382788e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"周杰伦是谁？/no_think\"\n",
    "result = qa_chain({\"query\": question_2})\n",
    "print(\"大模型+知识库后回答 question_2 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d8d81-085f-4dd4-bf3b-0db74b3824f9",
   "metadata": {},
   "source": [
    "预期输出： \n",
    "\n",
    "```\n",
    "大模型+知识库后回答 question_2 的结果：\n",
    "\n",
    "\n",
    "我是一个VMAX运维助手，专注于提供与VMAX系统相关的技术支持和信息。关于周杰伦的问题，我无法提供相关信息。谢谢你的提问！\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9a50a-46bf-4dd7-8c4a-02509d6c4996",
   "metadata": {},
   "source": [
    "### 无知识库大模型自己回答的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc66afe-377b-474e-9daf-ea7fbe76d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_1)\n",
    "\n",
    "### 基于大模型的问答\n",
    "my_llm.invoke(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ea178-e25d-4959-ba98-5479856f6097",
   "metadata": {},
   "source": [
    "预期输出：\n",
    "```\n",
    "'<think>\\n\\n</think>\\n\\nZXVMAX-S 是华为推出的一款面向5G网络的虚拟化核心网（5GC）解决方案，其全称是 **ZXVMAX-S 5G Core**。它是一种基于云原生架构的5G核心网业务平台，支持多种5GC业务功能，如：\\n\\n- **UE（用户设备）管理（AMF）**\\n- **会话管理（SMF）**\\n- **接入和移动性管理（AMF）**\\n- **策略控制（PCF）**\\n- **网络切片管理（NSSF）**\\n- **统一数据管理（UDM）**\\n- **服务化接口（NRF）**\\n- **策略控制（PCF）**\\n- **网络暴露功能（NEF）**\\n\\n### ZXVMAX-S 的5GC业务特点：\\n\\n1. **云原生架构**：基于微服务架构，支持灵活扩展和高可用性。\\n2. **多业务支持**：支持多种5G业务场景，如eMBB（增强移动宽带）、URLLC（超可靠低时延通信）、mMTC（大规模机器通信）等。\\n3. **开放接口**：支持与第三方应用、网络切片管理平台、业务链管理平台等进行对接。\\n4. **灵活部署**：支持云化部署（如NFVI）、虚拟化部署（如VNF）和混合部署。\\n5. **高可靠性**：支持多实例冗余、故障自动切换、负载均衡等机制，保障业务连续性。\\n6. **支持网络切片**：支持不同业务场景下的网络切片管理，满足不同行业对网络性能、安全、隔离等的不同需求。\\n\\n### 应用场景：\\n\\n- **工业互联网**：支持高可靠、低时延的工业自动化控制。\\n- **车联网（V2X）**：支持超低时延和高可靠性的车联网通信。\\n- **智慧城市**：支持大规模设备接入和数据处理。\\n- **远程医疗**：支持高带宽、低时延的远程手术和诊断。\\n- **AR/VR**：支持高带宽、低时延的沉浸式体验。\\n\\n### 总结：\\n\\nZXVMAX-S 的5GC业务是华为面向5G时代推出的核心网解决方案，支持多种5G业务功能和场景，具备高可靠性、灵活性和开放性，适用于多种行业和应用场景，是构建5G网络的重要基础设施。'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd3c1b-ca61-4295-92fa-a125ad121dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_2)\n",
    "\n",
    "### 基于大模型的问答\n",
    "my_llm.invoke(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87bf8b6-c490-4001-ae66-865af60197f0",
   "metadata": {},
   "source": [
    "预期输出： \n",
    "\n",
    "```\n",
    "'<think>\\n\\n</think>\\n\\n周杰伦（Jay Chou），1970年1月18日出生于中国台湾省新北市，是中国台湾的著名音乐人、歌手、音乐制作人、导演和演员。他是华语乐坛最具影响力的音乐人之一，以其独特的音乐风格、创新的编曲方式和深情的歌词而闻名。\\n\\n周杰伦的音乐融合了多种元素，包括流行、R&B、嘻哈、中国风、古典音乐等，他的作品常常带有浓厚的东方文化色彩。他不仅在音乐创作上表现出色，还涉足电影导演领域，执导了多部电影，如《不能说的秘密》《天台上的魔幻时刻》等，均获得广泛好评。\\n\\n周杰伦的代表作品包括《七里香》《青花瓷》《菊花台》《告白气球》《听妈妈的话》等，这些歌曲不仅在华语地区广为传唱，也在全球范围内拥有大量粉丝。他多次获得金曲奖等多项音乐大奖，是华语乐坛的标志性人物之一。\\n\\n总的来说，周杰伦不仅是一位才华横溢的音乐人，也是华语流行文化的重要代表人物。'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d37e6-656c-4d47-a9c4-3bdd95c612bb",
   "metadata": {},
   "source": [
    "> ⭐ 通过以上两个问题，我们发现 LLM 对于一些近几年的知识以及非常识性的专业问题，回答的并不是很好。而加上我们的本地知识，就可以帮助 LLM 做出更好的回答。另外，也有助于缓解大模型的“幻觉”问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56088884-369b-451a-94e5-3929c0570c22",
   "metadata": {},
   "source": [
    "## 添加历史对话的记忆功能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194248b2-8dc7-493b-85b2-68a0f67cf89d",
   "metadata": {},
   "source": [
    "现在我们已经实现了通过上传本地知识文档，然后将他们保存到向量知识库，通过将查询问题与向量知识库的召回结果进行结合输入到 LLM 中，我们就得到了一个相比于直接让 LLM 回答要好得多的结果。在与语言模型交互时，你可能已经注意到一个关键问题 - **它们并不记得你之前的交流内容**。这在我们构建一些应用程序（如聊天机器人）的时候，带来了很大的挑战，使得对话似乎缺乏真正的连续性。这个问题该如何解决呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58cf56-9dfb-4cf7-9ac1-17610812b899",
   "metadata": {},
   "source": [
    "### 记忆（Memory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75fe68c-2bfd-4dac-b628-d9237ffcd714",
   "metadata": {},
   "source": [
    "在本节中我们将介绍 LangChain 中的储存模块，即如何将先前的对话嵌入到语言模型中的，使其具有连续对话的能力。我们将使用 `ConversationBufferMemory` ，它保存聊天消息历史记录的列表，这些历史记录将在回答问题时与问题一起传递给聊天机器人，从而将它们添加到上下文中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711d219-cc03-487e-ab75-8fbca96fb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f59ba-b2c9-440f-8a3a-9fd211f099b1",
   "metadata": {},
   "source": [
    "关于更多的 Memory 的使用，包括保留指定对话轮数、保存指定 token 数量、保存历史对话的总结摘要等内容，请参考 langchain 的 Memory 部分的相关文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590ff9c-b2dd-479f-a130-c49a3700a7a8",
   "metadata": {},
   "source": [
    "### 对话检索链（ConversationalRetrievalChain）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45592a2e-0475-4049-bd73-eb3439c200e9",
   "metadata": {},
   "source": [
    "对话检索链（ConversationalRetrievalChain）在检索 QA 链的基础上，增加了处理对话历史的能力。\n",
    "\n",
    "它的工作流程是:\n",
    "1. 将之前的对话与新问题合并生成一个完整的查询语句。\n",
    "2. 在向量数据库中搜索该查询的相关文档。\n",
    "3. 获取结果后,存储所有答案到对话记忆区。\n",
    "4. 用户可在 UI 中查看完整的对话流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c0e94-4e9a-4a75-94d1-9309bbc4012f",
   "metadata": {},
   "source": [
    "这种链式方式将新问题放在之前对话的语境中进行检索，可以处理依赖历史信息的查询。并保留所有信\n",
    "息在对话记忆中，方便追踪。\n",
    "\n",
    "接下来让我们可以测试这个对话检索链的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c28ce7-0961-448a-8be5-b4a40ff038e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "# 修改后的Prompt模板（添加chat_history变量）\n",
    "template = \"\"\"你是VMAX运维助手，请参考以下对话历史和上下文来回答问题：\n",
    "    {chat_history}\n",
    "    \n",
    "    相关上下文：\n",
    "    {context}\n",
    "    \n",
    "    问题：{question}\n",
    "    回答结束时说“谢谢你的提问！”\n",
    "    \"\"\"\n",
    "    \n",
    "QA_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"chat_history\", \"context\", \"question\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "# 创建对话链\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=my_llm,\n",
    "        retriever=vectordb.as_retriever(),\n",
    "        memory=memory,\n",
    "        combine_docs_chain_kwargs={\"prompt\": QA_PROMPT},\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    \n",
    "    # result = qa_chain({\"question\": question})\n",
    "    # return result[\"answer\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c617601-fc16-4042-949f-7707b571048f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d900bbb5-63e9-4f60-97eb-0548da0ae9df",
   "metadata": {},
   "source": [
    "然后基于答案进行下一个问题“为什么这门课需要教这方面的知识？”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1881e4-ed20-43c9-b579-dcbd7c1aabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"什么是ZXVMAX-S的5GC业务？/no_think\",\n",
    "    \"包含哪些功能/no_think\", \n",
    "    \"整理成markdown表格形式/no_think\" \n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"question\": question})  # Pass string directly, not dict\n",
    "    # print(f\"问题：{question}\")\n",
    "    print(f\"回答：{result['answer']}\")\n",
    "    # print(\"对话历史：\", memory.load_memory_variables({}))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db020a-9fa7-44ed-8faa-e24c2cd133f6",
   "metadata": {},
   "source": [
    "预期输出：\n",
    "\n",
    "```\n",
    "\n",
    "回答：\n",
    "\n",
    "ZXVMAX-S的5GC业务是指中兴通讯推出的ZXVMAX-S多维价值分析系统在5G核心网（5GC）场景下的应用。该系统支持对5GC网络中的各种业务数据进行分析，包括性能分析、事件分析、终端分析和业务优化等，帮助用户更好地理解和优化5G网络的运行效率与服务质量。系统采用分层架构，包括采集层、存储共享层和应用分析层，能够根据用户需求进行数据自定义查询和分析，满足不同场景下的运维与管理需求。\n",
    "\n",
    "谢谢你的提问！\n",
    "\n",
    "==================================================\n",
    "\n",
    "回答：\n",
    "\n",
    "ZXVMAX-S的5GC业务包含以下功能：\n",
    "\n",
    "1. **性能分析**：对5GC网络中的性能数据进行分析，帮助识别网络瓶颈，优化网络运行效率。\n",
    "2. **事件分析**：对5GC网络中发生的各类事件进行分析，支持快速定位和处理问题。\n",
    "3. **终端分析**：分析终端设备在5GC网络中的行为和表现，提升用户体验。\n",
    "4. **业务优化**：针对5GC网络中的业务进行优化，提升服务质量与业务运行效率。\n",
    "\n",
    "此外，ZXVMAX-S系统支持根据用户需求进行数据自定义查询和分析，并且可以根据目标用户的需求开启对应权限，部署相应的模块，以满足不同场景下的运维与管理需求。\n",
    "\n",
    "谢谢你的提问！\n",
    "\n",
    "==================================================\n",
    "\n",
    "回答：\n",
    "\n",
    "以下是ZXVMAX-S的5GC业务功能整理成的Markdown表格形式：\n",
    "\n",
    "```markdown\n",
    "| 功能模块       | 功能描述                                                                 |\n",
    "|----------------|--------------------------------------------------------------------------|\n",
    "| 性能分析       | 对5GC网络中的性能数据进行分析，帮助识别网络瓶颈，优化网络运行效率。       |\n",
    "| 事件分析       | 对5GC网络中发生的各类事件进行分析，支持快速定位和处理问题。               |\n",
    "| 终端分析       | 分析终端设备在5GC网络中的行为和表现，提升用户体验。                       |\n",
    "| 业务优化       | 针对5GC网络中的业务进行优化，提升服务质量与业务运行效率。                 |\n",
    "| 数据自定义查询 | 支持根据用户需求进行数据自定义查询和分析，满足不同场景下的运维与管理需求。 |\n",
    "| 权限管理       | 根据目标用户的需求，开启对应权限，部署相应的模块。                         |\n",
    "```\n",
    "\n",
    "谢谢你的提问！\n",
    "\n",
    "==================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3b919-b4d2-436d-8239-7251941eca6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1ccd76-69a4-4b16-a33f-0e5849161797",
   "metadata": {},
   "source": [
    "## 加载向量数据库\n",
    "\n",
    "首先，我们加载在前一章已经构建的向量数据库。注意，此处你需要使用和构建时相同的 Emedding。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ae0df-2e29-418c-99b1-52f563c1418a",
   "metadata": {},
   "source": [
    "设置embedding - zhipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fec4a90-d661-45f0-91a8-c8234fbcdc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_12328\\2576265592.py:5: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from zhipuai_embedding import ZhipuAIEmbeddings\n",
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_12328\\2576265592.py:41: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量数据库已成功加载。\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../C3 搭建知识库\") # 将父目录放入系统路径中\n",
    "\n",
    "# 使用智谱 Embedding API，注意，需要将上一章实现的封装代码下载到本地\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "# 从环境变量中加载你的 API_KEY\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "# zhipuai_api_key\n",
    "\n",
    "# 加载数据库\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings  # 假设这是正确的导入路径\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "# 定义持久化目录\n",
    "persist_directory = '../chromatest'\n",
    "\n",
    "# 创建嵌入模型\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "\n",
    "zhipu_embed = ZhipuAIEmbeddings(\n",
    "    model=\"embedding-2\",\n",
    "    api_key=zhipuai_api_key\n",
    ")\n",
    "\n",
    "try:\n",
    "    # 加载持久化的 Chroma 向量数据库\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,  # 允许我们将persist_directory目录保存到磁盘上\n",
    "        embedding_function=zhipu_embed\n",
    "    )\n",
    "    print(\"向量数据库已成功加载。\")\n",
    "except Exception as e:\n",
    "    print(f\"加载向量数据库时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cafb78-a3d0-48fc-b76a-9a278f6e00f9",
   "metadata": {},
   "source": [
    "从环境变量中加载你的 API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1023dd1-af42-4bb1-b657-f6aa8e0be1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "zhipuai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866e5eb-a0a1-4fef-8d9c-3c0802555b3d",
   "metadata": {},
   "source": [
    "加载向量数据库，其中包含了 ../../data_base/knowledge_db 下多个文档的 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa96942-bcbb-4880-b6b7-1fd49cf75697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义 Embeddings\n",
    "# # embeddings = ZhipuAIEmbeddings()\n",
    "# # embeddings = OpenAIEmbeddings()\n",
    "# embedding = ZhipuAIEmbeddings()\n",
    "\n",
    "# # 向量数据库持久化路径\n",
    "# # persist_directory = '../C3 搭建知识库/data_base/vector_db/chroma'\n",
    "# persist_directory = '../../data_base/vector_db/chroma'\n",
    "# # 加载数据库\n",
    "# vectordb = Chroma(\n",
    "#     persist_directory=persist_directory,  # 允许我们将persist_directory目录保存到磁盘上\n",
    "#     embedding_function=embedding\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2a4cc-efc4-43cd-a1a4-23c46bb794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings  # 假设这是正确的导入路径\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "# 定义持久化目录\n",
    "persist_directory = '../../data_base/vector_db/chroma'\n",
    "\n",
    "# 创建嵌入模型\n",
    "embedding = ZhipuAIEmbeddings()\n",
    "\n",
    "try:\n",
    "    # 加载持久化的 Chroma 向量数据库\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,  # 允许我们将persist_directory目录保存到磁盘上\n",
    "        embedding_function=embedding\n",
    "    )\n",
    "    print(\"向量数据库已成功加载。\")\n",
    "except Exception as e:\n",
    "    print(f\"加载向量数据库时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b17d9-326b-4fc4-ba37-0c418db83469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835138e9-5e87-49b8-aa34-1e5b6a48fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026983d-1c08-44e8-9391-cccc6cf0772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"什么是机器学习?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "print(f\"检索到的内容数：{len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e97ad6-a4f6-41bb-8c25-47f6724a6ed8",
   "metadata": {},
   "source": [
    "打印一下检索到的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aee869-4734-4bfd-b908-f613bb11fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n {doc.page_content}\", end=\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b0c38a-c2b6-4708-81a3-ae3833289790",
   "metadata": {},
   "source": [
    "## 创建一个LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9a806-0e7c-4fc2-903c-2fa55dec3ff7",
   "metadata": {},
   "source": [
    "在这里，我们调用 OpenAI 的 API 创建一个 LLM，当然你也可以使用其他 LLM 的 API 进行创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e55e20-8f5f-457f-ae61-1b79234120a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "zhipuai_llm = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=zhipuai_api_key,\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45017d3-aea1-433b-b59f-f2d8d4e0d555",
   "metadata": {},
   "source": [
    "## 进行问答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f777f24-7e02-414c-afeb-648b025060b3",
   "metadata": {},
   "source": [
    "基于rerank回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec6cd22-6607-45da-802b-dd892e3c60ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_12328\\1207227334.py:7: LangChainDeprecationWarning: The class `CohereRerank` was deprecated in LangChain 0.0.30 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import CohereRerank``.\n",
      "  compressor = CohereRerank(\n",
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_12328\\1207227334.py:27: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='根据您提供的上下文，关于“机器学习”的相关信息分布在几页文档中。其中涉及到的内容包括梯度下降法、牛顿法、线性判别分析以及深度学习的概念等。以下是对这些内容的简要概述，并标明相应的页码：\\n\\n- **梯度下降法**：在文档的第3页，介绍了梯度下降法的概念。[P3]\\n- **牛顿法**：在第3页中，也对牛顿法进行了讲解。[P3]\\n- **线性判别分析**：同样在第3页，涉及线性判别分析的内容。[P3]\\n- **深度学习**：从第4页开始，介绍了深度学习的概念，包括深度学习的起源和特征学习的理解。[P4]\\n\\n这些内容均来源于南瓜书《机器学习公式详解》。如果需要更详细的信息，请参阅对应的纸质版书籍或电子文档。' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 1700, 'total_tokens': 1878, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'glm-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-f5f2fa3a-9da1-42a7-93cf-80e5a71cabf2-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "\n",
    "# Cohere Rerank配置\n",
    "import cohere\n",
    "cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "compressor = CohereRerank(\n",
    "    client=cohere_client,\n",
    "    top_n=5  # 保留Top5相关文档\n",
    ")\n",
    "\n",
    "# 创建带重排序的检索器\n",
    "# base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 15, \"lambda_mult\": 0.5}\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# 5. LLM模型初始化\n",
    "# from openai import OpenAI \n",
    "\n",
    "# llm = OpenAI(\n",
    "#     api_key=\"5713143e8fdc4b4a8b284cf97092e70f.qEK71mGIlavzO1Io\",\n",
    "#     base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "# ) \n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=\"5713143e8fdc4b4a8b284cf97092e70f.qEK71mGIlavzO1Io\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "# 6. 构建RAG链\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 提示模板设计\n",
    "template = \"\"\"基于以下上下文，用中文回答用户问题：\n",
    "上下文：{context}\n",
    "问题：{question}\n",
    "要求：答案需包含引用来源的页码（示例：[P3]）\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 组装RAG链\n",
    "rag_chain = (\n",
    "    {\"context\": compression_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 7. 使用示例\n",
    "response = rag_chain.invoke(\"机器学习\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26a492-97e1-4a66-917f-7c2f1390b6e0",
   "metadata": {},
   "source": [
    "对比norank 和 rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5f8342-e7b4-4f52-a78a-bde4de71dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础检索器（无重排序）\n",
    "base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# 构建RAG链\n",
    "basic_rag_chain = (\n",
    "    {\"context\": base_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c0272b-0403-463d-86c4-9842f1618528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 带重排序的检索器\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=CohereRerank(client=cohere_client, top_n=5),\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# 构建RAG链\n",
    "rerank_rag_chain = (\n",
    "    {\"context\": compression_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b721f6-bcd1-489b-b79f-12f793f91128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 无Rerank的答案 ===\n",
      "content='机器学习的主要应用场景包括但不限于以下几个方面：\\n\\n1. 图像识别与处理：如图像分类、目标检测、图像分割等。[P4]\\n2. 自然语言处理：如文本分类、情感分析、机器翻译、语音识别等。[P4]\\n3. 推荐系统：根据用户的历史行为和偏好，为用户推荐合适的商品、服务等。[P4]\\n4. 数据挖掘：从海量数据中挖掘有价值的信息，如关联规则挖掘、聚类分析等。[P3]\\n5. 语音识别与处理：将语音信号转换为文本信息，应用于语音助手、语音翻译等场景。[P3]\\n6. 生物信息学：如基因序列分析、蛋白质结构预测等。[P3]\\n7. 金融领域：如信用评分、风险管理、股票预测等。[P3]\\n\\n以上仅是部分应用场景，实际上机器学习在许多其他领域也有广泛的应用。引用来源页码为上述文档中的页码。' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 200, 'prompt_tokens': 3257, 'total_tokens': 3457, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'glm-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-240f27f7-08be-4818-b6e7-e5fb5adbbb63-0'\n",
      "\n",
      "=== 带Rerank的答案 ===\n",
      "content='机器学习的主要应用场景包括但不限于以下几个方面：\\n\\n1. 图像识别与处理：如图像分类、目标检测、图像分割等。[P3]\\n2. 自然语言处理：如文本分类、情感分析、机器翻译、语音识别等。[P3]\\n3. 推荐系统：如电商推荐、电影推荐、音乐推荐等。[P3]\\n4. 数据挖掘：如用户行为分析、异常检测、关联规则挖掘等。[P3]\\n5. 语音识别与处理：如语音唤醒、语音助手、语音合成等。[P4]\\n6. 深度学习：在各类应用场景中，深度学习技术都取得了显著的成果，如自动驾驶、医疗诊断、机器人等。[P4]\\n\\n请注意，这里提供的仅是部分应用场景，实际上机器学习可以应用于更多领域。引用来源的页码为上下文中的文档页码。' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 186, 'prompt_tokens': 1712, 'total_tokens': 1898, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'glm-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5de26216-e6ee-4c19-bab3-89e8a702d040-0'\n"
     ]
    }
   ],
   "source": [
    "# 测试同一问题\n",
    "question = \"机器学习的主要应用场景有哪些？\"\n",
    "\n",
    "# 无Rerank的结果\n",
    "basic_response = basic_rag_chain.invoke(question)\n",
    "print(\"=== 无Rerank的答案 ===\")\n",
    "print(basic_response)\n",
    "\n",
    "# 带Rerank的结果\n",
    "rerank_response = rerank_rag_chain.invoke(question)\n",
    "print(\"\\n=== 带Rerank的答案 ===\")\n",
    "print(rerank_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd040ce-0c76-418f-a7ee-8bb9fd2afbdd",
   "metadata": {},
   "source": [
    "打印详细记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdad58fb-2064-44b5-8af5-90baafe599e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rerank前检索结果 ===\n",
      "[文档1] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.1...\n",
      "元数据：页码=4, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档2] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.1...\n",
      "元数据：页码=4, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档3] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.1...\n",
      "元数据：页码=4, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档4] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.1...\n",
      "元数据：页码=4, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档5] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←\n",
      "目录\n",
      "第1章绪论\n",
      "11.1\n",
      "引言................................................1...\n",
      "元数据：页码=2, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档6] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←\n",
      "目录\n",
      "第1章绪论\n",
      "11.1\n",
      "引言................................................1...\n",
      "元数据：页码=2, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档7] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←\n",
      "目录\n",
      "第1章绪论\n",
      "11.1\n",
      "引言................................................1...\n",
      "元数据：页码=2, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档8] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←\n",
      "目录\n",
      "第1章绪论\n",
      "11.1\n",
      "引言................................................1...\n",
      "元数据：页码=2, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档9] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←3.3.1\n",
      "式(3.27)的推导\n",
      ".....................................233.3.2\n",
      "梯度下降...\n",
      "元数据：页码=3, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档10] 相似度分：N/A\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←3.3.1\n",
      "式(3.27)的推导\n",
      ".....................................233.3.2\n",
      "梯度下降...\n",
      "元数据：页码=3, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "\n",
      "=== Rerank后检索结果 ===\n",
      "[文档1] 重排序分：0.98262435\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←3.3.1\n",
      "式(3.27)的推导\n",
      ".....................................233.3.2\n",
      "梯度下降...\n",
      "元数据：页码=3, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档2] 重排序分：0.98262435\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←3.3.1\n",
      "式(3.27)的推导\n",
      ".....................................233.3.2\n",
      "梯度下降...\n",
      "元数据：页码=3, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档3] 重排序分：0.9718326\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.1...\n",
      "元数据：页码=4, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档4] 重排序分：0.9718326\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.1...\n",
      "元数据：页码=4, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "[文档5] 重排序分：0.9718326\n",
      "内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.1...\n",
      "元数据：页码=4, 来源=../data_base/knowledge_path\\pumkin_book\\pumpkin_book.pdf\n",
      "\n",
      "\n",
      "=== 最终答案 ===\n",
      "content='根据提供的上下文，关于“机器学习”的内容可以在以下页面找到：\\n\\n- 页码3：涉及到了南瓜书《机器学习公式详解》中的一些具体内容，如式(3.27)的推导，梯度下降法，牛顿法，以及式(3.29)、(3.30)、(3.31)的解释和推导。\\n- 页码4：包含有关于其他常见神经网络以及深度学习的介绍，解释了什么是深度学习，深度学习的起源，以及如何理解特征学习。\\n\\n因此，如果需要引用来源的页码，可以这样表示：\\n\\n“在南瓜书《机器学习公式详解》中，机器学习相关的概念和算法，如梯度下降法、牛顿法以及深度学习的介绍等，可以在第3页至第4页找到。[P3-P4]”' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 169, 'prompt_tokens': 1697, 'total_tokens': 1866, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'glm-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-32ceaaab-1b44-4f8c-93cd-2c9ffb307d93-0'\n"
     ]
    }
   ],
   "source": [
    "# 在原有代码基础上新增以下对比逻辑\n",
    "\n",
    "# 执行原始检索（无rerank）\n",
    "base_docs = base_retriever.invoke(\"机器学习\")\n",
    "print(\"=== Rerank前检索结果 ===\")\n",
    "for i, doc in enumerate(base_docs):\n",
    "    print(f\"[文档{i+1}] 相似度分：{doc.metadata.get('score', 'N/A')}\")\n",
    "    print(f\"内容摘要：{doc.page_content[:100]}...\")\n",
    "    print(f\"元数据：页码={doc.metadata.get('page', 'N/A')}, 来源={doc.metadata.get('source', 'N/A')}\\n\")\n",
    "\n",
    "# 执行带rerank的检索\n",
    "reranked_docs = compression_retriever.invoke(\"机器学习\")\n",
    "print(\"\\n=== Rerank后检索结果 ===\")\n",
    "for i, doc in enumerate(reranked_docs):\n",
    "    print(f\"[文档{i+1}] 重排序分：{doc.metadata.get('relevance_score', 'N/A')}\")\n",
    "    print(f\"内容摘要：{doc.page_content[:100]}...\")\n",
    "    print(f\"元数据：页码={doc.metadata.get('page', 'N/A')}, 来源={doc.metadata.get('source', 'N/A')}\\n\")\n",
    "\n",
    "# 原有RAG流程保持不变\n",
    "response = rag_chain.invoke(\"机器学习\")\n",
    "print(\"\\n=== 最终答案 ===\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d04887d5-99f9-4c17-9b83-a44bc84b03fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 原始检索结果（MMR算法） ===\n",
      "• 结果1 [页码:4]\n",
      "  相似度分：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "• 结果2 [页码:4]\n",
      "  相似度分：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "• 结果3 [页码:4]\n",
      "  相似度分：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "\n",
      "=== 重排序后结果（Cohere Rerank） ===\n",
      "• 结果1 [页码:3]\n",
      "  相似度分：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←3.3.1\n",
      "式(3.27)的推导\n",
      "................................\n",
      "\n",
      "• 结果2 [页码:4]\n",
      "  相似度分：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "• 结果3 [页码:4]\n",
      "  相似度分：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "\n",
      "=== 优化后的问答结果 ===\n",
      "content='根据提供的知识来源，以下是关于机器学习的相关信息：\\n\\n机器学习的内容包括但不限于梯度下降法、牛顿法、线性判别分析以及深度学习等概念。[P3] \\n\\n- 梯度下降法在文献中的介绍位于第3.3.2节。[P3]\\n- 牛顿法的相关内容则在第3.3.3节。[P3]\\n- 线性判别分析的相关推导可以在第3.4节找到。[P3]\\n  \\n另外，还有关于其他常见神经网络以及深度学习的讨论：\\n\\n- 在第5.5节中，有对其他常见神经网络的相关解释，如式(5.18)、(5.20)、(5.22)和(5.23)的解释。[P4]\\n- 深度学习部分，包括什么是深度学习、深度学习的起源以及如何理解特征学习等，这些内容在第5.6节中有所阐述。[P4]\\n\\n以上信息没有明显的矛盾，各来源在内容上相互补充。\\n\\n---\\n\\n请注意，以上内容按照Markdown格式组织，并在合适的位置标注了页码来源。如果需要更详细的解释或其他具体信息，请告知，我会继续补充。' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 1734, 'total_tokens': 1980, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'glm-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-fbbd62dd-5837-4b98-a493-281bbbac83e6-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import cohere\n",
    "\n",
    "# ----------------- 改进点1：增强元数据处理 -----------------\n",
    "def format_document_metadata(docs):\n",
    "    \"\"\"为文档添加规范化元数据（参考网页1的注释规范）\"\"\"\n",
    "    for doc in docs:\n",
    "        if 'page' not in doc.metadata:\n",
    "            doc.metadata['page'] = 'P0'  # 默认页码\n",
    "        if 'source' not in doc.metadata:\n",
    "            doc.metadata['source'] = 'unknown'\n",
    "    return docs\n",
    "\n",
    "# ----------------- 改进点2：优化检索配置 -----------------\n",
    "def init_retrievers(vector_db):\n",
    "    \"\"\"初始化带/不带rerank的检索器（参考网页6的检索器配置）\"\"\"\n",
    "    # 基础检索器（MMR算法平衡多样性）\n",
    "    base_retriever = vector_db.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 10, \"lambda_mult\": 0.3}\n",
    "    )\n",
    "    \n",
    "    # Cohere重排序配置（参考网页8的检索优化）\n",
    "    cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "    compressor = CohereRerank(client=cohere_client, top_n=5)\n",
    "    \n",
    "    # 带重排序的检索器\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=base_retriever\n",
    "    )\n",
    "    \n",
    "    return base_retriever, compression_retriever\n",
    "\n",
    "# ----------------- 改进点3：增强结果可视化 -----------------\n",
    "def print_retrieval_results(retriever, query, title):\n",
    "    \"\"\"打印检索结果（含元数据展示，参考网页4的格式化输出）\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    formatted_docs = format_document_metadata(docs)\n",
    "    \n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for i, doc in enumerate(formatted_docs[:3]):  # 展示Top3结果\n",
    "        print(f\"• 结果{i+1} [页码:{doc.metadata['page']}]\")\n",
    "        print(f\"  相似度分：{doc.metadata.get('score', 0):.2f}\")\n",
    "        print(f\"  内容摘要：{doc.page_content[:80]}...\\n\")\n",
    "\n",
    "# ----------------- 主执行流程 -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化组件\n",
    "    base_retriever, rerank_retriever = init_retrievers(vectordb)\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"glm-4\",\n",
    "        temperature=0.7,  # 调整生成稳定性（参考网页5的温度系数建议）\n",
    "        openai_api_key=\"5713143e8fdc4b4a8b284cf97092e70f.qEK71mGIlavzO1Io\",\n",
    "        openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    )\n",
    "    \n",
    "    # 打印检索对比结果\n",
    "    query = \"机器学习\"\n",
    "    print_retrieval_results(base_retriever, query, \"原始检索结果（MMR算法）\")\n",
    "    print_retrieval_results(rerank_retriever, query, \"重排序后结果（Cohere Rerank）\")\n",
    "    \n",
    "    # ----------------- 改进点4：增强提示工程 -----------------\n",
    "    prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "    基于以下上下文，用中文回答用户问题：\n",
    "    [知识来源]\n",
    "    {context}\n",
    "    \n",
    "    [回答要求]\n",
    "    1. 答案需包含引用来源的页码（示例：[P3]）\n",
    "    2. 若存在矛盾信息，请说明各来源差异\n",
    "    3. 使用Markdown格式组织内容\n",
    "    \n",
    "    当前问题：{question}\n",
    "    \"\"\")\n",
    "    \n",
    "    # 构建RAG链（参考网页7的Runnable组合方式）\n",
    "    rag_chain = (\n",
    "        {\"context\": rerank_retriever, \"question\": RunnablePassthrough()} \n",
    "        | prompt_template \n",
    "        | llm\n",
    "    )\n",
    "    \n",
    "    # 执行问答\n",
    "    print(\"\\n=== 优化后的问答结果 ===\")\n",
    "    print(rag_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e4ea47-5fe4-4599-be3b-36f64d345ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 原始检索结果（Chroma MMR） ===\n",
      "• 结果1 [页码:4]\n",
      "  向量相似度：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "• 结果2 [页码:4]\n",
      "  向量相似度：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "• 结果3 [页码:4]\n",
      "  向量相似度：0.00\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "\n",
      "=== 重排序后结果（Cohere Rerank） ===\n",
      "• 结果1 [页码:3]\n",
      "  向量相似度：0.00\n",
      "  语义重排分：0.98\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←3.3.1\n",
      "式(3.27)的推导\n",
      "................................\n",
      "\n",
      "• 结果2 [页码:4]\n",
      "  向量相似度：0.00\n",
      "  语义重排分：0.97\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "• 结果3 [页码:4]\n",
      "  向量相似度：0.00\n",
      "  语义重排分：0.97\n",
      "  内容摘要：→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "....................................\n",
      "\n",
      "\n",
      "=== 优化后的问答结果 ===\n",
      "content='根据提供的上下文信息，关于机器学习的内容可以在南瓜书《机器学习公式详解》中找到。以下是相关信息：\\n\\n- [P3] 介绍了式(3.27)的推导，梯度下降法，牛顿法，以及式(3.29)、式(3.30)、式(3.31)的解释和推导。\\n- [P4] 涉及了其他常见神经网络，式(5.18)、式(5.20)、式(5.22)、式(5.23)的解释，以及深度学习的概念，包括深度学习的起源和特征学习的理解。\\n\\n目前没有发现冲突信息需要说明来源差异。如果需要更详细的信息，请告知具体想要了解的部分。' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 1716, 'total_tokens': 1866, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'glm-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-96e5d9b5-c08c-460d-be15-974c16c571fa-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import cohere\n",
    "\n",
    "# ----------------- Chroma专属配置 -----------------\n",
    "def chroma_score_converter(docs):\n",
    "    \"\"\"将Chroma的距离值转换为相似度分数（余弦距离→相似度）\"\"\"\n",
    "    for doc in docs:\n",
    "        if 'distances' in doc.metadata:\n",
    "            # Chroma的余弦距离计算式为 1 - cosine_similarity\n",
    "            distance = doc.metadata['distances'][0]  # 取第一个距离值\n",
    "            doc.metadata['score'] = 1 - distance  # 转换为相似度分数\n",
    "    return docs\n",
    "\n",
    "# ----------------- 改进点1：增强元数据处理 -----------------\n",
    "def format_document_metadata(docs):\n",
    "    \"\"\"为文档添加规范化元数据\"\"\"\n",
    "    docs = chroma_score_converter(docs)  # 先转换分数\n",
    "    for doc in docs:\n",
    "        if 'page' not in doc.metadata:\n",
    "            doc.metadata['page'] = 'P0'\n",
    "        if 'source' not in doc.metadata:\n",
    "            doc.metadata['source'] = 'unknown'\n",
    "    return docs\n",
    "\n",
    "# ----------------- 改进点2：优化检索配置 -----------------\n",
    "def init_retrievers(vector_db):\n",
    "    \"\"\"初始化带/不带rerank的检索器（Chroma专属配置）\"\"\"\n",
    "    # Chroma检索器需显式请求距离值\n",
    "    base_retriever = vector_db.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 10,\n",
    "            \"lambda_mult\": 0.3,\n",
    "            \"include\": [\"distances\"]  # 关键配置：获取距离信息\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Cohere重排序配置\n",
    "    cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "    compressor = CohereRerank(client=cohere_client, top_n=5)\n",
    "    \n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=base_retriever\n",
    "    )\n",
    "    \n",
    "    return base_retriever, compression_retriever\n",
    "\n",
    "# ----------------- 改进点3：增强结果可视化 -----------------\n",
    "def print_retrieval_results(retriever, query, title):\n",
    "    \"\"\"打印检索结果（适配Chroma的分数格式）\"\"\"\n",
    "    raw_docs = retriever.invoke(query)\n",
    "    processed_docs = format_document_metadata(raw_docs)\n",
    "    \n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for i, doc in enumerate(processed_docs[:3]):\n",
    "        print(f\"• 结果{i+1} [页码:{doc.metadata['page']}]\")\n",
    "        print(f\"  向量相似度：{doc.metadata.get('score', 0):.2f}\")\n",
    "        if 'relevance_score' in doc.metadata:\n",
    "            print(f\"  语义重排分：{doc.metadata['relevance_score']:.2f}\")\n",
    "        print(f\"  内容摘要：{doc.page_content[:80]}...\\n\")\n",
    "\n",
    "# ----------------- 主执行流程 -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化组件（假设vectordb已正确初始化）\n",
    "    base_retriever, rerank_retriever = init_retrievers(vectordb)\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"glm-4\",\n",
    "        temperature=0.7,\n",
    "        openai_api_key=\"5713143e8fdc4b4a8b284cf97092e70f.qEK71mGIlavzO1Io\",\n",
    "        openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    )\n",
    "    \n",
    "    # 打印对比结果\n",
    "    query = \"机器学习\"\n",
    "    print_retrieval_results(base_retriever, query, \"原始检索结果（Chroma MMR）\")\n",
    "    print_retrieval_results(rerank_retriever, query, \"重排序后结果（Cohere Rerank）\")\n",
    "    \n",
    "    # 构建RAG链\n",
    "    prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "    基于以下上下文，用中文回答用户问题：\n",
    "    [知识来源]\n",
    "    {context}\n",
    "    \n",
    "    [回答要求]\n",
    "    1. 包含引用页码（示例：[P3]）\n",
    "    2. 冲突信息需说明来源差异\n",
    "    \n",
    "    当前问题：{question}\n",
    "    \"\"\")\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": rerank_retriever, \"question\": RunnablePassthrough()} \n",
    "        | prompt_template \n",
    "        | llm\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== 优化后的问答结果 ===\")\n",
    "    print(rag_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a3a76-881d-4537-b508-5e93f7c7e5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

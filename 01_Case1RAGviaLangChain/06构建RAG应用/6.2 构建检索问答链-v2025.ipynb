{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c794bc7",
   "metadata": {},
   "source": [
    "# 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0f2c3-3bd9-4de1-bbd2-e0e2b09161c8",
   "metadata": {},
   "source": [
    "我们已经介绍了如何根据自己的本地知识文档，搭建一个向量知识库。 在接下来的内容里，我们将使用搭建好的向量数据库，对 query 查询问题进行召回，并将召回结果和 query 结合起来构建 prompt，输入到大模型中进行问答。   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8d968-8d98-47b9-8885-dc17d24dce76",
   "metadata": {},
   "source": [
    "## 1. 加载向量数据库\n",
    "\n",
    "首先，我们加载在前一章已经构建的向量数据库。注意，此处你需要使用和构建时相同的 Emedding。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7affbed-f36e-4700-a1d9-c5d88917fff5",
   "metadata": {},
   "source": [
    "设置embedding - zhipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f66d376-8140-4224-bdfb-360b60aef43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量数据库已成功加载。\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../C3 搭建知识库\") # 将父目录放入系统路径中\n",
    "\n",
    "# 使用智谱 Embedding API，注意，需要将上一章实现的封装代码下载到本地\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "# 从环境变量中加载你的 API_KEY\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "# zhipuai_api_key\n",
    "\n",
    "# 加载数据库\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings  # 假设这是正确的导入路径\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "# 定义持久化目录\n",
    "persist_directory = '../chroma-will'\n",
    "\n",
    "# 创建嵌入模型\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "\n",
    "zhipu_embed = ZhipuAIEmbeddings(\n",
    "    model=\"embedding-2\",\n",
    "    api_key=zhipuai_api_key\n",
    ")\n",
    "\n",
    "try:\n",
    "    # 加载持久化的 Chroma 向量数据库\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,  # 允许我们将persist_directory目录保存到磁盘上\n",
    "        embedding_function=zhipu_embed\n",
    "    )\n",
    "    print(\"向量数据库已成功加载。\")\n",
    "except Exception as e:\n",
    "    print(f\"加载向量数据库时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b0b1838-38a3-4666-8bc8-c4592a5a39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：20\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f5912d3d-9517-465c-8b82-cdd1eab27a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：20\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8a68dc0-4f4c-433b-a367-44b5cffe8516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：15\n"
     ]
    }
   ],
   "source": [
    "question = \"什么是机器学习?\"\n",
    "docs = vectordb.similarity_search(question,k=15)\n",
    "print(f\"检索到的内容数：{len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09852d2a-aeda-4822-bf56-782a0397df3c",
   "metadata": {},
   "source": [
    "打印一下检索到的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2f492bf-197b-4f94-820c-2d88c17754d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      " 欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》其他常见神经网络式的解释式的解释式的解释式的解释深度学习什么是深度学习深度学习的起源\n",
      "-----------------------------------------------------\n",
      "检索到的第1个内容: \n",
      " 欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》目录第章绪论引言基本术语假设空间归纳偏好式和式的解释第章模型评估与选择经验误差与过拟合评估方法算法参数超参数与模型参数\n",
      "-----------------------------------------------------\n",
      "检索到的第2个内容: \n",
      " 欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》式的推导梯度下降法牛顿法式的解释式的推导式的推导线性判别分析式的推导\n",
      "-----------------------------------------------------\n",
      "检索到的第3个内容: \n",
      " 前言周志华老师的《机器学习》西瓜书是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读者通过西瓜书对机器学习有所了解所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推导细节的读者来说可能不太友好，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充具体的推导细节。读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周老师之所以省去这些推导细节的真实原因是，他本尊认为理工科数学基础扎实点的大二下学生应该对西瓜书中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习。所以本南瓜书只能算是我等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的理工科数学基础扎实点的大二下学生。使用说明南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；对于初学机器学习的小白，西瓜书第章和第章的公式强烈不建议深究，简单过一下即可，等你学得有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力争\n",
      "-----------------------------------------------------\n",
      "检索到的第4个内容: \n",
      " 式的解释多变量决策树图的解释图的解释第章神经网络神经元模型感知机与多层网络式和式的推导图的解释误差逆传播算法\n",
      "-----------------------------------------------------\n",
      "检索到的第5个内容: \n",
      " 式到式的推导第章线性模型基本形式线性回归属性数值化式的解释式的推导式的推导式的推导式的推导\n",
      "-----------------------------------------------------\n",
      "检索到的第6个内容: \n",
      " 式到式的推导式的推导式的推导式的推导多分类学习图的解释类别不平衡问题第章决策树基本流程划分选择\n",
      "-----------------------------------------------------\n",
      "检索到的第7个内容: \n",
      " 软间隔与正则化式式和式的推导式式对数几率回归与支持向量机的关系式的解释支持向量回归式的解释\n",
      "-----------------------------------------------------\n",
      "检索到的第8个内容: \n",
      " 怎么理解特征学习第章支持向量机间隔与支持向量图的解释式的解释式的推导式的推导式的推导式的解释对偶问题\n",
      "-----------------------------------------------------\n",
      "检索到的第9个内容: \n",
      " 式的推导式的推导对数几率回归配套视频教程：\n",
      "-----------------------------------------------------\n",
      "检索到的第10个内容: \n",
      " 验证集性能度量式到式的解释式和式的解释图的解释式的推导式的解释式到式的解释式和式的解释\n",
      "-----------------------------------------------------\n",
      "检索到的第11个内容: \n",
      " 深究，简单过一下即可，等你学得有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力争以本科数学基础的视角进行讲解，所以超纲的数学知识我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们的\n",
      "-----------------------------------------------------\n",
      "检索到的第12个内容: \n",
      " 式的推导式的推导式的推导式的推导式的推导全局最小与局部极小配套视频教程：\n",
      "-----------------------------------------------------\n",
      "检索到的第13个内容: \n",
      " 凸优化问题条件拉格朗日对偶函数拉格朗日对偶问题式和式的推导式的推导式的解释核函数式的解释\n",
      "-----------------------------------------------------\n",
      "检索到的第14个内容: \n",
      " 式的推导式的推导核方法式和式的解释式的推导式和式的解释式的推导核对数几率回归配套视频教程：\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n {doc.page_content}\", end=\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f8dbd-ecd5-449d-9753-aedc2b74289c",
   "metadata": {},
   "source": [
    "## 2. 创建一个 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bd74f-3dd0-496e-905b-950a444bb7a7",
   "metadata": {},
   "source": [
    "在这里，我们调用 OpenAI 的 API 创建一个 LLM，当然你也可以使用其他 LLM 的 API 进行创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7fe25e4-e98e-4cb7-ac95-40e0e7b14ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "zhipuai_llm = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=zhipuai_api_key,\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f361e27-cafb-48bf-bb41-50c9cb3a4f7e",
   "metadata": {},
   "source": [
    "## 3. 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b5e3c-1bc9-40e9-83c7-0594c2e7727d",
   "metadata": {},
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91be03f4-264d-45cb-bebd-223c1c5747fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"],\n",
    "                                 template=template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d06d7f-1dca-4d10-b5cd-3a23e9d91200",
   "metadata": {},
   "source": [
    "#### 创建一个基于模板的检索链： 基础检索版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b05eb57-edf5-4b35-9538-42c2b8f5cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 基础检索\n",
    "base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 15},  # 扩大召回池\n",
    "    search_type=\"mmr\",  # 最大边际相关性算法（网页5）\n",
    "    metadata_filter={\"source\": \"权威文档.pdf\"}  # 元数据过滤\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(zhipuai_llm,\n",
    "                                       retriever=base_retriever,\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fa1a61eb-feea-4fff-8063-a20c3b392aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_1 的结果：\n",
      "？\n",
      "\n",
      "这是一本关于机器学习的辅助教材，旨在帮助读者理解周志华老师的《机器学习》（西瓜书）中的公式和概念。\n",
      "\n",
      "这本书特别感谢了早期对南瓜书做出贡献的人。\n",
      "\n",
      "读者可以通过扫描二维码加入南瓜书的交流群。\n",
      "\n",
      "版权声明表示这本书遵循知识共享署名非商业性使用相同方式共享国际许可协议。\n",
      "\n",
      "南瓜书建议读者在遇到难以理解的公式时，以西瓜书为主线，辅以南瓜书。\n",
      "\n",
      "对于初学者，不建议深入探究西瓜书中的某些章节公式，可以先简单了解，以后再深入研究。\n",
      "\n",
      "南瓜书力求以本科生数学基础的角度解释公式，并在必要时提供额外的资料。\n",
      "\n",
      "如果南瓜书中有错误或缺少内容，作者鼓励读者积极反馈。\n",
      "\n",
      "谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "question_1 = \"什么是南瓜书？\"\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b68384-e2ac-482b-ae87-f94dc1345e5e",
   "metadata": {},
   "source": [
    "### 创建一个基于模板的检索链： BM25检索版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8d33b-ffcd-4def-9bf7-d36d068b0b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c08ac734-6693-422d-97e1-50f140e2d358",
   "metadata": {},
   "source": [
    "### 创建一个基于模板的检索链： rerank检索版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e2347f57-a191-4580-bd3f-e5623e17ae8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='27c295c4-f96b-4e63-889f-9707b246f31c' results=[RerankResponseResultsItem(document=None, index=3, relevance_score=0.8742601), RerankResponseResultsItem(document=None, index=0, relevance_score=0.17292508), RerankResponseResultsItem(document=None, index=4, relevance_score=0.10793502)] meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=None, output_tokens=None, search_units=1.0, classifications=None), tokens=None, warnings=None)\n"
     ]
    }
   ],
   "source": [
    "# 测试API\n",
    "\n",
    "import cohere\n",
    "# co = cohere.ClientV2()\n",
    "co = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "docs = [\n",
    "    \"Carson City is the capital city of the American state of Nevada.\",\n",
    "    \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan.\",\n",
    "    \"Capitalization or capitalisation in English grammar is the use of a capital letter at the start of a word. English usage varies from capitalization in other languages.\",\n",
    "    \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district.\",\n",
    "    \"Capital punishment has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
    "]\n",
    "response = co.rerank(\n",
    "    model=\"rerank-v3.5\",\n",
    "    query=\"What is the capital of the United States?\",\n",
    "    documents=docs,\n",
    "    top_n=3,\n",
    ")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "24c893eb-3a30-40c1-9b60-dc6d448ea1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "# rerank检索\n",
    "# Cohere Rerank配置\n",
    "import cohere\n",
    "cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "\n",
    "compressor = CohereRerank(\n",
    "    client=cohere_client,\n",
    "    top_n=5,\n",
    "    model=\"rerank-multilingual-v3.0\"  # 支持多语言的新版本\n",
    ")\n",
    "\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 15},  # 扩大召回池\n",
    "    search_type=\"mmr\",  # 最大边际相关性算法（网页5）\n",
    "    # metadata_filter={\"source\": \"权威文档.pdf\"}  # 元数据过滤\n",
    ")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    zhipuai_llm,\n",
    "    retriever=compression_retriever,  # 替换为压缩检索器\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_CHAIN_PROMPT,\n",
    "        # \"llm_kwargs\": {\"max_length\": 300}  # 新增输出长度限制\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a7972-a673-41ca-a028-647169d19fcb",
   "metadata": {},
   "source": [
    "## 4.检索问答链效果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a610e223-64c2-4865-b049-b47a36262a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"什么是南瓜书？\"\n",
    "question_2 = \"严威是谁？\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2223f-6fb5-4504-bfcd-ac74ca9ff2fa",
   "metadata": {},
   "source": [
    "### 4.1 基于召回结果和 query 结合起来构建的 prompt 效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1eb5c5c3-9958-44f5-9fbc-f867de6c5042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_1 的结果：\n",
      "南瓜书是针对周志华老师《机器学习》西瓜书中一些难理解公式和推导细节的补充解析，是数学基础较弱的读者在自学时整理的笔记，旨在帮助读者更好地理解和学习机器学习相关公式。它建议与西瓜书结合使用，遇到难以推导或理解的公式时查阅。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "37a0f3c4-4c50-4b73-a4b3-674825a366f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_2 的结果：\n",
      "我不知道严威是谁，这个信息在提供的上下文中没有提及。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question_2})\n",
    "print(\"大模型+知识库后回答 question_2 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4195cfa-1fc8-41a9-8984-91f2e5fbe013",
   "metadata": {},
   "source": [
    "### 4.2 大模型自己回答的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "569fbe28-2e2d-4042-b3a1-65326842bdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_9320\\1697173039.py:5: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  zhipuai_llm.predict(prompt_template)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'南瓜书（Pumpkin Book）通常不是一个广为人知的标准名词，它可能指代不同的内容，具体含义取决于上下文。以下是几种可能的解释：\\n\\n1. **儿童书籍**：可能是指一本以南瓜为主题的儿童读物，这样的书籍通常会在万圣节前后出现，讲述与南瓜有关的故事或活动。\\n\\n2. **食谱书**：也可能是一本介绍如何制作南瓜相关菜肴的烹饪书籍，例如南瓜派、南瓜汤等。\\n\\n3. **园艺指导书**：关于如何种植和培育南瓜的园艺指南。\\n\\n4. **艺术作品或手工书**：一些书籍可能会教人如何雕刻南瓜灯或制作与南瓜相关的手工艺品。\\n\\n5. **特定文化或传统的参考书籍**：在某些文化中，南瓜可能具有重要的象征意义，相关的书籍可能会探讨这些含义。\\n\\n6. **网络流行文化**：在现代互联网文化中，“南瓜书”可能是某个特定的梗或者某个社区内的特定称谓。\\n\\n如果您是在特定的上下文中遇到“南瓜书”这个词，提供更多的信息可以帮助给出更准确的解释。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_1)\n",
    "\n",
    "### 基于大模型的问答\n",
    "zhipuai_llm.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0d3a813-db19-4be5-8926-ad8298e3e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很抱歉，根据我截至2023的知识库，\"严威\"这个名字并不足以确定是指哪位具体的人物。严威可能是一个普通的姓名，没有在公开的知名人物数据库或新闻报道中找到与之相关的显著信息。\\n\\n如果严威是一个特定领域的专家、学者或者其他类型的人物，并且您正在寻找关于此人的具体信息，请提供更多的上下文或者详细背景，这样我可能能够提供更准确的帮助。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_2)\n",
    "\n",
    "### 基于大模型的问答\n",
    "zhipuai_llm.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9ba4a-053d-409a-a632-63336c2bdf84",
   "metadata": {},
   "source": [
    "> ⭐ 通过以上两个问题，我们发现 LLM 对于一些近几年的知识以及非常识性的专业问题，回答的并不是很好。而加上我们的本地知识，就可以帮助 LLM 做出更好的回答。另外，也有助于缓解大模型的“幻觉”问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20c510-f583-42b4-ac5c-b232388e9673",
   "metadata": {},
   "source": [
    "## 5. 添加历史对话的记忆功能-v2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e43e5-262d-4358-afb4-129dbf413287",
   "metadata": {},
   "source": [
    "现在我们已经实现了通过上传本地知识文档，然后将他们保存到向量知识库，通过将查询问题与向量知识库的召回结果进行结合输入到 LLM 中，我们就得到了一个相比于直接让 LLM 回答要好得多的结果。在与语言模型交互时，你可能已经注意到一个关键问题 - **它们并不记得你之前的交流内容**。这在我们构建一些应用程序（如聊天机器人）的时候，带来了很大的挑战，使得对话似乎缺乏真正的连续性。这个问题该如何解决呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadc3df-4123-4e12-9516-8632b10dc41f",
   "metadata": {},
   "source": [
    "### 5.1 记忆（Memory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f3fd2-14de-4177-893c-53ddaf6768e9",
   "metadata": {},
   "source": [
    "在本节中我们将介绍 LangChain 中的储存模块，即如何将先前的对话嵌入到语言模型中的，使其具有连续对话的能力。我们将使用 `ConversationBufferMemory` ，它保存聊天消息历史记录的列表，这些历史记录将在回答问题时与问题一起传递给聊天机器人，从而将它们添加到上下文中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42210b88-3590-47dc-a087-ab9cef14f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_9320\\2228008247.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d580d9-b926-462f-9d6a-23135ecece37",
   "metadata": {},
   "source": [
    "关于更多的 Memory 的使用，包括保留指定对话轮数、保存指定 token 数量、保存历史对话的总结摘要等内容，请参考 langchain 的 Memory 部分的相关文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec5f5c-5ee8-4b89-add3-25f3c864200d",
   "metadata": {},
   "source": [
    "### 5.2 对话检索链（ConversationalRetrievalChain）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1afd4-a5e7-4eea-855b-d03055c93e2d",
   "metadata": {},
   "source": [
    "对话检索链（ConversationalRetrievalChain）在检索 QA 链的基础上，增加了处理对话历史的能力。\n",
    "\n",
    "它的工作流程是:\n",
    "1. 将之前的对话与新问题合并生成一个完整的查询语句。\n",
    "2. 在向量数据库中搜索该查询的相关文档。\n",
    "3. 获取结果后,存储所有答案到对话记忆区。\n",
    "4. 用户可在 UI 中查看完整的对话流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0305623-1a06-4bb8-b340-dde57202dd67",
   "metadata": {},
   "source": [
    "这种链式方式将新问题放在之前对话的语境中进行检索，可以处理依赖历史信息的查询。并保留所有信\n",
    "息在对话记忆中，方便追踪。\n",
    "\n",
    "接下来让我们可以测试这个对话检索链的效果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd113e-9d21-4385-a426-7e7a8ebb887a",
   "metadata": {},
   "source": [
    "使用上一节中的向量数据库和 LLM ！首先提出一个无历史对话的问题“这门课会学习 Python 吗？”，并查看回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbf223-ffb1-4220-bd16-2de3f1fbc6bc",
   "metadata": {},
   "source": [
    "v2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d5dcc5f-545e-463a-9f3f-9eca90457caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的信息，南瓜书似乎是一个作品的名字，但是具体的内容和性质没有详细说明。从信息中可以看出，有一些人担任了编委会的主编和编委，还有人对封面进行了设计。此外，还特别感谢了一些人在南瓜书最早期时所做出的贡献。如果需要了解南瓜书更具体的信息，可能需要扫描提供的二维码并回复关键词“南瓜书”，或者在网络中进行进一步的查询。我这里没有足够的信息来定义南瓜书的具体内容。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    zhipuai_llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "question = \"什么是南瓜书？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d48806-de78-4927-82de-f3adde8833fd",
   "metadata": {},
   "source": [
    "V2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d0089-02ed-4737-b834-914eed83c5e9",
   "metadata": {},
   "source": [
    "不带memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10cccd64-c744-407d-868b-e1534b272a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_1 的结果：\n",
      "南瓜书是对周志华老师的《机器学习》（西瓜书）中部分公式推导细节的补充解析，旨在帮助读者更好地理解西瓜书中的难点。它适合在阅读西瓜书时遇到难以推导或理解的公式时查阅。南瓜书是数学基础较弱的读者在学习过程中的笔记汇集。\n",
      "\n",
      "谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "# rerank检索\n",
    "# Cohere Rerank配置\n",
    "import cohere\n",
    "cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "# compressor = CohereRerank(\n",
    "#     client=cohere_client,\n",
    "#     top_n=5  # 保留Top5相关文档\n",
    "# )\n",
    "compressor = CohereRerank(\n",
    "    client=cohere_client,\n",
    "    top_n=5,\n",
    "    model=\"rerank-multilingual-v3.0\"  # 支持多语言的新版本\n",
    ")\n",
    "\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 15},  # 扩大召回池\n",
    "    search_type=\"mmr\",  # 最大边际相关性算法（网页5）\n",
    "    metadata_filter={\"source\": \"权威文档.pdf\"}  # 元数据过滤\n",
    ")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(zhipuai_llm,\n",
    "#                                        retriever=base_retriever,\n",
    "#                                        return_source_documents=True,\n",
    "#                                        chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    zhipuai_llm,\n",
    "    retriever=compression_retriever,  # 替换为压缩检索器\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_CHAIN_PROMPT,\n",
    "        # \"llm_kwargs\": {\"max_length\": 300}  # 新增输出长度限制\n",
    "    }\n",
    ")\n",
    "\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2b197-e0bd-40ca-9351-20fd47c2991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bf5a9be-7fa9-46e3-8966-7c7fad7f259c",
   "metadata": {},
   "source": [
    "新增MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25601979-9c1b-4d48-bceb-1cf2c979a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    你是一个专业的问答助手。请根据对话历史和提供的上下文回答问题。\n",
    "    \n",
    "    历史对话：\n",
    "    {chat_history}\n",
    "    \n",
    "    上下文：\n",
    "    {context}\n",
    "    \n",
    "    问题：{question}\n",
    "    \n",
    "    回答：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=zhipuai_llm,\n",
    "    retriever=compression_retriever,\n",
    "    memory=memory,\n",
    "    # return_source_documents=True,\n",
    "    output_key=\"answer\",  # 明确指定存储到内存的键\n",
    "    combine_docs_chain_kwargs={  # 替代chain_type_kwargs\n",
    "        \"prompt\": QA_CHAIN_PROMPT\n",
    "    },\n",
    "    verbose=True, # 独立传递verbose参数\n",
    ")\n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"南瓜书的主要内容？\", \n",
    "    \"第三章提到的关键技术是什么？\",  # 需记忆前一轮的\"主要内容\"\n",
    "    # \"请用表格总结这些技术的优缺点\"  # 需合并多轮信息\n",
    "    \"请讲前两个问题的答案整理成表格\"  # 需合并多轮信息\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"question\": question})\n",
    "    print(f\"问题：{question}\")\n",
    "    print(f\"回答：{result['answer']}\")\n",
    "    # print(f\"引用的来源：{result['source_documents'][0].metadata}\")  # 显示来源文档\n",
    "    print(\"对话历史：\", memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6ab35-9054-4bf5-a2ed-2c6f8012ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    你是一个专业的问答助手。请根据对话历史和提供的上下文回答问题。\n",
    "    \n",
    "    历史对话：\n",
    "    {chat_history}\n",
    "    \n",
    "    上下文：\n",
    "    {context}\n",
    "    \n",
    "    问题：{question}\n",
    "    \n",
    "    回答：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "#     llm=zhipuai_llm.bind(max_length=300),  # 绑定输出长度限制\n",
    "#     retriever=compression_retriever,\n",
    "#     memory=memory,  # 注入记忆模块\n",
    "#     return_source_documents=True,\n",
    "#     chain_type_kwargs={\n",
    "#         \"prompt\": QA_CHAIN_PROMPT,\n",
    "#         \"verbose\": True  # 可查看详细处理过程\n",
    "#     }\n",
    "# )\n",
    "\n",
    "questions = [\n",
    "    \"南瓜书的作者是谁？\",  # 初始问题\n",
    "    \"他们的研究领域是什么？\",  # 依赖前文\"作者\"信息\n",
    "    \"这本书的出版时间？\"  # 依赖前文\"书\"实体\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    \"南瓜书的主要内容？\", \n",
    "    \"第三章提到的关键技术是什么？\",  # 需记忆前一轮的\"主要内容\"\n",
    "    \"请用表格总结这些技术的优缺点\"  # 需合并多轮信息\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"question\": question})\n",
    "    print(f\"问题：{question}\")\n",
    "    print(f\"回答：{result['answer']}\")\n",
    "    print(f\"引用的来源：{result['source_documents'][0].metadata}\")  # 显示来源文档\n",
    "    print(\"对话历史：\", memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a420dfcc-7519-4297-a76f-108c241d4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_9320\\2072884007.py:2: LangChainDeprecationWarning: The class `ConversationalRetrievalChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~create_history_aware_retriever together with create_retrieval_chain (see example in docstring)` instead.\n",
      "  qa_chain = ConversationalRetrievalChain(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BaseModel.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversationalRetrievalChain\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m qa_chain = \u001b[43mConversationalRetrievalChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzhipuai_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression_retriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 替换为压缩检索器\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchain_type_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQA_CHAIN_PROMPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"llm_kwargs\": {\"max_length\": 300}  # 新增输出长度限制\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33m什么是南瓜书？\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m result = qa({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\ProgramData\\Python312\\venv\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    213\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\ProgramData\\Python312\\venv\\langchain\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: BaseModel.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# compression_retriever = ContextualCompressionRetriever(\n",
    "#     base_compressor=compressor,\n",
    "#     base_retriever=base_retriever\n",
    "# )\n",
    "\n",
    "# qa_chain = ConversationalRetrievalChain(\n",
    "#     zhipuai_llm,\n",
    "#     retriever=compression_retriever,  # 替换为压缩检索器\n",
    "#     return_source_documents=True,\n",
    "#     chain_type_kwargs={\n",
    "#         \"prompt\": QA_CHAIN_PROMPT,\n",
    "#         # \"llm_kwargs\": {\"max_length\": 300}  # 新增输出长度限制\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# question = \"什么是南瓜书？\"\n",
    "# result = qa({\"question\": question})\n",
    "# print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad80344-7079-4fa2-a3f6-065f1a0a2d79",
   "metadata": {},
   "source": [
    "然后基于答案进行下一个问题“为什么这门课需要教这方面的知识？”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef314c-515d-499c-8358-f19f188895b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"南瓜书包含哪些内容？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b44d8b-145d-42fc-b790-476798efdabe",
   "metadata": {},
   "source": [
    "可以看到，LLM 它准确地判断了这方面的知识，指代内容是强化学习的知识，也就\n",
    "是我们成功地传递给了它历史信息。这种持续学习和关联前后问题的能力，可大大增强问答系统的连续\n",
    "性和智能水平。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d86b8-7968-4a87-8bd5-9bceb5f65aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f2be-19aa-428e-b991-3755e5628c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72780ae5-b010-4eb8-8885-7c449412183f",
   "metadata": {},
   "source": [
    "## 5. 添加历史对话的记忆功能 - v2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c6341-9529-48f6-b0d6-df0cb38692cb",
   "metadata": {},
   "source": [
    "现在我们已经实现了通过上传本地知识文档，然后将他们保存到向量知识库，通过将查询问题与向量知识库的召回结果进行结合输入到 LLM 中，我们就得到了一个相比于直接让 LLM 回答要好得多的结果。在与语言模型交互时，你可能已经注意到一个关键问题 - **它们并不记得你之前的交流内容**。这在我们构建一些应用程序（如聊天机器人）的时候，带来了很大的挑战，使得对话似乎缺乏真正的连续性。这个问题该如何解决呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef1dbbf-3260-4865-a71a-11d22317a195",
   "metadata": {},
   "source": [
    "### 5.1 记忆（Memory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8ac5e-e5f2-42a2-8c5a-cf416aaa2a7a",
   "metadata": {},
   "source": [
    "在本节中我们将介绍 LangChain 中的储存模块，即如何将先前的对话嵌入到语言模型中的，使其具有连续对话的能力。我们将使用 `ConversationBufferMemory` ，它保存聊天消息历史记录的列表，这些历史记录将在回答问题时与问题一起传递给聊天机器人，从而将它们添加到上下文中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d58ef8-297f-4a56-9d7c-9cdc043ddda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/lx3tlt3d6fz2bys8ct46fzxh0000gn/T/ipykernel_90332/2228008247.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb6d61-0772-453c-b507-db57afac74fe",
   "metadata": {},
   "source": [
    "关于更多的 Memory 的使用，包括保留指定对话轮数、保存指定 token 数量、保存历史对话的总结摘要等内容，请参考 langchain 的 Memory 部分的相关文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84184f40-44e0-4c25-91e4-241f7364f654",
   "metadata": {},
   "source": [
    "### 5.2 对话检索链（ConversationalRetrievalChain）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1aea7-7d40-4101-8f9e-65b26d54ad40",
   "metadata": {},
   "source": [
    "对话检索链（ConversationalRetrievalChain）在检索 QA 链的基础上，增加了处理对话历史的能力。\n",
    "\n",
    "它的工作流程是:\n",
    "1. 将之前的对话与新问题合并生成一个完整的查询语句。\n",
    "2. 在向量数据库中搜索该查询的相关文档。\n",
    "3. 获取结果后,存储所有答案到对话记忆区。\n",
    "4. 用户可在 UI 中查看完整的对话流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cd6ab-0471-4104-b0d7-0e5198996d59",
   "metadata": {},
   "source": [
    "这种链式方式将新问题放在之前对话的语境中进行检索，可以处理依赖历史信息的查询。并保留所有信\n",
    "息在对话记忆中，方便追踪。\n",
    "\n",
    "接下来让我们可以测试这个对话检索链的效果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1dccc5-989f-4d92-8896-2fb16c2e429b",
   "metadata": {},
   "source": [
    "使用上一节中的向量数据库和 LLM ！首先提出一个无历史对话的问题“这门课会学习 Python 吗？”，并查看回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d47e13b1-9208-4f04-a2ec-ac4dc5141a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "南瓜书是根据提供的上下文看起来是一本关于机器学习的书籍，名为《机器学习公式详解》。这本书由一个编委会负责，其中包括主编和编委，并且有一个封面设计团队。书中包含了机器学习的基本概念、模型评估与选择等内容，并且力图以本科数学基础的视角对公式进行解析和推导。此外，南瓜书还提供了配套的视频教程和在线阅读地址，以及通过GitHub平台收集读者反馈的方式。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "question = \"什么是南瓜书？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0855c0-c860-48e0-a2a0-52674526db3c",
   "metadata": {},
   "source": [
    "然后基于答案进行下一个问题“为什么这门课需要教这方面的知识？”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8167f9af-82e6-46b7-abb0-aa715aec3f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "南瓜书主要包含以下内容和特点：\n",
      "\n",
      "1. 以本科数学基础的视角对机器学习中的公式进行解析和推导。\n",
      "2. 针对超纲的数学知识，通常以附录和参考文献的形式给出，方便感兴趣的同学深入学习。\n",
      "3. 提供了一个GitHub的Issues页面（地址：https://github.com/datawhalechina/pumpkin-book/issues），供读者反馈错误或提出希望补充的公式编号。\n",
      "4. 对于反馈，编委会承诺通常在24小时内回复。\n",
      "5. 提供了微信联系方式（微信号：at-Sm1les），以便在超过24小时未回复的情况下与编委会联系。\n",
      "6. 配套视频教程，可以在Bilibili上观看（地址：https://www.bilibili.com/video/BV1Mh411e7VU）。\n",
      "7. 提供在线阅读地址（https://datawhalechina.github.io/pumpkin-book），仅供第1版。\n",
      "8. 最新版PDF可以在GitHub的发布页面上获取（地址：https://github.com/datawhalechina/pumpkin-book/releases）。\n",
      "9. 包含了从绪论到模型评估与选择等章节，具体内容涵盖引言、基本术语、假设空间、归纳偏好、经验误差与过拟合、评估方法以及算法参数（超参数）与模型参数等。\n",
      "\n",
      "以上内容摘自提供的文本，具体书中内容可能更加丰富。\n"
     ]
    }
   ],
   "source": [
    "question = \"南瓜书包含哪些内容？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e686548-57a2-45e6-9fcd-42f4c673c7a0",
   "metadata": {},
   "source": [
    "可以看到，LLM 它准确地判断了这方面的知识，指代内容是强化学习的知识，也就\n",
    "是我们成功地传递给了它历史信息。这种持续学习和关联前后问题的能力，可大大增强问答系统的连续\n",
    "性和智能水平。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6cd22-6607-45da-802b-dd892e3c60ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

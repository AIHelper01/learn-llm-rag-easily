{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c794bc7",
   "metadata": {},
   "source": [
    "# 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0f2c3-3bd9-4de1-bbd2-e0e2b09161c8",
   "metadata": {},
   "source": [
    "我们已经介绍了如何根据自己的本地知识文档，搭建一个向量知识库。 在接下来的内容里，我们将使用搭建好的向量数据库，对 query 查询问题进行召回，并将召回结果和 query 结合起来构建 prompt，输入到大模型中进行问答。   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8d968-8d98-47b9-8885-dc17d24dce76",
   "metadata": {},
   "source": [
    "## 1. 加载向量数据库\n",
    "\n",
    "首先，我们加载在前一章已经构建的向量数据库。注意，此处你需要使用和构建时相同的 Emedding。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7affbed-f36e-4700-a1d9-c5d88917fff5",
   "metadata": {},
   "source": [
    "设置embedding - zhipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66d376-8140-4224-bdfb-360b60aef43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../C3 搭建知识库\") # 将父目录放入系统路径中\n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "# # 从环境变量中加载你的 API_KEY\n",
    "# _ = load_dotenv(find_dotenv())    # read local .env file\n",
    "# zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "# 定义持久化目录\n",
    "persist_directory = '../chroma-vmax'\n",
    "\n",
    "# # 创建嵌入模型\n",
    "# from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "\n",
    "# zhipu_embed = ZhipuAIEmbeddings(\n",
    "#     model=\"embedding-2\",\n",
    "#     api_key=zhipuai_api_key\n",
    "# )\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "emb_bgem3 = OllamaEmbeddings(base_url='http://localhost:11434',model=\"bge-m3:latest\")\n",
    "\n",
    "try:\n",
    "    # 加载持久化的 Chroma 向量数据库\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,  # 允许我们将persist_directory目录保存到磁盘上\n",
    "        collection_name=\"vmax-s\",\n",
    "        embedding_function=emb_bgem3\n",
    "    )\n",
    "    print(\"向量数据库已成功加载。\")\n",
    "except Exception as e:\n",
    "    print(f\"加载向量数据库时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b1838-38a3-4666-8bc8-c4592a5a39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5912d3d-9517-465c-8b82-cdd1eab27a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a68dc0-4f4c-433b-a367-44b5cffe8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VMAX上网日志业务是什么？\"\n",
    "docs = vectordb.similarity_search(question,k=15)\n",
    "print(f\"检索到的内容数：{len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09852d2a-aeda-4822-bf56-782a0397df3c",
   "metadata": {},
   "source": [
    "打印一下检索到的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f492bf-197b-4f94-820c-2d88c17754d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n {doc.page_content}\", end=\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f8dbd-ecd5-449d-9753-aedc2b74289c",
   "metadata": {},
   "source": [
    "## 2. 创建一个 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bd74f-3dd0-496e-905b-950a444bb7a7",
   "metadata": {},
   "source": [
    "在这里，我们调用 OpenAI 的 API 创建一个 LLM，当然你也可以使用其他 LLM 的 API 进行创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe25e4-e98e-4cb7-ac95-40e0e7b14ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 从环境变量中加载你的 API_KEY\n",
    "# _ = load_dotenv(find_dotenv())    # read local .env file\n",
    "# zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# zhipuai_llm = ChatOpenAI(\n",
    "#     temperature=0,\n",
    "#     model=\"glm-4\",\n",
    "#     openai_api_key=zhipuai_api_key,\n",
    "#     openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fb297-888a-4d35-b519-90eba639893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "\n",
    "# llm_deepseek = Ollama(base_url='http://localhost:11434', model='deepseek-r1:1.5b', temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db394906-5379-48e5-abf4-abdf60082884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm_deepseek = OllamaLLM(base_url='http://localhost:11434', model='deepseek-r1:1.5b', temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0fd45-73a0-451c-8e0e-7ea7b7365d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_deepseek import ChatDeepSeek\n",
    "# _ = load_dotenv(find_dotenv())    # read local .env file\n",
    "# deepseek_api_key = os.environ['DEEPSEEK_API_KEY']\n",
    "# llm_deepseek = ChatDeepSeek(\n",
    "#     model=\"deepseek-reasoner\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     # max_retries=2,\n",
    "#     api_key=deepseek_api_key,\n",
    "#     # other params...\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee13994-8cc6-45c0-a19a-c18dddddab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# _ = load_dotenv(find_dotenv())    # read local .env file\n",
    "# deepseek_api_key = os.environ['DEEPSEEK_API_KEY']\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# zhipuai_llm = ChatOpenAI(\n",
    "#     temperature=0,\n",
    "#     model=\"deepseek-chat\",\n",
    "#     openai_api_key=deepseek_api_key,\n",
    "#     openai_api_base=\"https://api.deepseek.com\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f361e27-cafb-48bf-bb41-50c9cb3a4f7e",
   "metadata": {},
   "source": [
    "## 3. 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b5e3c-1bc9-40e9-83c7-0594c2e7727d",
   "metadata": {},
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be03f4-264d-45cb-bebd-223c1c5747fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"],\n",
    "                                 template=template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d06d7f-1dca-4d10-b5cd-3a23e9d91200",
   "metadata": {},
   "source": [
    "#### 创建一个基于模板的检索链： 基础检索版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05eb57-edf5-4b35-9538-42c2b8f5cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 基础检索\n",
    "base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 15},  # 扩大召回池\n",
    "    search_type=\"mmr\",  # 最大边际相关性算法（网页5）\n",
    "    # metadata_filter={\"source\": \"权威文档.pdf\"}  # 元数据过滤\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm_deepseek,\n",
    "                                       retriever=base_retriever,\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a61eb-feea-4fff-8063-a20c3b392aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"什么是安全加固？\"\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707095e-21d0-4e2b-8a5b-0c02258d2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"严威是谁？\"\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5eabd-054b-4872-8867-759433ab22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"VMAX是什么？\"\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ac734-6693-422d-97e1-50f140e2d358",
   "metadata": {},
   "source": [
    "### 创建一个基于模板的检索链： rerank检索版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2347f57-a191-4580-bd3f-e5623e17ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试API\n",
    "\n",
    "# import cohere\n",
    "# # co = cohere.ClientV2()\n",
    "# co = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "# docs = [\n",
    "#     \"Carson City is the capital city of the American state of Nevada.\",\n",
    "#     \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean. Its capital is Saipan.\",\n",
    "#     \"Capitalization or capitalisation in English grammar is the use of a capital letter at the start of a word. English usage varies from capitalization in other languages.\",\n",
    "#     \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district.\",\n",
    "#     \"Capital punishment has existed in the United States since beforethe United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
    "# ]\n",
    "# response = co.rerank(\n",
    "#     model=\"rerank-v3.5\",\n",
    "#     query=\"What is the capital of the United States?\",\n",
    "#     documents=docs,\n",
    "#     top_n=3,\n",
    "# )\n",
    "# print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c893eb-3a30-40c1-9b60-dc6d448ea1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "# rerank检索\n",
    "# Cohere Rerank配置\n",
    "import cohere\n",
    "cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "\n",
    "compressor = CohereRerank(\n",
    "    client=cohere_client,\n",
    "    top_n=5,\n",
    "    model=\"rerank-multilingual-v3.0\"  # 支持多语言的新版本\n",
    ")\n",
    "\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 15},  # 扩大召回池\n",
    "    search_type=\"mmr\",  # 最大边际相关性算法（网页5）\n",
    "    # metadata_filter={\"source\": \"权威文档.pdf\"}  # 元数据过滤\n",
    ")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm_deepseek,\n",
    "    retriever=compression_retriever,  # 替换为压缩检索器\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_CHAIN_PROMPT,\n",
    "        # \"llm_kwargs\": {\"max_length\": 300}  # 新增输出长度限制\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b68384-e2ac-482b-ae87-f94dc1345e5e",
   "metadata": {},
   "source": [
    "### 创建一个基于模板的检索链： BM25检索版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a7972-a673-41ca-a028-647169d19fcb",
   "metadata": {},
   "source": [
    "## 4.检索问答链效果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610e223-64c2-4865-b049-b47a36262a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"VMAX是什么？\"\n",
    "question_2 = \"严威是谁？\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2223f-6fb5-4504-bfcd-ac74ca9ff2fa",
   "metadata": {},
   "source": [
    "### 4.1 基于召回结果和 query 结合起来构建的 prompt 效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5c5c3-9958-44f5-9fbc-f867de6c5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0f3c4-4c50-4b73-a4b3-674825a366f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question_2})\n",
    "print(\"大模型+知识库后回答 question_2 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4195cfa-1fc8-41a9-8984-91f2e5fbe013",
   "metadata": {},
   "source": [
    "### 4.2 大模型自己回答的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fbe28-2e2d-4042-b3a1-65326842bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_1)\n",
    "\n",
    "### 基于大模型的问答\n",
    "llm_deepseek.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3a813-db19-4be5-8926-ad8298e3e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_2)\n",
    "\n",
    "### 基于大模型的问答\n",
    "llm_deepseek.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9ba4a-053d-409a-a632-63336c2bdf84",
   "metadata": {},
   "source": [
    "> ⭐ 通过以上两个问题，我们发现 LLM 对于一些近几年的知识以及非常识性的专业问题，回答的并不是很好。而加上我们的本地知识，就可以帮助 LLM 做出更好的回答。另外，也有助于缓解大模型的“幻觉”问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20c510-f583-42b4-ac5c-b232388e9673",
   "metadata": {},
   "source": [
    "## 5. 添加历史对话的记忆功能-v2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e43e5-262d-4358-afb4-129dbf413287",
   "metadata": {},
   "source": [
    "现在我们已经实现了通过上传本地知识文档，然后将他们保存到向量知识库，通过将查询问题与向量知识库的召回结果进行结合输入到 LLM 中，我们就得到了一个相比于直接让 LLM 回答要好得多的结果。在与语言模型交互时，你可能已经注意到一个关键问题 - **它们并不记得你之前的交流内容**。这在我们构建一些应用程序（如聊天机器人）的时候，带来了很大的挑战，使得对话似乎缺乏真正的连续性。这个问题该如何解决呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadc3df-4123-4e12-9516-8632b10dc41f",
   "metadata": {},
   "source": [
    "### 5.1 记忆（Memory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f3fd2-14de-4177-893c-53ddaf6768e9",
   "metadata": {},
   "source": [
    "在本节中我们将介绍 LangChain 中的储存模块，即如何将先前的对话嵌入到语言模型中的，使其具有连续对话的能力。我们将使用 `ConversationBufferMemory` ，它保存聊天消息历史记录的列表，这些历史记录将在回答问题时与问题一起传递给聊天机器人，从而将它们添加到上下文中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42210b88-3590-47dc-a087-ab9cef14f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d580d9-b926-462f-9d6a-23135ecece37",
   "metadata": {},
   "source": [
    "关于更多的 Memory 的使用，包括保留指定对话轮数、保存指定 token 数量、保存历史对话的总结摘要等内容，请参考 langchain 的 Memory 部分的相关文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec5f5c-5ee8-4b89-add3-25f3c864200d",
   "metadata": {},
   "source": [
    "### 5.2 对话检索链（ConversationalRetrievalChain）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1afd4-a5e7-4eea-855b-d03055c93e2d",
   "metadata": {},
   "source": [
    "对话检索链（ConversationalRetrievalChain）在检索 QA 链的基础上，增加了处理对话历史的能力。\n",
    "\n",
    "它的工作流程是:\n",
    "1. 将之前的对话与新问题合并生成一个完整的查询语句。\n",
    "2. 在向量数据库中搜索该查询的相关文档。\n",
    "3. 获取结果后,存储所有答案到对话记忆区。\n",
    "4. 用户可在 UI 中查看完整的对话流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0305623-1a06-4bb8-b340-dde57202dd67",
   "metadata": {},
   "source": [
    "这种链式方式将新问题放在之前对话的语境中进行检索，可以处理依赖历史信息的查询。并保留所有信\n",
    "息在对话记忆中，方便追踪。\n",
    "\n",
    "接下来让我们可以测试这个对话检索链的效果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd113e-9d21-4385-a426-7e7a8ebb887a",
   "metadata": {},
   "source": [
    "使用上一节中的向量数据库和 LLM ！首先提出一个无历史对话的问题“这门课会学习 Python 吗？”，并查看回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbf223-ffb1-4220-bd16-2de3f1fbc6bc",
   "metadata": {},
   "source": [
    "v2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5dcc5f-545e-463a-9f3f-9eca90457caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm_deepseek,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "question = \"什么是安全加固？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d48806-de78-4927-82de-f3adde8833fd",
   "metadata": {},
   "source": [
    "V2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d0089-02ed-4737-b834-914eed83c5e9",
   "metadata": {},
   "source": [
    "不带memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cccd64-c744-407d-868b-e1534b272a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "# rerank检索\n",
    "# Cohere Rerank配置\n",
    "import cohere\n",
    "cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "# compressor = CohereRerank(\n",
    "#     client=cohere_client,\n",
    "#     top_n=5  # 保留Top5相关文档\n",
    "# )\n",
    "compressor = CohereRerank(\n",
    "    client=cohere_client,\n",
    "    top_n=5,\n",
    "    model=\"rerank-multilingual-v3.0\"  # 支持多语言的新版本\n",
    ")\n",
    "\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 15},  # 扩大召回池\n",
    "    search_type=\"mmr\",  # 最大边际相关性算法（网页5）\n",
    "    metadata_filter={\"source\": \"权威文档.pdf\"}  # 元数据过滤\n",
    ")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(zhipuai_llm,\n",
    "#                                        retriever=base_retriever,\n",
    "#                                        return_source_documents=True,\n",
    "#                                        chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm_deepseek,\n",
    "    retriever=compression_retriever,  # 替换为压缩检索器\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_CHAIN_PROMPT,\n",
    "        # \"llm_kwargs\": {\"max_length\": 300}  # 新增输出长度限制\n",
    "    }\n",
    ")\n",
    "\n",
    "result = qa_chain({\"query\": question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2b197-e0bd-40ca-9351-20fd47c2991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bf5a9be-7fa9-46e3-8966-7c7fad7f259c",
   "metadata": {},
   "source": [
    "新增MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25601979-9c1b-4d48-bceb-1cf2c979a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    你是一个专业的问答助手。请根据对话历史和提供的上下文回答问题。\n",
    "    \n",
    "    历史对话：\n",
    "    {chat_history}\n",
    "    \n",
    "    上下文：\n",
    "    {context}\n",
    "    \n",
    "    问题：{question}\n",
    "    \n",
    "    回答：\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm_deepseek,\n",
    "    retriever=compression_retriever,\n",
    "    memory=memory,\n",
    "    # return_source_documents=True,\n",
    "    output_key=\"answer\",  # 明确指定存储到内存的键\n",
    "    combine_docs_chain_kwargs={  # 替代chain_type_kwargs\n",
    "        \"prompt\": QA_CHAIN_PROMPT\n",
    "    },\n",
    "    verbose=True, # 独立传递verbose参数\n",
    ")\n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"什么是VMAX的安全加固？\", \n",
    "    \"安全加固的操作步骤？\",  # 需记忆前一轮的\"主要内容\"\n",
    "    \"整理成中文表格\"  # 需合并多轮信息\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"question\": question})\n",
    "    print(f\"问题：{question}\")\n",
    "    print(f\"回答：{result['answer']}\")\n",
    "    # print(f\"引用的来源：{result['source_documents'][0].metadata}\")  # 显示来源文档\n",
    "    print(\"对话历史：\", memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f2be-19aa-428e-b991-3755e5628c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72780ae5-b010-4eb8-8885-7c449412183f",
   "metadata": {},
   "source": [
    "## 5. 添加历史对话的记忆功能 - v2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c6341-9529-48f6-b0d6-df0cb38692cb",
   "metadata": {},
   "source": [
    "现在我们已经实现了通过上传本地知识文档，然后将他们保存到向量知识库，通过将查询问题与向量知识库的召回结果进行结合输入到 LLM 中，我们就得到了一个相比于直接让 LLM 回答要好得多的结果。在与语言模型交互时，你可能已经注意到一个关键问题 - **它们并不记得你之前的交流内容**。这在我们构建一些应用程序（如聊天机器人）的时候，带来了很大的挑战，使得对话似乎缺乏真正的连续性。这个问题该如何解决呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef1dbbf-3260-4865-a71a-11d22317a195",
   "metadata": {},
   "source": [
    "### 5.1 记忆（Memory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8ac5e-e5f2-42a2-8c5a-cf416aaa2a7a",
   "metadata": {},
   "source": [
    "在本节中我们将介绍 LangChain 中的储存模块，即如何将先前的对话嵌入到语言模型中的，使其具有连续对话的能力。我们将使用 `ConversationBufferMemory` ，它保存聊天消息历史记录的列表，这些历史记录将在回答问题时与问题一起传递给聊天机器人，从而将它们添加到上下文中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d58ef8-297f-4a56-9d7c-9cdc043ddda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb6d61-0772-453c-b507-db57afac74fe",
   "metadata": {},
   "source": [
    "关于更多的 Memory 的使用，包括保留指定对话轮数、保存指定 token 数量、保存历史对话的总结摘要等内容，请参考 langchain 的 Memory 部分的相关文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84184f40-44e0-4c25-91e4-241f7364f654",
   "metadata": {},
   "source": [
    "### 5.2 对话检索链（ConversationalRetrievalChain）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1aea7-7d40-4101-8f9e-65b26d54ad40",
   "metadata": {},
   "source": [
    "对话检索链（ConversationalRetrievalChain）在检索 QA 链的基础上，增加了处理对话历史的能力。\n",
    "\n",
    "它的工作流程是:\n",
    "1. 将之前的对话与新问题合并生成一个完整的查询语句。\n",
    "2. 在向量数据库中搜索该查询的相关文档。\n",
    "3. 获取结果后,存储所有答案到对话记忆区。\n",
    "4. 用户可在 UI 中查看完整的对话流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cd6ab-0471-4104-b0d7-0e5198996d59",
   "metadata": {},
   "source": [
    "这种链式方式将新问题放在之前对话的语境中进行检索，可以处理依赖历史信息的查询。并保留所有信\n",
    "息在对话记忆中，方便追踪。\n",
    "\n",
    "接下来让我们可以测试这个对话检索链的效果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1dccc5-989f-4d92-8896-2fb16c2e429b",
   "metadata": {},
   "source": [
    "使用上一节中的向量数据库和 LLM ！首先提出一个无历史对话的问题“这门课会学习 Python 吗？”，并查看回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e13b1-9208-4f04-a2ec-ac4dc5141a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "question = \"什么是南瓜书？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0855c0-c860-48e0-a2a0-52674526db3c",
   "metadata": {},
   "source": [
    "然后基于答案进行下一个问题“为什么这门课需要教这方面的知识？”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167f9af-82e6-46b7-abb0-aa715aec3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"南瓜书包含哪些内容？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e686548-57a2-45e6-9fcd-42f4c673c7a0",
   "metadata": {},
   "source": [
    "可以看到，LLM 它准确地判断了这方面的知识，指代内容是强化学习的知识，也就\n",
    "是我们成功地传递给了它历史信息。这种持续学习和关联前后问题的能力，可大大增强问答系统的连续\n",
    "性和智能水平。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6cd22-6607-45da-802b-dd892e3c60ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7db4e11-bc42-4289-bb04-4334d3155742",
   "metadata": {},
   "source": [
    "# 脚本汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca516d-c604-473d-92c4-2b7646b23088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm():\n",
    "    return OllamaLLM(base_url='http://localhost:11434', model='deepseek-r1:1.5b', temperature=0.1)\n",
    "\n",
    "\n",
    "def generate_response(input_text):\n",
    "    llm = get_llm()\n",
    "    output = llm.invoke(input_text)\n",
    "    output_parser = StrOutputParser()\n",
    "    return output_parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff0fe-0086-46a2-859b-2c4943f23252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "import cohere\n",
    "\n",
    "\n",
    "# 初始化函数 (保持你的原始代码不变)\n",
    "def get_vectordb():\n",
    "    emb_bgem3 = OllamaEmbeddings(base_url='http://localhost:11434', model=\"bge-m3:latest\")\n",
    "    persist_directory = '../chroma-vmax'\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=\"vmax-s\",\n",
    "        embedding_function=emb_bgem3\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "def get_llm():\n",
    "    return OllamaLLM(base_url='http://localhost:11434', model='deepseek-r1:1.5b', temperature=0.1)\n",
    "\n",
    "\n",
    "def get_qa_chain_without_memory(question: str):\n",
    "    vectordb = get_vectordb()\n",
    "    myllm = get_llm()\n",
    "\n",
    "    cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "    compressor = CohereRerank(\n",
    "        client=cohere_client,\n",
    "        top_n=5,\n",
    "        model=\"rerank-multilingual-v3.0\"\n",
    "    )\n",
    "\n",
    "    base_retriever = vectordb.as_retriever(\n",
    "        search_kwargs={\"k\": 15},\n",
    "        search_type=\"mmr\",\n",
    "    )\n",
    "\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=base_retriever\n",
    "    )\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=myllm,\n",
    "        retriever=compression_retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": PromptTemplate(\n",
    "                input_variables=[\"context\", \"question\"],\n",
    "                template=\"\"\"你是DeepSeek VMAX-S知识助手。使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "                案。总是在回答的最后说“谢谢你的提问！”。\n",
    "                {context}\n",
    "                问题: {question}\n",
    "                \"\"\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result = qa_chain({\"query\": question})\n",
    "    return result[\"result\"]\n",
    "\n",
    "\n",
    "print(get_qa_chain_without_memory(\"介绍下VMAX的上网日志业务\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e125db7b-640d-4640-b98f-9899bf48296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是DeepSeek VMAX-S知识助手。使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。总是在回答的最后说“谢谢你的提问！”。\n",
      "                2维护工程师要求掌握应有的技能是维护工程师顺利完成故障处理活动的重要条件。维护工程师应具备如下技能。熟练掌握通信基础知识：熟悉以太网、TCP/IP等计算机网络知识。掌握VMAX设备的组网和业务功能：→熟悉实际的网络组网情况。→熟悉VMAX各功能的实现原理。→熟悉VMAX与网络上其它设备之间的连接关系。→熟悉VMAX与网络上其它设备之间所使用的协议。掌握VMAX的常用故障定位操作，在操作设备时还应清楚：→哪些操作将导致部分或全部业务中断。→哪些操作将导致用户投诉。→哪些操作将造成设备损坏。→有哪些应急或备份的措施。熟练使用以下测试工具和仪表：→万用表→线路测试仪→光功率计→光衰减器掌握设备紧急故障的判断、定位和排除方法。通过演练，能熟练运用这些方法开展紧急故障处理。不同运营商有所不同，请了解本运营商的相关标准和要求。采集和保存现场数据现场数据的采集和保存，包括设备正常运行时的定期采集和设备发生故障时的采集。一般在故障处理前，要求维护人员首先要采集、保存现场数据。对需要采集的数据的详细介绍，参见“故障信息采集”。了解出现故障时的求助渠道，包括但不限于故障处理类资料、如何联系技术支持。\n",
      "2\n",
      "\n",
      "7可靠性设计容错能力\n",
      "ZXVMAX-S通过对关键软件资源的定时检测、实时任务监控、存储保护、数据校验、操作日志信息保存等手段，可有效地防止小软件故障对系统所造成的冲击，提高了软件系统的容错能力（即软件错误情况下的自愈能力）。故障监视及处理\n",
      "ZXVMAX-S具备自动检测与诊断系统软硬件故障的功能，可对故障硬件实施自动隔离、倒换、重新启动、重新加载等处理。满足漏洞扫描为了避免存在安全漏洞使在网设备受外部攻击，需要使系统满足主流安全漏洞扫描工具的要求。\n",
      "ZXVMAX-S满足Nessus和CD工具安全漏洞扫描的要求。\n",
      "7.3 数据可靠性\n",
      "\n",
      "7可靠性设计\n",
      "7.2 软件可靠性松耦合设计\n",
      "ZXVMAX-S语音业务的软件采用分层的模块化结构，各软件模块的设计基于松散耦合的机制，这样，当一个软件模块出错时，其对其它软件模块的影响将降低到最低限度。容错能力\n",
      "ZXVMAX-S语音业务通过对关键软件资源的定时检测、实时任务分析、存储保护、数据校验、操作日志信息保存等手段，可有效地防止小软件故障对系统所造成的冲击，提高了软件系统的容错能力（即软件错误情况下的自愈能力）。故障监视及处理\n",
      "ZXVMAX-S语音业务具备自动检测与诊断系统软硬件故障的功能，可对故障硬件实施自动隔离、倒换、重新启动、重新加载等处理。满足漏洞扫描为了避免存在安全漏洞使在网设备受外部攻击，需要使系统满足主流安全漏洞扫描工具的要求。\n",
      "ZXVMAX-S语音业务满足Nessus和CD工具安全漏洞扫描的要求。\n",
      "7.3 数据可靠性\n",
      "\n",
      "4.1.4 评估优化功能评估优化是为语音业务提供了评估报告功能，按照一定报告模板输出选定区域、时间范围的评估报告，同时提供设置定期自动生成每周或每月评估报告的功能。通过立即或定时输出报告，可以节省网络维护人员工作量提高工作效率。语音业务的质量指标MOS值分析出发，根据MOS指标识别出语音质差区域，对质差区域进行问题根因定位，给出解决建议，并提供解决问题的闭环验证。具体分析操作参见表4-2。表4-2具体分析操作操作名称操作过程操作功能注册质差分析系统通过对全网或具体地市注册事件的失败原因进行分析，并按网元、小区、终端、用户四个维度，进行不同维度的失败次数统计，然后通过VMAX客户端界面呈现出来。针对注册中发生的失败问题进行多维度深度统计，方便维护人员从不同角度查找注册失败问题的主因，快速对问题进行定界处理。呼叫质差分析系统通过对全网或具体地市呼叫事件的失败原因进行分析，并按网元、小区、终端、用户四个维度，进行不同维度的失败次数统计，然后通过VMAX客户端界面呈现出来。针对呼叫中发生的失败问题进行了多维度深度统计，方便维护人员从不同角度查找呼叫失败问题的主因，快速对问题进行定界处理。\n",
      "\n",
      "ZXVMAX-S多维价值分析系统产品描述（数据业务）元、位置、终端等维度的分析，也可以从失败指标钻取失败原因值分析，再从失败原因值分析钻取详细XDR。网络实时保障移动通信网络发生异常时，对用户的业务使用影响重大，有必要对网络进行实时的保障，以便在网络发生异常时迅速做出反应，及时处理，将对用户的负面影响降低到最小。实时保障功能以图形的方式实时呈现出网络的相关质量指标，呈现图形可以选择为柱状图或者折线图。实时保障的目标、场景、告警门限、时长和粒度等均可配置，这些配置信息可保存为模板供重复使用。保障结果数据可以导出、保存。实时保障支持的指标完全覆盖网络性能指标，支持的分析维度主要为\n",
      "MME、eNodeB等网元。\n",
      "                问题: 什么是VMAX的安全加固？\n",
      "        \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "问题：什么是VMAX的安全加固？\n",
      "回答：<think>\n",
      "嗯，用户问的是“什么是VMAX的安全加固？”首先，我需要理解VMAX是什么。根据上下文，VMAX是用于网络设备管理的软件，可能是一个安全工具或监控平台。\n",
      "\n",
      "接下来，用户的问题涉及到安全加固，这通常指的是为某个系统或产品添加额外的安全功能来增强其安全性。所以，我应该从VMAX的角度出发，看看它有哪些安全加固的功能。\n",
      "\n",
      "在提供的上下文中，我看到VMAX-S有多个模块，比如通信基础知识、组网和业务功能、故障定位操作、测试工具和仪表等。这些部分都可能涉及安全方面的功能。\n",
      "\n",
      "例如，在“故障定位操作”部分提到需要了解哪些操作会导致业务中断或用户投诉，以及哪些导致设备损坏。这说明VMAX在检测和处理故障时有安全层面的功能。\n",
      "\n",
      "另外，“数据可靠性”部分提到了软件可靠性松耦合设计，容错能力的提高，这些都与安全性有关。同时，“评估优化功能”中提到评估报告和定期自动生成报告，这也涉及到安全监控和保护。\n",
      "\n",
      "还有“多维价值分析系统”部分，讨论了网络实时保障，包括质量指标和图形展示，这可能涉及安全性能的监控和保护。\n",
      "\n",
      "综合来看，VMAX的安全加固应该包括检测、诊断、修复和保护功能。这些功能帮助用户或维护人员及时发现并处理问题，同时确保设备在异常情况下能够正常运行，保护数据不被窃取或损坏。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "对话历史： {'chat_history': [HumanMessage(content='什么是VMAX的安全加固？', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n嗯，用户问的是“什么是VMAX的安全加固？”首先，我需要理解VMAX是什么。根据上下文，VMAX是用于网络设备管理的软件，可能是一个安全工具或监控平台。\\n\\n接下来，用户的问题涉及到安全加固，这通常指的是为某个系统或产品添加额外的安全功能来增强其安全性。所以，我应该从VMAX的角度出发，看看它有哪些安全加固的功能。\\n\\n在提供的上下文中，我看到VMAX-S有多个模块，比如通信基础知识、组网和业务功能、故障定位操作、测试工具和仪表等。这些部分都可能涉及安全方面的功能。\\n\\n例如，在“故障定位操作”部分提到需要了解哪些操作会导致业务中断或用户投诉，以及哪些导致设备损坏。这说明VMAX在检测和处理故障时有安全层面的功能。\\n\\n另外，“数据可靠性”部分提到了软件可靠性松耦合设计，容错能力的提高，这些都与安全性有关。同时，“评估优化功能”中提到评估报告和定期自动生成报告，这也涉及到安全监控和保护。\\n\\n还有“多维价值分析系统”部分，讨论了网络实时保障，包括质量指标和图形展示，这可能涉及安全性能的监控和保护。\\n\\n综合来看，VMAX的安全加固应该包括检测、诊断、修复和保护功能。这些功能帮助用户或维护人员及时发现并处理问题，同时确保设备在异常情况下能够正常运行，保护数据不被窃取或损坏。\\n</think>\\n\\nVMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\\n\\n1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\\n\\n2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\\n\\n3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\\n\\n4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\\n\\n5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\\n\\n综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: 什么是VMAX的安全加固？\n",
      "Assistant: <think>\n",
      "嗯，用户问的是“什么是VMAX的安全加固？”首先，我需要理解VMAX是什么。根据上下文，VMAX是用于网络设备管理的软件，可能是一个安全工具或监控平台。\n",
      "\n",
      "接下来，用户的问题涉及到安全加固，这通常指的是为某个系统或产品添加额外的安全功能来增强其安全性。所以，我应该从VMAX的角度出发，看看它有哪些安全加固的功能。\n",
      "\n",
      "在提供的上下文中，我看到VMAX-S有多个模块，比如通信基础知识、组网和业务功能、故障定位操作、测试工具和仪表等。这些部分都可能涉及安全方面的功能。\n",
      "\n",
      "例如，在“故障定位操作”部分提到需要了解哪些操作会导致业务中断或用户投诉，以及哪些导致设备损坏。这说明VMAX在检测和处理故障时有安全层面的功能。\n",
      "\n",
      "另外，“数据可靠性”部分提到了软件可靠性松耦合设计，容错能力的提高，这些都与安全性有关。同时，“评估优化功能”中提到评估报告和定期自动生成报告，这也涉及到安全监控和保护。\n",
      "\n",
      "还有“多维价值分析系统”部分，讨论了网络实时保障，包括质量指标和图形展示，这可能涉及安全性能的监控和保护。\n",
      "\n",
      "综合来看，VMAX的安全加固应该包括检测、诊断、修复和保护功能。这些功能帮助用户或维护人员及时发现并处理问题，同时确保设备在异常情况下能够正常运行，保护数据不被窃取或损坏。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "Follow Up Input: 安全加固的操作步骤？\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是DeepSeek VMAX-S知识助手。使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。总是在回答的最后说“谢谢你的提问！”。\n",
      "                ZXVMAX-S多维价值分析系统产品描述（5GC业务）\n",
      "ZXVMAX-S系统支持满足用户需求根据用户需求进行数据自定义的查询或分析。满足不同场景下用户分析解决问题的需求。多种应用，自由选择。\n",
      "ZXVMAX-S支持性能分析、事件分析、终端分析等多种应用，可以根据目标用户的需求，开启对应权限，部署相应模块。\n",
      "4\n",
      "SJ-20230406152852-016|2023-03-30（R1.0）\n",
      "\n",
      "7.4 组网可靠性\n",
      "ZXVMAX-S产品根据需要，可以通过交换机冗余备份，各主机网络的以太网隧道冗余备份，实现对业务和设备的保护。在单一交换机故障时，备用交换机会及时启用，避免业务中断。在单一的网络传输故障时，备用的传输链路仍然生效，也能避免业务中断。\n",
      "SJ-20230406152852-014|2023-03-30（R1.0）\n",
      "29\n",
      "\n",
      "ZXVMAX-S多维价值分析系统产品描述（数据业务）元、位置、终端等维度的分析，也可以从失败指标钻取失败原因值分析，再从失败原因值分析钻取详细XDR。网络实时保障移动通信网络发生异常时，对用户的业务使用影响重大，有必要对网络进行实时的保障，以便在网络发生异常时迅速做出反应，及时处理，将对用户的负面影响降低到最小。实时保障功能以图形的方式实时呈现出网络的相关质量指标，呈现图形可以选择为柱状图或者折线图。实时保障的目标、场景、告警门限、时长和粒度等均可配置，这些配置信息可保存为模板供重复使用。保障结果数据可以导出、保存。实时保障支持的指标完全覆盖网络性能指标，支持的分析维度主要为\n",
      "MME、eNodeB等网元。\n",
      "\n",
      "ZXVMAX-S多维价值分析系统产品描述（语音业务）\n",
      "ZXVMAX-S语音业务系统支持事件详细信息的呈现，也支持基于经验算法的问题定位，提升分析解决问题的效率，满足不同层次用户的需求。多种应用，自由选择。\n",
      "ZXVMAX-S语音业务支持信令回溯、记录查询、呼叫分析、网络质量分析、业务质量定界、时延分析等多种应用，可以根据目标用户的需求，开启对应权限，部署相应模块。\n",
      "4\n",
      "SJ-20230406152852-013|2023-03-30（R1.0）\n",
      "\n",
      "7可靠性设计容错能力\n",
      "ZXVMAX-S通过对关键软件资源的定时检测、实时任务监控、存储保护、数据校验、操作日志信息保存等手段，可有效地防止小软件故障对系统所造成的冲击，提高了软件系统的容错能力（即软件错误情况下的自愈能力）。故障监视及处理\n",
      "ZXVMAX-S具备自动检测与诊断系统软硬件故障的功能，可对故障硬件实施自动隔离、倒换、重新启动、重新加载等处理。满足漏洞扫描为了避免存在安全漏洞使在网设备受外部攻击，需要使系统满足主流安全漏洞扫描工具的要求。\n",
      "ZXVMAX-S满足Nessus和CD工具安全漏洞扫描的要求。\n",
      "7.3 数据可靠性\n",
      "                问题: <think>\n",
      "用户的问题是关于“什么是VMAX的安全加固？”，我需要将其转换为一个独立的问句。首先，理解VMAX是什么，然后明确安全加固的概念。\n",
      "\n",
      "接下来，思考如何将这些信息整合成一个清晰、简洁的回答。确保回答准确传达VMAX的安全加固的功能和作用。\n",
      "\n",
      "最后，组织语言，使其逻辑清晰，易于理解。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "        \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "问题：安全加固的操作步骤？\n",
      "回答：<think>\n",
      "嗯，用户问的是“什么是VMAX的安全加固？”。首先，我需要明确VMAX是什么。根据上下文，VMAX是一个多维价值分析系统，主要用于数据分析和决策支持。\n",
      "\n",
      "接下来，我要解释安全加固的概念。安全加固是为确保系统的安全性而设计的额外功能或措施。它能够检测到潜在的安全威胁，防止设备损坏或数据丢失。\n",
      "\n",
      "然后，我需要将这些信息整合成一个清晰、简洁的回答，涵盖VMAX的安全加固的主要特点，包括检测与诊断、修复与恢复、数据可靠性等。\n",
      "\n",
      "最后，我要确保语言自然流畅，逻辑清晰，让用户能够轻松理解VMAX安全加固的功能和作用。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "对话历史： {'chat_history': [HumanMessage(content='什么是VMAX的安全加固？', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n嗯，用户问的是“什么是VMAX的安全加固？”首先，我需要理解VMAX是什么。根据上下文，VMAX是用于网络设备管理的软件，可能是一个安全工具或监控平台。\\n\\n接下来，用户的问题涉及到安全加固，这通常指的是为某个系统或产品添加额外的安全功能来增强其安全性。所以，我应该从VMAX的角度出发，看看它有哪些安全加固的功能。\\n\\n在提供的上下文中，我看到VMAX-S有多个模块，比如通信基础知识、组网和业务功能、故障定位操作、测试工具和仪表等。这些部分都可能涉及安全方面的功能。\\n\\n例如，在“故障定位操作”部分提到需要了解哪些操作会导致业务中断或用户投诉，以及哪些导致设备损坏。这说明VMAX在检测和处理故障时有安全层面的功能。\\n\\n另外，“数据可靠性”部分提到了软件可靠性松耦合设计，容错能力的提高，这些都与安全性有关。同时，“评估优化功能”中提到评估报告和定期自动生成报告，这也涉及到安全监控和保护。\\n\\n还有“多维价值分析系统”部分，讨论了网络实时保障，包括质量指标和图形展示，这可能涉及安全性能的监控和保护。\\n\\n综合来看，VMAX的安全加固应该包括检测、诊断、修复和保护功能。这些功能帮助用户或维护人员及时发现并处理问题，同时确保设备在异常情况下能够正常运行，保护数据不被窃取或损坏。\\n</think>\\n\\nVMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\\n\\n1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\\n\\n2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\\n\\n3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\\n\\n4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\\n\\n5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\\n\\n综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。', additional_kwargs={}, response_metadata={}), HumanMessage(content='安全加固的操作步骤？', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n嗯，用户问的是“什么是VMAX的安全加固？”。首先，我需要明确VMAX是什么。根据上下文，VMAX是一个多维价值分析系统，主要用于数据分析和决策支持。\\n\\n接下来，我要解释安全加固的概念。安全加固是为确保系统的安全性而设计的额外功能或措施。它能够检测到潜在的安全威胁，防止设备损坏或数据丢失。\\n\\n然后，我需要将这些信息整合成一个清晰、简洁的回答，涵盖VMAX的安全加固的主要特点，包括检测与诊断、修复与恢复、数据可靠性等。\\n\\n最后，我要确保语言自然流畅，逻辑清晰，让用户能够轻松理解VMAX安全加固的功能和作用。\\n</think>\\n\\nVMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\\n\\n1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\\n\\n2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\\n\\n3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\\n\\n4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\\n\\n5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\\n\\n综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: 什么是VMAX的安全加固？\n",
      "Assistant: <think>\n",
      "嗯，用户问的是“什么是VMAX的安全加固？”首先，我需要理解VMAX是什么。根据上下文，VMAX是用于网络设备管理的软件，可能是一个安全工具或监控平台。\n",
      "\n",
      "接下来，用户的问题涉及到安全加固，这通常指的是为某个系统或产品添加额外的安全功能来增强其安全性。所以，我应该从VMAX的角度出发，看看它有哪些安全加固的功能。\n",
      "\n",
      "在提供的上下文中，我看到VMAX-S有多个模块，比如通信基础知识、组网和业务功能、故障定位操作、测试工具和仪表等。这些部分都可能涉及安全方面的功能。\n",
      "\n",
      "例如，在“故障定位操作”部分提到需要了解哪些操作会导致业务中断或用户投诉，以及哪些导致设备损坏。这说明VMAX在检测和处理故障时有安全层面的功能。\n",
      "\n",
      "另外，“数据可靠性”部分提到了软件可靠性松耦合设计，容错能力的提高，这些都与安全性有关。同时，“评估优化功能”中提到评估报告和定期自动生成报告，这也涉及到安全监控和保护。\n",
      "\n",
      "还有“多维价值分析系统”部分，讨论了网络实时保障，包括质量指标和图形展示，这可能涉及安全性能的监控和保护。\n",
      "\n",
      "综合来看，VMAX的安全加固应该包括检测、诊断、修复和保护功能。这些功能帮助用户或维护人员及时发现并处理问题，同时确保设备在异常情况下能够正常运行，保护数据不被窃取或损坏。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "Human: 安全加固的操作步骤？\n",
      "Assistant: <think>\n",
      "嗯，用户问的是“什么是VMAX的安全加固？”。首先，我需要明确VMAX是什么。根据上下文，VMAX是一个多维价值分析系统，主要用于数据分析和决策支持。\n",
      "\n",
      "接下来，我要解释安全加固的概念。安全加固是为确保系统的安全性而设计的额外功能或措施。它能够检测到潜在的安全威胁，防止设备损坏或数据丢失。\n",
      "\n",
      "然后，我需要将这些信息整合成一个清晰、简洁的回答，涵盖VMAX的安全加固的主要特点，包括检测与诊断、修复与恢复、数据可靠性等。\n",
      "\n",
      "最后，我要确保语言自然流畅，逻辑清晰，让用户能够轻松理解VMAX安全加固的功能和作用。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "Follow Up Input: 整理成中文表格\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是DeepSeek VMAX-S知识助手。使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。总是在回答的最后说“谢谢你的提问！”。\n",
      "                4 功能本章包含如下主题：基础分析\n",
      "12\n",
      "维护保障\n",
      "15\n",
      "本节介绍ZXVMAX-S的主要的功能。\n",
      "4.1 基础分析\n",
      "\n",
      "ZXVMAX-S多维价值分析系统产品描述（数据业务）元、位置、终端等维度的分析，也可以从失败指标钻取失败原因值分析，再从失败原因值分析钻取详细XDR。网络实时保障移动通信网络发生异常时，对用户的业务使用影响重大，有必要对网络进行实时的保障，以便在网络发生异常时迅速做出反应，及时处理，将对用户的负面影响降低到最小。实时保障功能以图形的方式实时呈现出网络的相关质量指标，呈现图形可以选择为柱状图或者折线图。实时保障的目标、场景、告警门限、时长和粒度等均可配置，这些配置信息可保存为模板供重复使用。保障结果数据可以导出、保存。实时保障支持的指标完全覆盖网络性能指标，支持的分析维度主要为\n",
      "MME、eNodeB等网元。\n",
      "\n",
      "7可靠性设计容错能力\n",
      "ZXVMAX-S通过对关键软件资源的定时检测、实时任务监控、存储保护、数据校验、操作日志信息保存等手段，可有效地防止小软件故障对系统所造成的冲击，提高了软件系统的容错能力（即软件错误情况下的自愈能力）。故障监视及处理\n",
      "ZXVMAX-S具备自动检测与诊断系统软硬件故障的功能，可对故障硬件实施自动隔离、倒换、重新启动、重新加载等处理。满足漏洞扫描为了避免存在安全漏洞使在网设备受外部攻击，需要使系统满足主流安全漏洞扫描工具的要求。\n",
      "ZXVMAX-S满足Nessus和CD工具安全漏洞扫描的要求。\n",
      "7.3 数据可靠性\n",
      "\n",
      "ZXVMAX-S多维价值分析系统产品描述（5GC业务）\n",
      "4.2.1 可维可测功能概述系统提供维护管理类功能，既可以提供给运营商使用，也可以提供给我司运维人员操作。其聚焦于数据质量、系统的可维护性等方面。数据质量核查系统提供数据质量核查功能，构建从采集层到共享层，再到应用层的全流程数据质量核查体系，全面反映系统运行中各环节状态和业务过程中的质量。主要提供客户关注的详单数据三率检查，即完整率、合规率、准确率的检查。在准确率方面提供关键指标对比等专项分析。\n",
      "\n",
      "3 操作维护系统\n",
      "ZXVMAX-S的系统管理功能，主要分为三大类功能：基础管理功能，集群管理功能，产品管理功能。基础管理功能是指有助于安装、安全、日志、license功能等系统基础性的功能。集群管理功能是指针对ZXVMAX-S特有的服务器集群进行管理支持的功能，比如集群配置管理功能，集群的监控功能，集群服务器的IT硬件管理功能等。产品管理功能主要是指对ZXVMAX-S的性能、告警、版本等业务相关管理功能。\n",
      "SJ-20220623151803-017|2023-03-30（R1.0）\n",
      "9\n",
      "                问题: <think>\n",
      "用户问的是“什么是VMAX的安全加固？”，我需要先理解VMAX是什么。根据上下文，VMAX是一个多维价值分析系统，主要用于数据分析和决策支持。\n",
      "\n",
      "接下来，我要解释安全加固的概念。安全加固是为确保系统的安全性而设计的额外功能或措施。它能够检测到潜在的安全威胁，防止设备损坏或数据丢失。\n",
      "\n",
      "然后，我需要将这些信息整合成一个清晰、简洁的回答，涵盖VMAX的安全加固的主要特点，包括检测与诊断、修复与恢复、数据可靠性等。\n",
      "\n",
      "最后，我要确保语言自然流畅，逻辑清晰，让用户能够轻松理解VMAX安全加固的功能和作用。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "        \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "问题：整理成中文表格\n",
      "回答：<think>\n",
      "嗯，用户问的是“什么是VMAX的安全加固？”，我需要先理解VMAX是什么。根据上下文，VMAX是一个多维价值分析系统，主要用于数据分析和决策支持。\n",
      "\n",
      "接下来，我要解释安全加固的概念。安全加固是为确保系统的安全性而设计的额外功能或措施。它能够检测到潜在的安全威胁，防止设备损坏或数据丢失。\n",
      "\n",
      "然后，我需要将这些信息整合成一个清晰、简洁的回答，涵盖VMAX安全加固的主要特点，包括检测与诊断、修复与恢复、数据可靠性等。\n",
      "\n",
      "最后，我要确保语言自然流畅，逻辑清晰，让用户能够轻松理解VMAX安全加固的功能和作用。\n",
      "</think>\n",
      "\n",
      "VMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\n",
      "\n",
      "1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\n",
      "\n",
      "2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\n",
      "\n",
      "3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\n",
      "\n",
      "4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\n",
      "\n",
      "5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\n",
      "\n",
      "综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。\n",
      "对话历史： {'chat_history': [HumanMessage(content='什么是VMAX的安全加固？', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n嗯，用户问的是“什么是VMAX的安全加固？”首先，我需要理解VMAX是什么。根据上下文，VMAX是用于网络设备管理的软件，可能是一个安全工具或监控平台。\\n\\n接下来，用户的问题涉及到安全加固，这通常指的是为某个系统或产品添加额外的安全功能来增强其安全性。所以，我应该从VMAX的角度出发，看看它有哪些安全加固的功能。\\n\\n在提供的上下文中，我看到VMAX-S有多个模块，比如通信基础知识、组网和业务功能、故障定位操作、测试工具和仪表等。这些部分都可能涉及安全方面的功能。\\n\\n例如，在“故障定位操作”部分提到需要了解哪些操作会导致业务中断或用户投诉，以及哪些导致设备损坏。这说明VMAX在检测和处理故障时有安全层面的功能。\\n\\n另外，“数据可靠性”部分提到了软件可靠性松耦合设计，容错能力的提高，这些都与安全性有关。同时，“评估优化功能”中提到评估报告和定期自动生成报告，这也涉及到安全监控和保护。\\n\\n还有“多维价值分析系统”部分，讨论了网络实时保障，包括质量指标和图形展示，这可能涉及安全性能的监控和保护。\\n\\n综合来看，VMAX的安全加固应该包括检测、诊断、修复和保护功能。这些功能帮助用户或维护人员及时发现并处理问题，同时确保设备在异常情况下能够正常运行，保护数据不被窃取或损坏。\\n</think>\\n\\nVMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\\n\\n1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\\n\\n2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\\n\\n3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\\n\\n4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\\n\\n5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\\n\\n综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。', additional_kwargs={}, response_metadata={}), HumanMessage(content='安全加固的操作步骤？', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n嗯，用户问的是“什么是VMAX的安全加固？”。首先，我需要明确VMAX是什么。根据上下文，VMAX是一个多维价值分析系统，主要用于数据分析和决策支持。\\n\\n接下来，我要解释安全加固的概念。安全加固是为确保系统的安全性而设计的额外功能或措施。它能够检测到潜在的安全威胁，防止设备损坏或数据丢失。\\n\\n然后，我需要将这些信息整合成一个清晰、简洁的回答，涵盖VMAX的安全加固的主要特点，包括检测与诊断、修复与恢复、数据可靠性等。\\n\\n最后，我要确保语言自然流畅，逻辑清晰，让用户能够轻松理解VMAX安全加固的功能和作用。\\n</think>\\n\\nVMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\\n\\n1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\\n\\n2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\\n\\n3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\\n\\n4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\\n\\n5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\\n\\n综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。', additional_kwargs={}, response_metadata={}), HumanMessage(content='整理成中文表格', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\n嗯，用户问的是“什么是VMAX的安全加固？”，我需要先理解VMAX是什么。根据上下文，VMAX是一个多维价值分析系统，主要用于数据分析和决策支持。\\n\\n接下来，我要解释安全加固的概念。安全加固是为确保系统的安全性而设计的额外功能或措施。它能够检测到潜在的安全威胁，防止设备损坏或数据丢失。\\n\\n然后，我需要将这些信息整合成一个清晰、简洁的回答，涵盖VMAX安全加固的主要特点，包括检测与诊断、修复与恢复、数据可靠性等。\\n\\n最后，我要确保语言自然流畅，逻辑清晰，让用户能够轻松理解VMAX安全加固的功能和作用。\\n</think>\\n\\nVMAX的安全加固是指为VMAX系统设计的额外安全功能，旨在增强其安全性，防止潜在的安全威胁和故障。以下是VMAX安全加固的主要特点：\\n\\n1. **检测与诊断**：VMAX能够自动检测和诊断设备中的潜在问题，包括网络异常、硬件故障等，确保及时发现并处理故障。\\n\\n2. **修复与恢复**：系统具备修复功能，可以倒换、重新启动或重载设备，防止设备损坏或数据丢失。\\n\\n3. **数据可靠性**：通过实时监控和保护措施，VMAX能够检测到小故障对系统的影响，并自动隔离或重置设备，确保数据不被窃取或损坏。\\n\\n4. **安全性能监控**：VMAX支持网络实时保障功能，包括图形化质量指标展示和实时告警，帮助维护人员及时发现异常情况并采取措施。\\n\\n5. **多维度分析与修复**：VMAX能够从多个维度（如注册、呼叫、数据业务）进行深入分析，识别问题根源，并提供闭环验证解决方案。\\n\\n综上所述，VMAX的安全加固功能旨在通过检测、诊断和修复设备，同时保护数据安全，确保网络设备在异常情况下能够正常运行。', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import cohere\n",
    "\n",
    "# Initialize memory outside the function so it persists across questions\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "def get_vectordb():\n",
    "    emb_bgem3 = OllamaEmbeddings(base_url='http://localhost:11434', model=\"bge-m3:latest\")\n",
    "    persist_directory = '../chroma-vmax'\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=\"vmax-s\",\n",
    "        embedding_function=emb_bgem3\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "def get_llm():\n",
    "    return OllamaLLM(base_url='http://localhost:11434', model='deepseek-r1:1.5b', temperature=0.1)\n",
    "\n",
    "def get_qa_chain_with_memory(question: str):\n",
    "    vectordb = get_vectordb()\n",
    "    myllm = get_llm()\n",
    "\n",
    "    cohere_client = cohere.Client(api_key=\"Tahx1eySFbKvu9sTyTXrRLf59la3ZUG9vy02stRZ\")\n",
    "    compressor = CohereRerank(\n",
    "        client=cohere_client,\n",
    "        top_n=5,\n",
    "        model=\"rerank-multilingual-v3.0\"\n",
    "    )\n",
    "\n",
    "    base_retriever = vectordb.as_retriever(\n",
    "        search_kwargs={\"k\": 15},\n",
    "        search_type=\"mmr\",\n",
    "    )\n",
    "\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=base_retriever\n",
    "    )\n",
    "\n",
    "    QA_CHAIN_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "        template=\"\"\"\n",
    "        你是DeepSeek VMAX-S知识助手。使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。总是在回答的最后说“谢谢你的提问！\n",
    "        \n",
    "        历史对话：\n",
    "        {chat_history}\n",
    "        \n",
    "        上下文：\n",
    "        {context}\n",
    "        \n",
    "        问题：{question}\n",
    "        \n",
    "        回答：\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    #     input_variables=[\"context\",\"question\"],\n",
    "    #     template=\"\"\"你是DeepSeek VMAX-S知识助手。使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。总是在回答的最后说“谢谢你的提问！”。\n",
    "    #             {context}\n",
    "    #             问题: {question}\n",
    "    #     \"\"\"\n",
    "    # )\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=get_llm(),\n",
    "        retriever=compression_retriever,\n",
    "        memory=memory,\n",
    "        output_key=\"answer\",\n",
    "        combine_docs_chain_kwargs={\n",
    "            \"prompt\": QA_CHAIN_PROMPT\n",
    "        },\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    result = qa_chain({\"question\": question})  # Changed from \"query\" to \"question\"\n",
    "    return result\n",
    "\n",
    "questions = [\n",
    "    \"什么是VMAX的上网日志业务？\",\n",
    "    \"上网日志业务包含哪些功能？\",  # 需记忆前一轮的\"主要内容\"\n",
    "    \"整理成中文表格\"  # 需合并多轮信息\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = get_qa_chain_with_memory(question)  # Pass string directly, not dict\n",
    "    print(f\"问题：{question}\")\n",
    "    print(f\"回答：{result['answer']}\")\n",
    "    print(\"对话历史：\", memory.load_memory_variables({}))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5bcc09-e938-427f-8c8c-e6cdb3f335ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ LLM API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ¬ç« èŠ‚ä¸»è¦ä»‹ç»æ™ºè°± GLMçš„ API ç”³è¯·æŒ‡å¼•å’Œ Python ç‰ˆæœ¬çš„åŸç”Ÿ API è°ƒç”¨æ–¹æ³•ï¼Œè¯»è€…æŒ‰ç…§å®é™…æƒ…å†µé€‰æ‹©ä¸€ç§è‡ªå·±å¯ä»¥ç”³è¯·çš„ API è¿›è¡Œé˜…è¯»å­¦ä¹ å³å¯ã€‚\n",
    "\n",
    "å¦‚æœä½ éœ€è¦åœ¨ LangChain ä¸­ä½¿ç”¨ LLMï¼Œå¯ä»¥å‚ç…§[LLM æ¥å…¥ LangChain]ä¸­çš„è°ƒç”¨æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯»å– `.env` æ–‡ä»¶ä¸­ä¿å­˜çš„API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "# find_dotenv() å¯»æ‰¾å¹¶å®šä½ .env æ–‡ä»¶çš„è·¯å¾„\n",
    "# load_dotenv() è¯»å–è¯¥ .env æ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¸­çš„ç¯å¢ƒå˜é‡åŠ è½½åˆ°å½“å‰çš„è¿è¡Œç¯å¢ƒä¸­  \n",
    "# å¦‚æœä½ è®¾ç½®çš„æ˜¯å…¨å±€çš„ç¯å¢ƒå˜é‡ï¼Œè¿™è¡Œä»£ç åˆ™æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\learn-llm-rag-easily\\\\.env'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-b03a5d47f1094751ac79560dcf91ddd0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key=os.environ[\"DEEPSEEK_API_KEY\"]\n",
    "\n",
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‚è€ƒä½¿ç”¨ ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPTï¼Œå‘å¸ƒäº 2022 å¹´ 11 æœˆï¼Œæ˜¯ç›®å‰ç«çƒ­å‡ºåœˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼ŒLLMï¼‰çš„ä»£è¡¨äº§å“ã€‚åœ¨ 2022 å¹´åº•ï¼Œä¹Ÿæ­£æ˜¯ ChatGPT çš„æƒŠäººè¡¨ç°å¼•å‘äº† LLM çš„çƒ­æ½®ã€‚æ—¶è‡³ç›®å‰ï¼Œç”± OpenAI å‘å¸ƒçš„ GPT-4 ä»ç„¶æ˜¯ LLM æ€§èƒ½ä¸Šé™çš„ä»£è¡¨ï¼ŒChatGPT ä¹Ÿä»ç„¶æ˜¯ç›®å‰ä½¿ç”¨äººæ•°æœ€å¤šã€ä½¿ç”¨çƒ­åº¦æœ€å¤§ã€æœ€å…·å‘å±•æ½œåŠ›çš„ LLM äº§å“ã€‚äº‹å®ä¸Šï¼Œåœ¨åœˆå¤–äººçœ‹æ¥ï¼ŒChatGPT å³æ˜¯ LLM çš„ä»£ç§°ã€‚\n",
    "\n",
    "OpenAI é™¤å‘å¸ƒäº†å…è´¹çš„ Web ç«¯äº§å“å¤–ï¼Œä¹Ÿæä¾›äº†å¤šç§ ChatGPT APIï¼Œæ”¯æŒå¼€å‘è€…é€šè¿‡ Python æˆ– Request è¯·æ±‚æ¥è°ƒç”¨ ChatGPTï¼Œå‘è‡ªå·±çš„æœåŠ¡ä¸­åµŒå…¥ LLM çš„å¼ºå¤§èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API ç”³è¯·æŒ‡å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è·å–å¹¶é…ç½® OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI API è°ƒç”¨æœåŠ¡æ˜¯ä»˜è´¹çš„ï¼Œæ¯ä¸€ä¸ªå¼€å‘è€…éƒ½éœ€è¦é¦–å…ˆè·å–å¹¶é…ç½® OpenAI API keyï¼Œæ‰èƒ½åœ¨è‡ªå·±æ„å»ºçš„åº”ç”¨ä¸­è®¿é—® ChatGPTã€‚æˆ‘ä»¬å°†åœ¨è¿™éƒ¨åˆ†ç®€è¿°å¦‚ä½•è·å–å¹¶é…ç½® OpenAI API keyã€‚\n",
    "\n",
    "åœ¨è·å– OpenAI API key ä¹‹å‰æˆ‘ä»¬éœ€è¦åœ¨[OpenAI å®˜ç½‘](https://openai.com/)æ³¨å†Œä¸€ä¸ªè´¦å·ã€‚è¿™é‡Œå‡è®¾æˆ‘ä»¬å·²ç»æœ‰äº† OpenAI è´¦å·ï¼Œåœ¨[OpenAI å®˜ç½‘](https://openai.com/)ç™»å½•ï¼Œç™»å½•åå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../figures/C2-2-openai-choose.png\" width=\"1000\" alt=\"OpenAI å®˜ç½‘ç™»å½•åé€‰æ‹© API\">\n",
    "</p>\n",
    "\n",
    "æˆ‘ä»¬é€‰æ‹© `API`ï¼Œç„¶åç‚¹å‡»å·¦ä¾§è¾¹æ çš„ `API keys`ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../figures/C2-2-openai-get-key.png\" width=\"1000\" alt=\"OpenAI è·å– API key\">\n",
    "</p>\n",
    "\n",
    "ç‚¹å‡» `Create new secret key` æŒ‰é’®åˆ›å»º OpenAI API key ï¼Œæˆ‘ä»¬å°†åˆ›å»ºå¥½çš„ OpenAI API key å¤åˆ¶ä»¥æ­¤å½¢å¼ `OPENAI_API_KEY=\"sk-...\"` ä¿å­˜åˆ° `.env` æ–‡ä»¶ä¸­ï¼Œå¹¶å°† `.env` æ–‡ä»¶ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è°ƒç”¨ OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨ ChatGPT éœ€è¦ä½¿ç”¨ [ChatCompletion API](https://platform.openai.com/docs/api-reference/chat)ï¼Œè¯¥ API æä¾›äº† ChatGPT ç³»åˆ—æ¨¡å‹çš„è°ƒç”¨ï¼ŒåŒ…æ‹¬ ChatGPT-3.5ï¼ŒGPT-4 ç­‰ã€‚\n",
    "\n",
    "ChatCompletion API è°ƒç”¨æ–¹æ³•å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m client = OpenAI(\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# This is the default and can be omitted\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# api_key=os.environ.get(\"OPENAI_API_KEY\"),\u001b[39;00m\n\u001b[32m      6\u001b[39m     api_key=\u001b[33m'\u001b[39m\u001b[33msk-Ocsm6ESqIIrTe6qssqriT3BlbkFJH1SvD3pUol9nBoQqfWGR\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# å¯¼å…¥æ‰€éœ€åº“\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# æ³¨æ„ï¼Œæ­¤å¤„æˆ‘ä»¬å‡è®¾ä½ å·²æ ¹æ®ä¸Šæ–‡é…ç½®äº† OpenAI API Keyï¼Œå¦‚æ²¡æœ‰å°†è®¿é—®å¤±è´¥\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_key='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'\n",
    ")\n",
    "\n",
    "\n",
    "# å¯¼å…¥æ‰€éœ€åº“\n",
    "# æ³¨æ„ï¼Œæ­¤å¤„æˆ‘ä»¬å‡è®¾ä½ å·²æ ¹æ®ä¸Šæ–‡é…ç½®äº† OpenAI API Keyï¼Œå¦‚æ²¡æœ‰å°†è®¿é—®å¤±è´¥\n",
    "completion = client.chat.completions.create(\n",
    "    # è°ƒç”¨æ¨¡å‹ï¼šChatGPT-3.5\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    # messages æ˜¯å¯¹è¯åˆ—è¡¨\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨è¯¥ API ä¼šè¿”å›ä¸€ä¸ª ChatCompletion å¯¹è±¡ï¼Œå…¶ä¸­åŒ…æ‹¬äº†å›ç­”æ–‡æœ¬ã€åˆ›å»ºæ—¶é—´ã€id ç­‰å±æ€§ã€‚æˆ‘ä»¬ä¸€èˆ¬éœ€è¦çš„æ˜¯å›ç­”æ–‡æœ¬ï¼Œä¹Ÿå°±æ˜¯å›ç­”å¯¹è±¡ä¸­çš„ content ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­¤å¤„æˆ‘ä»¬è¯¦ç»†ä»‹ç»è°ƒç”¨ API å¸¸ä¼šç”¨åˆ°çš„å‡ ä¸ªå‚æ•°ï¼š\n",
    "\n",
    "    Â· modelï¼Œå³è°ƒç”¨çš„æ¨¡å‹ï¼Œä¸€èˆ¬å–å€¼åŒ…æ‹¬â€œgpt-3.5-turboâ€ï¼ˆChatGPT-3.5ï¼‰ã€â€œgpt-3.5-turbo-16k-0613â€ï¼ˆChatGPT-3.5 16K ç‰ˆæœ¬ï¼‰ã€â€œgpt-4â€ï¼ˆChatGPT-4ï¼‰ã€‚æ³¨æ„ï¼Œä¸åŒæ¨¡å‹çš„æˆæœ¬æ˜¯ä¸ä¸€æ ·çš„ã€‚\n",
    "\n",
    "    Â· messagesï¼Œå³æˆ‘ä»¬çš„ promptã€‚ChatCompletion çš„ messages éœ€è¦ä¼ å…¥ä¸€ä¸ªåˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­åŒ…æ‹¬å¤šä¸ªä¸åŒè§’è‰²çš„ promptã€‚æˆ‘ä»¬å¯ä»¥é€‰æ‹©çš„è§’è‰²ä¸€èˆ¬åŒ…æ‹¬ systemï¼šå³å‰æ–‡ä¸­æåˆ°çš„ system promptï¼›userï¼šç”¨æˆ·è¾“å…¥çš„ promptï¼›assistantï¼šåŠ©æ‰‹ï¼Œä¸€èˆ¬æ˜¯æ¨¡å‹å†å²å›å¤ï¼Œä½œä¸ºæä¾›ç»™æ¨¡å‹çš„å‚è€ƒå†…å®¹ã€‚\n",
    "\n",
    "    Â· temperatureï¼Œæ¸©åº¦ã€‚å³å‰æ–‡ä¸­æåˆ°çš„ Temperature ç³»æ•°ã€‚\n",
    "\n",
    "    Â· max_tokensï¼Œæœ€å¤§ token æ•°ï¼Œå³æ¨¡å‹è¾“å‡ºçš„æœ€å¤§ token æ•°ã€‚OpenAI è®¡ç®— token æ•°æ˜¯åˆå¹¶è®¡ç®— Prompt å’Œ Completion çš„æ€» token æ•°ï¼Œè¦æ±‚æ€» token æ•°ä¸èƒ½è¶…è¿‡æ¨¡å‹ä¸Šé™ï¼ˆå¦‚é»˜è®¤æ¨¡å‹ token ä¸Šé™ä¸º 4096ï¼‰ã€‚å› æ­¤ï¼Œå¦‚æœè¾“å…¥çš„ prompt è¾ƒé•¿ï¼Œéœ€è¦è®¾ç½®è¾ƒå¤§çš„ max_token å€¼ï¼Œå¦åˆ™ä¼šæŠ¥é”™è¶…å‡ºé™åˆ¶é•¿åº¦ã€‚\n",
    "\n",
    "OpenAI æä¾›äº†å……åˆ†çš„è‡ªå®šä¹‰ç©ºé—´ï¼Œæ”¯æŒæˆ‘ä»¬é€šè¿‡è‡ªå®šä¹‰ prompt æ¥æå‡æ¨¡å‹å›ç­”æ•ˆæœï¼Œå¦‚ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„å°è£… OpenAI æ¥å£çš„å‡½æ•°ï¼Œæ”¯æŒæˆ‘ä»¬ç›´æ¥ä¼ å…¥ prompt å¹¶è·å¾—æ¨¡å‹çš„è¾“å‡ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m client = OpenAI(\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# This is the default and can be omitted\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# api_key=os.environ.get(\"OPENAI_API_KEY\"),\u001b[39;00m\n\u001b[32m      6\u001b[39m     api_key=\u001b[33m'\u001b[39m\u001b[33msk-Ocsm6ESqIIrTe6qssqriT3BlbkFJH1SvD3pUol9nBoQqfWGR\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgen_gpt_messages\u001b[39m(prompt):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_key='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'\n",
    ")\n",
    "\n",
    "\n",
    "def gen_gpt_messages(prompt):\n",
    "    '''\n",
    "    æ„é€  GPT æ¨¡å‹è¯·æ±‚å‚æ•° messages\n",
    "    \n",
    "    è¯·æ±‚å‚æ•°ï¼š\n",
    "        prompt: å¯¹åº”çš„ç”¨æˆ·æç¤ºè¯\n",
    "    '''\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature = 0):\n",
    "    '''\n",
    "    è·å– GPT æ¨¡å‹è°ƒç”¨ç»“æœ\n",
    "\n",
    "    è¯·æ±‚å‚æ•°ï¼š\n",
    "        prompt: å¯¹åº”çš„æç¤ºè¯\n",
    "        model: è°ƒç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º gpt-3.5-turboï¼Œä¹Ÿå¯ä»¥æŒ‰éœ€é€‰æ‹© gpt-4 ç­‰å…¶ä»–æ¨¡å‹\n",
    "        temperature: æ¨¡å‹è¾“å‡ºçš„æ¸©åº¦ç³»æ•°ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºç¨‹åº¦ï¼Œå–å€¼èŒƒå›´æ˜¯ 0~2ã€‚æ¸©åº¦ç³»æ•°è¶Šä½ï¼Œè¾“å‡ºå†…å®¹è¶Šä¸€è‡´ã€‚\n",
    "    '''\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=gen_gpt_messages(prompt),\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    if len(response.choices) > 0:\n",
    "        return response.choices[0].message.content\n",
    "    return \"generate answer error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_completion(\"ä½ å¥½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ä¸Šè¿°å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å°è£…äº† messages çš„ç»†èŠ‚ï¼Œä»…ä½¿ç”¨ user prompt æ¥å®ç°è°ƒç”¨ã€‚åœ¨ç®€å•åœºæ™¯ä¸­ï¼Œè¯¥å‡½æ•°è¶³å¤Ÿæ»¡è¶³ä½¿ç”¨éœ€æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨æ™ºè°± GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ™ºè°± AI æ˜¯ç”±æ¸…åå¤§å­¦è®¡ç®—æœºç³»æŠ€æœ¯æˆæœè½¬åŒ–è€Œæ¥çš„å…¬å¸ï¼Œè‡´åŠ›äºæ‰“é€ æ–°ä¸€ä»£è®¤çŸ¥æ™ºèƒ½é€šç”¨æ¨¡å‹ã€‚å…¬å¸åˆä½œç ”å‘äº†åŒè¯­åƒäº¿çº§è¶…å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ GLM-130Bï¼Œå¹¶æ„å»ºäº†é«˜ç²¾åº¦é€šç”¨çŸ¥è¯†å›¾è°±ï¼Œå½¢æˆæ•°æ®ä¸çŸ¥è¯†åŒè½®é©±åŠ¨çš„è®¤çŸ¥å¼•æ“ï¼ŒåŸºäºæ­¤æ¨¡å‹æ‰“é€ äº† ChatGLMï¼ˆchatglm.cnï¼‰ã€‚\n",
    "\n",
    "ChatGLM ç³»åˆ—æ¨¡å‹ï¼ŒåŒ…æ‹¬ ChatGLM-130Bã€ChatGLM-6B å’Œ ChatGLM2-6Bï¼ˆChatGLM-6B çš„å‡çº§ç‰ˆæœ¬ï¼‰æ¨¡å‹ï¼Œæ”¯æŒç›¸å¯¹å¤æ‚çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå¹¶ä¸”èƒ½å¤Ÿè§£å†³å›°éš¾çš„æ¨ç†ç±»é—®é¢˜ã€‚å…¶ä¸­ï¼ŒChatGLM-6B æ¨¡å‹æ¥è‡ª Huggingface ä¸Šçš„ä¸‹è½½é‡å·²ç»è¶…è¿‡ 300wï¼ˆæˆªè‡³ 2023 å¹´ 6 æœˆ 24 æ—¥ç»Ÿè®¡æ•°æ®ï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨ Hugging Face (HF) å…¨çƒå¤§æ¨¡å‹ä¸‹è½½æ¦œä¸­è¿ç»­ 12 å¤©ä½å±…ç¬¬ä¸€åï¼Œåœ¨å›½å†…å¤–çš„å¼€æºç¤¾åŒºä¸­äº§ç”Ÿäº†è¾ƒå¤§çš„å½±å“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API ç”³è¯·æŒ‡å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆè¿›å…¥åˆ° [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/overview)ï¼Œç‚¹å‡»`å¼€å§‹ä½¿ç”¨`æˆ–è€…`å¼€å‘å·¥ä½œå°`è¿›è¡Œæ³¨å†Œï¼š\n",
    "\n",
    "![](../../figures/C2-2-zhipuai_home.png)\n",
    "\n",
    "æ–°æ³¨å†Œçš„ç”¨æˆ·å¯ä»¥å…è´¹é¢†å–æœ‰æ•ˆæœŸ 1 ä¸ªæœˆçš„ 100w token çš„ä½“éªŒåŒ…ï¼Œè¿›è¡Œä¸ªäººå®åè®¤è¯åï¼Œè¿˜å¯ä»¥é¢å¤–é¢†å– 400w token ä½“éªŒåŒ…ã€‚æ™ºè°± AI æä¾›äº† GLM-4 å’Œ GLM-3-Turbo è¿™ä¸¤ç§ä¸åŒæ¨¡å‹çš„ä½“éªŒå…¥å£ï¼Œå¯ä»¥ç‚¹å‡»`ç«‹å³ä½“éªŒ`æŒ‰é’®ç›´æ¥ä½“éªŒã€‚\n",
    "\n",
    "![æ™ºè°± AI æ§åˆ¶å°](../../figures/C2-2-zhipuai_overview.png)\n",
    "\n",
    "å¯¹äºéœ€è¦ä½¿ç”¨ API key æ¥æ­å»ºåº”ç”¨çš„è¯ï¼Œéœ€è¦ç‚¹å‡»å³ä¾§çš„`æŸ¥çœ‹ API key`æŒ‰é’®ï¼Œå°±ä¼šè¿›å…¥åˆ°æˆ‘ä»¬ä¸ªäººçš„ API ç®¡ç†åˆ—è¡¨ä¸­ã€‚åœ¨è¯¥ç•Œé¢ï¼Œå°±å¯ä»¥çœ‹åˆ°æˆ‘ä»¬è·å–åˆ°çš„ API æ‰€å¯¹åº”çš„åº”ç”¨åå­—å’Œ `API key` äº†ã€‚\n",
    "\n",
    "![æ™ºè°± AI api ç®¡ç†](../../figures/C2-2-zhipuai_api.png)\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥ç‚¹å‡» `æ·»åŠ æ–°çš„ API key` å¹¶è¾“å…¥å¯¹åº”çš„åå­—å³å¯ç”Ÿæˆæ–°çš„ API keyã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è°ƒç”¨æ™ºè°± GLM API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ™ºè°± AI æä¾›äº† SDK å’ŒåŸç”Ÿ HTTP æ¥å®ç°æ¨¡å‹ API çš„è°ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨ SDK è¿›è¡Œè°ƒç”¨ä»¥è·å¾—æ›´å¥½çš„ç¼–ç¨‹ä½“éªŒã€‚\n",
    "\n",
    "é¦–å…ˆæˆ‘ä»¬éœ€è¦é…ç½®å¯†é’¥ä¿¡æ¯ï¼Œå°†å‰é¢è·å–åˆ°çš„ `API key` è®¾ç½®åˆ° `.env` æ–‡ä»¶ä¸­çš„ `ZHIPUAI_API_KEY` å‚æ•°ï¼Œç„¶åè¿è¡Œä»¥ä¸‹ä»£ç åŠ è½½é…ç½®ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "# find_dotenv() å¯»æ‰¾å¹¶å®šä½ .env æ–‡ä»¶çš„è·¯å¾„\n",
    "# load_dotenv() è¯»å–è¯¥ .env æ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¸­çš„ç¯å¢ƒå˜é‡åŠ è½½åˆ°å½“å‰çš„è¿è¡Œç¯å¢ƒä¸­  \n",
    "# å¦‚æœä½ è®¾ç½®çš„æ˜¯å…¨å±€çš„ç¯å¢ƒå˜é‡ï¼Œè¿™è¡Œä»£ç åˆ™æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\learn-llm-rag-easily\\\\.env'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05dc01cafdae67456b454b09a7548559.GWN9tBQtENjWuv1N'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"ZHIPUAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ™ºè°±çš„è°ƒç”¨ä¼ å‚å’Œå…¶ä»–ç±»ä¼¼ï¼Œä¹Ÿéœ€è¦ä¼ å…¥ä¸€ä¸ª messages åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­åŒ…æ‹¬ role å’Œ promptã€‚æˆ‘ä»¬å°è£…å¦‚ä¸‹çš„ `get_completion` å‡½æ•°ï¼Œä¾›åç»­ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI(\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "def gen_glm_params(prompt):\n",
    "    '''\n",
    "    æ„é€  GLM æ¨¡å‹è¯·æ±‚å‚æ•° messages\n",
    "\n",
    "    è¯·æ±‚å‚æ•°ï¼š\n",
    "        prompt: å¯¹åº”çš„ç”¨æˆ·æç¤ºè¯\n",
    "    '''\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"glm-4\", temperature=0.95):\n",
    "    '''\n",
    "    è·å– GLM æ¨¡å‹è°ƒç”¨ç»“æœ\n",
    "\n",
    "    è¯·æ±‚å‚æ•°ï¼š\n",
    "        prompt: å¯¹åº”çš„æç¤ºè¯\n",
    "        model: è°ƒç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º glm-4ï¼Œä¹Ÿå¯ä»¥æŒ‰éœ€é€‰æ‹© glm-3-turbo ç­‰å…¶ä»–æ¨¡å‹\n",
    "        temperature: æ¨¡å‹è¾“å‡ºçš„æ¸©åº¦ç³»æ•°ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºç¨‹åº¦ï¼Œå–å€¼èŒƒå›´æ˜¯ 0~1.0ï¼Œä¸”ä¸èƒ½è®¾ç½®ä¸º 0ã€‚æ¸©åº¦ç³»æ•°è¶Šä½ï¼Œè¾“å‡ºå†…å®¹è¶Šä¸€è‡´ã€‚\n",
    "    '''\n",
    "\n",
    "    messages = gen_glm_params(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    if len(response.choices) > 0:\n",
    "        return response.choices[0].message.content\n",
    "    return \"generate answer error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼Œå¯ä»¥å«æˆ‘å°æ™ºğŸ¤–ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"ä½ å¥½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œå¯¹ä¼ å…¥ zhipuai çš„å‚æ•°è¿›è¡Œç®€å•ä»‹ç»ï¼š\n",
    "\n",
    "- `messages (list)`ï¼Œè°ƒç”¨å¯¹è¯æ¨¡å‹æ—¶ï¼Œå°†å½“å‰å¯¹è¯ä¿¡æ¯åˆ—è¡¨ä½œä¸ºæç¤ºè¾“å…¥ç»™æ¨¡å‹ï¼›æŒ‰ç…§ {\"role\": \"user\", \"content\": \"ä½ å¥½\"} çš„é”®å€¼å¯¹å½¢å¼è¿›è¡Œä¼ å‚ï¼›æ€»é•¿åº¦è¶…è¿‡æ¨¡å‹æœ€é•¿è¾“å…¥é™åˆ¶åä¼šè‡ªåŠ¨æˆªæ–­ï¼Œéœ€æŒ‰æ—¶é—´ç”±æ—§åˆ°æ–°æ’åº\n",
    "\n",
    "- `temperature (float)`ï¼Œé‡‡æ ·æ¸©åº¦ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œå¿…é¡»ä¸ºæ­£æ•°å–å€¼èŒƒå›´æ˜¯ï¼š(0.0, 1.0)ï¼Œä¸èƒ½ç­‰äº 0ï¼Œé»˜è®¤å€¼ä¸º 0.95ã€‚å€¼è¶Šå¤§ï¼Œä¼šä½¿è¾“å‡ºæ›´éšæœºï¼Œæ›´å…·åˆ›é€ æ€§ï¼›å€¼è¶Šå°ï¼Œè¾“å‡ºä¼šæ›´åŠ ç¨³å®šæˆ–ç¡®å®š\n",
    "  \n",
    "- `top_p (float)`ï¼Œç”¨æ¸©åº¦å–æ ·çš„å¦ä¸€ç§æ–¹æ³•ï¼Œç§°ä¸ºæ ¸å–æ ·ã€‚å–å€¼èŒƒå›´æ˜¯ï¼š(0.0, 1.0) å¼€åŒºé—´ï¼Œä¸èƒ½ç­‰äº 0 æˆ– 1ï¼Œé»˜è®¤å€¼ä¸º 0.7ã€‚æ¨¡å‹è€ƒè™‘å…·æœ‰ top_p æ¦‚ç‡è´¨é‡ tokens çš„ç»“æœã€‚ä¾‹å¦‚ï¼š0.1 æ„å‘³ç€æ¨¡å‹è§£ç å™¨åªè€ƒè™‘ä»å‰ 10% çš„æ¦‚ç‡çš„å€™é€‰é›†ä¸­å– tokens\n",
    "\n",
    "- `request_id (string)`ï¼Œç”±ç”¨æˆ·ç«¯ä¼ å‚ï¼Œéœ€ä¿è¯å”¯ä¸€æ€§ï¼›ç”¨äºåŒºåˆ†æ¯æ¬¡è¯·æ±‚çš„å”¯ä¸€æ ‡è¯†ï¼Œç”¨æˆ·ç«¯ä¸ä¼ æ—¶å¹³å°ä¼šé»˜è®¤ç”Ÿæˆ\n",
    "\n",
    "- **å»ºè®®æ‚¨æ ¹æ®åº”ç”¨åœºæ™¯è°ƒæ•´ top_p æˆ– temperature å‚æ•°ï¼Œä½†ä¸è¦åŒæ—¶è°ƒæ•´ä¸¤ä¸ªå‚æ•°**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**å…¶ä»–æ¨èçš„APIï¼š**  \n",
    "ChatGPT  \n",
    "æ–‡å¿ƒä¸€è¨€  \n",
    "ä½¿ç”¨è®¯é£æ˜Ÿç«  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=os.environ[\"ZHIPUAI_API_KEY\"]) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # å¡«å†™éœ€è¦è°ƒç”¨çš„æ¨¡å‹ç¼–ç \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¹äºè§£ç­”å„ç§é—®é¢˜çš„åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸“ä¸šã€å‡†ç¡®ã€æœ‰è§åœ°çš„å»ºè®®ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"å†œå¤«éœ€è¦æŠŠç‹¼ã€ç¾Šå’Œç™½èœéƒ½å¸¦è¿‡æ²³ï¼Œä½†æ¯æ¬¡åªèƒ½å¸¦ä¸€æ ·ç‰©å“ï¼Œè€Œä¸”ç‹¼å’Œç¾Šä¸èƒ½å•ç‹¬ç›¸å¤„ï¼Œç¾Šå’Œç™½èœä¹Ÿä¸èƒ½å•ç‹¬ç›¸å¤„ï¼Œé—®å†œå¤«è¯¥å¦‚ä½•è¿‡æ²³ã€‚\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-c93efe07b0ef4445baca2cd28f54cb78\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ æœ¬åœ°å¼€æºLLM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è°ƒç”¨ollamaéƒ¨ç½²çš„å¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹ï¼ŒåŒæ ·å¯ä»¥ä½¿ç”¨ [ChatCompletion API](https://platform.openai.com/docs/api-reference/chat)ï¼Œè¯¥ API æä¾›äº† ChatGPT ç³»åˆ—æ¨¡å‹çš„è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nå—¯ï¼Œæˆ‘æœ€è¿‘åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œå¬è¯´æœ‰è¿™ä¸ªå«â€œå¤§è¯­è¨€æ¨¡å‹â€çš„ä¸œè¥¿ã€‚æˆ‘çŸ¥é“å®ƒè·ŸåƒGPTé‚£æ ·çš„æ¨¡å‹æœ‰å…³ï¼Œä½†å…·ä½“æ˜¯å•¥æ ·å­çš„æˆ‘è¿˜ä¸æ˜¯å¾ˆæ¸…æ¥šã€‚\\n\\né¦–å…ˆï¼Œæˆ‘è¦å¼„æ˜ç™½ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹äº†ã€‚å¥½åƒæ˜¯ç”¨æ¥ç”Ÿæˆæ–‡æœ¬çš„æ¨¡å‹ï¼Œå¯¹å§ï¼Ÿæ¯”å¦‚ï¼Œæˆ‘å¯ä»¥ç”¨å®ƒå»å†™æ–‡ç« ã€å›ç­”é—®é¢˜æˆ–è€…ç”Ÿæˆä¸€äº›æœ‰è¶£çš„è¯­å¥ã€‚é‚£å®ƒæ˜¯æ€ä¹ˆå·¥ä½œçš„å‘¢ï¼Ÿæ˜¯ä¸æ˜¯é€šè¿‡å‚æ•°æ¥å­¦ä¹ æ–‡æ¡£çš„å†…å®¹ï¼Ÿ\\n\\nç„¶åï¼Œæˆ‘è®°å¾—ä»¥å‰å­¦è¿‡æ¦‚ç‡è®ºä¸­çš„æ¡ä»¶æ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯P(A|B)è¡¨ç¤ºåœ¨äº‹ä»¶Bå‘ç”Ÿçš„æ¡ä»¶ä¸‹äº‹ä»¶Açš„æ¦‚ç‡ã€‚è€Œå¤§è¯­è¨€æ¨¡å‹å¥½åƒä¹Ÿæ˜¯åœ¨è®¡ç®—è¿™äº›æ¡ä»¶æ¦‚ç‡çš„ã€‚æ¯”å¦‚ï¼Œç”ŸæˆæŸå¥è¯çš„æ¦‚ç‡æœ‰å¤šå¤§ã€‚è¿™å¯èƒ½å’Œæ–‡æœ¬ç‰¹å¾æå–æœ‰å…³ã€‚\\n\\næ¥ä¸‹æ¥ï¼Œæˆ‘æœ‰ç‚¹æ··æ·†çš„æ˜¯è‡ªç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚å¬è¯´å¤§è¯­è¨€æ¨¡å‹ç”¨äº†è¿™ä¸¤ç§æ–¹æ³•æ¥è®­ç»ƒï¼Ÿé‚£ä»€ä¹ˆæ˜¯è‡ªç›‘ç£å­¦ä¹ å‘¢ï¼Ÿæ˜¯ä¸æ˜¯è®©æ¨¡å‹è‡ªå·±æ”¶é›†ä¸€äº›æ•°æ®ï¼Œç„¶åä»ä¸­æ¨æ–­å‡ºæˆ‘ä»¬éœ€è¦çš„ä¿¡æ¯ï¼Ÿè€Œå¼ºåŒ–å­¦ä¹ åˆ™æ˜¯é€šè¿‡å¥–åŠ±ç³»ç»Ÿæ¥å¼•å¯¼æ¨¡å‹å­¦ä¹ ï¼Ÿ\\n\\nå†æƒ³æƒ³ï¼Œç”Ÿæˆé—®é¢˜çš„æ—¶å€™ï¼Œæ¨¡å‹æ˜¯æ€ä¹ˆå¤„ç†çš„ï¼Ÿéœ€è¦è€ƒè™‘å“ªäº›å› ç´ ï¼Ÿæ¯”å¦‚ï¼Œç”¨æˆ·è¾“å…¥æ˜¯ä»€ä¹ˆæ ·çš„æ–‡æœ¬ç»“æ„å’Œä¿¡æ¯é‡ã€‚å¤§è¯­è¨€æ¨¡å‹æœ‰æ²¡æœ‰åŠæ³•é€‚åº”å„ç§ä¸åŒç±»å‹çš„æ–‡æ¡£ï¼Ÿ\\n\\næˆ‘è¿˜æƒ³äº†è§£ä¸€ä¸‹å®ƒæ˜¯å¦‚ä½•åˆ†è§£é—®é¢˜çš„ã€‚æ˜¯ä¸æ˜¯æŠŠç”Ÿæˆä¸€æ®µè¯çš„ä»»åŠ¡åˆ†è§£æˆä¸€æ®µä¸€å°æ®µä¸€å°æ®µåœ°å¤„ç†ï¼Œç„¶åæŠŠè¿™äº›æ®µè½ç»„åˆèµ·æ¥ï¼Ÿè¿™æ ·ä¼šä¸ä¼šå¯¼è‡´ç”Ÿæˆçš„å†…å®¹å¤ªè¿‡é‡å¤æˆ–è€…ä¸å¤Ÿç”ŸåŠ¨ï¼Ÿ\\n\\nè¿˜æœ‰ï¼Œè®­ç»ƒæ•°æ®çš„é—®é¢˜ã€‚æˆ‘å¾—çŸ¥é“æœ‰å¤šå°‘æ¡æ–°é—»æ ·æœ¬ã€ä¹¦ç±ç±ç›®æˆ–è€…æ–‡æœ¬æ¥è®­ç»ƒè¿™ä¸ªæ¨¡å‹å—ï¼Ÿå¯èƒ½å¾ˆå¤šå•Šï¼Œä½†å®é™…åº”ç”¨ä¸­ä¼šä¸ä¼šæœ‰å¤ªå¤šçš„æ•°æ®é‡å¸¦æ¥è®¡ç®—ä¸Šçš„è´Ÿæ‹…å‘¢ï¼Ÿ\\n\\nå¦å¤–ï¼Œæ¨¡å‹çš„æ¶æ„æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿæ˜¯ç±»ä¼¼äºç¥ç»ç½‘ç»œè¿˜æ˜¯å›¾ç¥ç»ç½‘ç»œæˆ–è€…å…¶ä»–ç»“æ„çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼Ÿæ¯å±‚çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Œæ˜¯ä¸æ˜¯æœ‰ä»€ä¹ˆç‰¹å®šçš„åŠŸèƒ½å¸®åŠ©å®ƒæ›´å¥½åœ°æ•æ‰æ·±å±‚çš„æ¨¡å¼ï¼Ÿ\\n\\nè¿˜æœ‰ï¼Œè®­ç»ƒæ—¶çš„æ•°æ®å¢å¼ºæ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿæœ‰æ²¡æœ‰åƒæ·»åŠ å™ªå£°æˆ–è€…å‰ªè£å¥å­é‚£æ ·æ‰‹æ®µæ¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å‘¢ï¼Ÿ\\n\\nç„¶åï¼Œç”Ÿæˆåçš„æ–‡æœ¬å¦‚ä½•è¯„ä»·å’Œä¼˜åŒ–ï¼Ÿæ˜¯åŸºäºæŸç§è¯„åˆ†æ ‡å‡†ï¼Œè¿˜æ˜¯é€šè¿‡å¤šè½®è°ƒæ•´æ‰èƒ½å¾—åˆ°æ›´é«˜è´¨é‡çš„ç»“æœï¼Ÿ\\n\\næˆ‘æœ‰ç‚¹å¯¹æ¦‚ç‡è®ºå’Œæœºå™¨å­¦ä¹ æœ‰ç‚¹äº†è§£ï¼Œä½†å…·ä½“çš„åº”ç”¨ä¸­çš„ä¾‹å­è¿˜æ˜¯æ²¡å¤ªå¤šæŒæ¡ã€‚æ¯”å¦‚ï¼Œä½¿ç”¨è¿™ç§æ¨¡å‹ç”Ÿæˆå›ç­”æ—¶ï¼Œæ˜¯å¦éœ€è¦å¤„ç†å¤šçº§æ„ŸçŸ¥å™¨æˆ–è€…ç»“åˆä¸åŒçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Ÿ\\n\\nè¿˜æœ‰ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œå¤§è¯­è¨€æ¨¡å‹èƒ½ä¸èƒ½åº”å¯¹å„ç§ä¸åŒé£æ ¼çš„æ–‡ç« å‘¢ï¼Ÿæ¯”å¦‚ï¼Œä¸€äº›å­¦æœ¯è®ºæ–‡æˆ–è€…æ–‡å­¦ä½œå“ï¼Œå®ƒä»¬çš„ç»“æ„å’Œè¯­è¨€ç‰¹ç‚¹ä¸æ™®é€šæ–°é—»æ–‡æœ¬æœ‰ä»€ä¹ˆä¸åŒå—ï¼Ÿæ¨¡å‹æ˜¯ä¸æ˜¯èƒ½åœ¨è¿™äº›æ–¹é¢ç»™å‡ºæ›´å¥½çš„å›ç­”ï¼Ÿ\\n\\nå¦å¤–ï¼Œæˆ‘å¬è¯´è®­ç»ƒæ—¶è¿˜ä½¿ç”¨äº†æ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œæ¶‰åŠæ¢¯åº¦ä¸‹é™ã€æ›´æ–°ç­‰ä¼˜åŒ–ç®—æ³•ã€‚äº†è§£è¿™äº›å…·ä½“çš„æ­¥éª¤ï¼Œä»¥åŠå¦‚ä½•åœ¨å®é™…ä¸­å®ç°æ¨¡å‹çš„è®­ç»ƒå’Œè°ƒæ•´ä¼šå¾ˆé‡è¦ã€‚\\n\\nè¿˜æœ‰ï¼Œç”¨æˆ·è¾“å…¥æ ¼å¼çš„ä¸åŒå¯èƒ½ä¼šå½±å“æ¨¡å‹çš„è¡¨ç°å¦‚ä½•ï¼Ÿæ¯”å¦‚ï¼Œåœ¨ä¸€äº›å¹³å°ä¸Šè¾“å…¥çš„ä¿¡æ¯å½¢å¼å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œå¤§è¯­è¨€æ¨¡å‹æ˜¯ä¸æ˜¯éœ€è¦è¿›è¡ŒæŸç§é¢„å¤„ç†æ‰èƒ½æ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆå“åº”ï¼Ÿ\\n\\næœ€åï¼Œæˆ‘æœ‰ç‚¹å¥½å¥‡çš„æ˜¯ï¼Œé™¤äº†ç”Ÿæˆæ–‡æœ¬å¤–ï¼Œè¿™ç§æ¨¡å‹è¿˜èƒ½åšä»€ä¹ˆå‘¢ï¼Ÿæ¯”å¦‚ï¼Œè¿›è¡Œåˆ†ç±»ã€é—®ç­”æˆ–è€…å†…å®¹æ¨èï¼Ÿè¿™äº›åº”ç”¨éƒ½æœ‰å„è‡ªçš„æŠ€æœ¯æŒ‘æˆ˜å’Œéœ€æ±‚ï¼Œå¯èƒ½ä¼šå½±å“å®ç°å’Œä½¿ç”¨çš„å¤§è¯­è¨€æ¨¡å‹ã€‚\\n\\næ€»ä¹‹ï¼Œå¤§è¯­è¨€æ¨¡å‹å¬èµ·æ¥æŒºå¤æ‚çš„ï¼Œæ¶‰åŠåˆ°äº†å¾ˆå¤šæ¦‚ç‡è®ºã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„çŸ¥è¯†ç‚¹ã€‚æˆ‘éœ€è¦è¿›ä¸€æ­¥äº†è§£å®ƒä»¬åœ¨å„ä¸ªæ–¹é¢çš„ç‰¹ç‚¹ã€æ¶æ„ä»¥åŠè®­ç»ƒæ–¹æ³•ï¼Œæ‰èƒ½æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨å®ƒã€‚\\n</think>\\n\\nå¤§è¯­è¨€æ¨¡å‹ï¼ˆ_large language model, LLMï¼‰æ˜¯ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆæ–‡æœ¬ã€å›ç­”é—®é¢˜åŠå†…å®¹æ¨èç­‰ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯å¯¹å…¶å·¥ä½œåŸç†å’Œç›¸å…³æŠ€æœ¯çš„è¯¦ç»†åˆ†æ­¥è§£é‡Šï¼š\\n\\n1. **æ¦‚è¿°ä¸èƒŒæ™¯**ï¼š\\n   - å¤§è¯­è¨€æ¨¡å‹å¹¿æ³›åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œç”¨äºç”Ÿæˆæ–‡æœ¬ï¼Œå¦‚å›ç­”ç”¨æˆ·æŸ¥è¯¢æˆ–åˆ›ä½œæœ‰è¶£çŸ­è¯­ã€‚\\n   - åŸºäºæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆæ¦‚ç‡è®ºä¸­çš„æ¡ä»¶æ¦‚ç‡æ¦‚å¿µã€‚\\n\\n2. **æ ¸å¿ƒæŠ€æœ¯**ï¼š\\n   \\n   - **å‚æ•°å­¦ä¹ **ï¼šé€šè¿‡è®­ç»ƒæ•°æ®å­¦ä¹ æ–‡æœ¬ç‰¹å¾ï¼Œè®¡ç®—P(A|B)çš„æ¦‚ç‡ï¼ŒæŒ‡å¯¼æ¨¡å‹åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ç”Ÿæˆå†…å®¹ã€‚\\n\\n   - **è‡ªç›‘ç£å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ **ï¼šè‡ªåŠ¨æå–æ•°æ®åï¼Œæ¨¡å‹ä½¿ç”¨è¿™äº›ä¿¡æ¯è¿›è¡Œé¢„æµ‹æˆ–ç­–ç•¥ä¼˜åŒ–æå‡æ€§èƒ½ã€‚\\n\\n3. **æƒ…æ„Ÿè¡¨ç¤ºä¸è¯­è¨€å»ºæ¨¡**ï¼š\\n   - åŸºäºè¯æ€§å’Œå¥æ³•ç»“æ„è¡¨ç¤ºæƒ…æ„Ÿå’Œè¯­ä¹‰ï¼Œæ•æ‰ä¸Šä¸‹æ–‡å’Œæ·±å±‚æ¨¡å¼ã€‚\\n\\n4. **ç”Ÿæˆè¿‡ç¨‹**ï¼š\\n   - å°†é—®é¢˜åˆ†è§£ä¸ºå°æ®µï¼Œæ¯ä¸ªæ®µç”Ÿæˆåç»„åˆæˆå®Œæ•´ç­”æ¡ˆã€‚\\n   ç„¶è€Œï¼Œç”Ÿæˆå†…å®¹å¯èƒ½è¿‡äºé‡å¤æˆ–ä¸å¤Ÿç”ŸåŠ¨ï¼Œéœ€æ”¹è¿›è¯­æ„Ÿã€‚\\n\\n5. **æ•°æ®ä¸æ¶æ„**ï¼š\\n   - ä½¿ç”¨å¤§é‡æ–‡æ¡£æ ·æœ¬è®­ç»ƒï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚\\n   ç»“æ„åŒ…æ‹¬å¤šä¸ªå±‚çº§æ„ŸçŸ¥å™¨ï¼ˆå¦‚å›¾ç¥ç»ç½‘ç»œï¼‰ï¼Œæ•æ‰æ·±å±‚æ¨¡å¼ã€‚\\n\\n6. **ä¼˜åŒ–ä¸è¯„ä»·**ï¼š\\n   - æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œå¦‚å™ªå£°æ·»åŠ ï¼Œæé«˜ç”Ÿæˆè´¨é‡ã€‚\\n   ç”Ÿæˆæ–‡æœ¬åŸºäºè¯„åˆ†æ ‡å‡†æˆ–åé¦ˆä¼˜åŒ–ï¼Œç¡®ä¿é«˜è´¨é‡ã€‚\\n\\n7. **è·¨é¢†åŸŸåº”ç”¨**ï¼š\\n   - åº”ç”¨æ–‡å‡­ã€é—®ç­”åŠå†…å®¹æ¨èï¼Œéœ€è§£å†³æ ¼å¼å’Œé£æ ¼é—®é¢˜ã€‚\\n\\n8. **å®ç°ç»†èŠ‚**ï¼š\\n   - æ·±åº¦å­¦ä¹ ä¸­çš„æ¢¯åº¦ä¸‹é™ä¸æ›´æ–°ç®—æ³•ï¼Œè®­ç»ƒæ¨¡å‹å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚\\n   é¢„å¤„ç†æ­¥éª¤ï¼šå¤„ç†ä¸åŒå½¢å¼ç”¨æˆ·è¾“å…¥ï¼Œä¼˜åŒ–ç”Ÿæˆæ•ˆæœã€‚\\n\\n9. **åº”ç”¨æ‰©å±•**ï¼š\\n\\n   - **é—®ç­”ç³»ç»Ÿ**ï¼šå›ç­”é—®é¢˜ï¼Œéœ€å¤šçº§æ„ŸçŸ¥å™¨å’Œæ³¨æ„åŠ›æœºåˆ¶ã€‚\\n   \\n   - **å†…å®¹æ¨èç³»ç»Ÿ**ï¼šåˆ†æç”¨æˆ·ç‰¹å¾ï¼Œé¢„æµ‹å…´è¶£ï¼Œæ¨èç›¸å…³å†…å®¹ã€‚\\n\\næ€»ä¹‹ï¼Œå¤§è¯­è¨€æ¨¡å‹é€šè¿‡å¤æ‚çš„æ·±åº¦å­¦ä¹ ç»“æ„ï¼Œåˆ©ç”¨æ¦‚ç‡è®ºå’Œè‡ªç„¶è¯­è¨€å¤„ç†åŸç†ï¼ŒæˆåŠŸåº”ç”¨äºæ–‡æœ¬ç”Ÿæˆã€é—®ç­”åŠå†…å®¹æ¨èã€‚å®ƒéœ€è¦æ·±å…¥ç†è§£å…¶æ ¸å¿ƒæŠ€æœ¯ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­ä¸æ–­ä¼˜åŒ–æ€§èƒ½å’ŒæŠ€æœ¯åˆ›æ–°ã€‚'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1/',\n",
    "    api_key = 'ollama'\n",
    ")\n",
    "\n",
    "prompt = 'å¤§è¯­è¨€æ¨¡å‹æ˜¯ä»€ä¹ˆï¼Ÿ'\n",
    "messages = [{\"role\":\"user\", \"content\":prompt}]\n",
    "response = client.chat.completions.create(\n",
    "    model = 'deepseek-r1:1.5b',\n",
    "    messages = messages,\n",
    "    temperature=0.95\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è°ƒç”¨vllméƒ¨ç½²çš„å¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: ChatCompletion(id='chatcmpl-21421752cdcd48b7b1ed53379a4fddff', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Alright, so the user asked me to tell them a joke. I need to respond in a way that\\'s helpful and engaging. Let me think of a good joke that\\'s a bit light-hearted. Maybe something about animals since that\\'s a popular topic. \\n\\nI remember a classic joke about bees and honey. It goes like this: Why do bees build hives in the spring? Because they\\'re looking for a sweet deal! That\\'s a simple and funny one. It\\'s a play on words with \"sweet deal\" sounding like \"hives\" and \"spring\" sounding like \"hives\" too.\\n\\nI should make sure the joke is clear and the pun works well. It should be easy to understand and bring a smile. I\\'ll go ahead and provide the joke as requested. I don\\'t want to overcomplicate it. Keeping it simple is better for humor.\\n</think>\\n\\nWhy do bees build hives in the spring?  \\nBecause they\\'re looking for a sweet deal!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None)], created=1743494974, model='deepseek-r1-distill-qwen-7b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=200, prompt_tokens=16, total_tokens=216, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"token-abc123\"\n",
    "openai_api_base = \"http://localhost:8081/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"deepseek-r1-distill-qwen-7b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "    ]\n",
    ")\n",
    "print(\"Chat response:\", chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
